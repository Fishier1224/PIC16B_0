[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Athena (Chou) Mo",
    "section": "",
    "text": "This is Athena’s blog for PIC16B"
  },
  {
    "objectID": "posts/Palmer-Penguins-data-visualization/Untitled.html",
    "href": "posts/Palmer-Penguins-data-visualization/Untitled.html",
    "title": "Palmer Penguins Data Visualization",
    "section": "",
    "text": "Begin by importing all the needed libraries. For databaset modifications, Pandas is required, while it will also be later used for visualization - along with Plotly and Matplotlib.\n\nimport pandas as pd\nfrom plotly import __version__\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nimport matplotlib.pyplot as plt\n\nWith the packages imported, we now read in the dataset (by using the provided url) and name it as penguins:\n\nurl = \"https://raw.githubusercontent.com/pic16b-ucla/24W/main/datasets/palmer_penguins.csv\"\npenguins = pd.read_csv(url)\n\nNow, specifically for the Species Adelie Penguin (Pygoscelis adeliae), we create a sub-dataframe named adelie_df that isolates data points for delie Penguins from the larger penguins dataframe:\n\nadelie_df = penguins[penguins[\"Species\"] == \"Adelie Penguin (Pygoscelis adeliae)\"].reset_index(drop=True)\nadelie_df.dropna()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n6\nPAL0708\n7\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN4A1\nNo\n11/15/07\n38.9\n17.8\n181.0\n3625.0\nFEMALE\n9.18718\n-25.21799\nNest never observed with full clutch.\n\n\n7\nPAL0708\n8\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN4A2\nNo\n11/15/07\n39.2\n19.6\n195.0\n4675.0\nMALE\n9.46060\n-24.89958\nNest never observed with full clutch.\n\n\n28\nPAL0708\n29\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN18A1\nNo\n11/10/07\n37.9\n18.6\n172.0\n3150.0\nFEMALE\n8.38404\n-25.19837\nNest never observed with full clutch.\n\n\n29\nPAL0708\n30\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN18A2\nNo\n11/10/07\n40.5\n18.9\n180.0\n3950.0\nMALE\n8.90027\n-25.11609\nNest never observed with full clutch.\n\n\n38\nPAL0708\n39\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nDream\nAdult, 1 Egg Stage\nN25A1\nNo\n11/13/07\n37.6\n19.3\n181.0\n3300.0\nFEMALE\n9.41131\n-25.04169\nNest never observed with full clutch.\n\n\n68\nPAL0809\n69\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN32A1\nNo\n11/11/08\n35.9\n16.6\n190.0\n3050.0\nFEMALE\n8.47781\n-26.07821\nNest never observed with full clutch.\n\n\n69\nPAL0809\n70\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN32A2\nNo\n11/11/08\n41.8\n19.4\n198.0\n4450.0\nMALE\n8.86853\n-26.06209\nNest never observed with full clutch.\n\n\n120\nPAL0910\n121\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN66A1\nNo\n11/17/09\n36.2\n17.2\n187.0\n3150.0\nFEMALE\n9.04296\n-26.19444\nNest never observed with full clutch.\n\n\n121\nPAL0910\n122\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN66A2\nNo\n11/17/09\n37.7\n19.8\n198.0\n3500.0\nMALE\n9.11066\n-26.42563\nNest never observed with full clutch.\n\n\n130\nPAL0910\n131\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN73A1\nNo\n11/23/09\n38.5\n17.9\n190.0\n3325.0\nFEMALE\n8.98460\n-25.57956\nNest never observed with full clutch.\n\n\n131\nPAL0910\n132\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN73A2\nNo\n11/23/09\n43.1\n19.2\n197.0\n3500.0\nMALE\n8.86495\n-26.13960\nNest never observed with full clutch.\n\n\n138\nPAL0910\n139\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nDream\nAdult, 1 Egg Stage\nN79A1\nNo\n11/16/09\n37.0\n16.5\n185.0\n3400.0\nFEMALE\n8.61651\n-26.07021\nNest never observed with full clutch.\n\n\n139\nPAL0910\n140\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nDream\nAdult, 1 Egg Stage\nN79A2\nNo\n11/16/09\n39.7\n17.9\n193.0\n4250.0\nMALE\n9.25769\n-25.88798\nNest never observed with full clutch.\n\n\n\n\n\n\n\nNote that the second line in the code block above drops rows for the adelie_df dataframe that includes NaN (incomplete data).\n\n\n\n\n\nFor plotly’s scatter plot, trace is a graph object that includes information about the graph’s x & y values, labels, and marker settings.\nThe following code block defines a new trace named trace1 which is specific to Adelie penguins using the adelie_df that we created before. It assigns “Culmen Length (mm) as the x values and Body Mass (g) as the y values.\nmode=“markers” specifies the drawing mode for the scatter plot. In this case, we are using markers.\nFor the line marker=dict(size=10, symbol=“circle”, line=dict(color=“rgb(0,0,0)”, width=0.5)), it defines the attribute marker (in the trace object) that specifies the design of the markers for the scatter plot. size is set to 10 pixels, and symbol is set to circle. line defines the marker’s outline, which is now black (“rgb(0,0,0)”) and has a width of 0.5.\nThe following line sets the marker color is set to black, and the line below that sets the label name to ““Adelie Penguin”.\n\ntrace1 = go.Scatter(\n    x=adelie_df[\"Culmen Length (mm)\"],\n    y=adelie_df[\"Body Mass (g)\"],\n    mode=\"markers\",\n    marker=dict(size=10, symbol=\"circle\", line=dict(color=\"rgb(0,0,0)\", width=0.5)),\n    marker_color=\"black\",\n    name=\"Adelie Penguin\",\n)\n\nNow we assigns the trace object to the variable data:\n\ndata = trace1\n\nAnd here we define the design for the plot. The title is set to “Culmen Depth (mm) vs. Body Mass (g) for Adelie Penguin” with the legend settings to “True” (which means to include it in the plot). The x-axis title is set to “Culmen Depth (mm)”, and the y-axis title is set to “Body Mass (g)”. The last two lines specifies that the background color for both plot area and the entire plot is transparent (“rgba(0,0,0,0)”).\n\nlayout = dict(\n    title=\"&lt;b&gt;Culmen Depth (mm) vs. Body Mass (g) for Adelie Penguin&lt;/b&gt;\",\n    showlegend=True,\n    xaxis=dict(title=\"Culmen Depth (mm)\"),\n    yaxis=dict(title=\"Body Mass (g)\"),\n    plot_bgcolor=\"rgba(0,0,0,0)\",\n    paper_bgcolor=\"rgba(0,0,0,0)\",\n)\n\nThe first two lines are used to set up the Plotly rendering so that the plots will properly display in JupyterNotebook. Lastly, we create a dictionary fig that includes both data as data and layout as layout. Then the plot is displayed with the line iplot(fig):\n\nimport plotly.io as pio\npio.renderers.default = 'notebook'\n\nfig = dict(data=data, layout=layout)\niplot(fig)\n\n                                                \n\n\n\n\n\n\nSince we are evaluating the Species and Sex variables for all species of penguins, we need to first define a new sub-dataframe that groups the two variables.\nThe following line calls the penguins dataframe and groups the rows from the dataframe based on the columns ‘Species’and ’Sex’. The feature .size() counts the size for each group. The feature .reset_index(name=‘count’) first resets the index of the newly structured dataframe then assigns a new column name count.\n\ngrouped_data = penguins.groupby(['Species', 'Sex']).size().reset_index(name='count')\n\nNow we need to clean the data. Notice how there are three categories for sex: MALE, FEMALE, and “.”\nSince “.” makes invalid information, we are dropping the rows with sex as “.” using the following line:\n\ngrouped_data = grouped_data[grouped_data['Sex'] != \".\"]\n\nSince we want to display the Species on the x-axis and the Sex stacked on the y-axis, we need to pivot the grouped_data using grouped_data.pivot, setting “Species” as the rows, “Sex” as columns, and the values as “count” (which is basically the frequency).\n\npivot_data = grouped_data.pivot(index='Species', columns='Sex', values='count')\n\nNow we plot the bar graph using .plot and setting the plot kind to “bar” and enabling stack with “stacked=True”.\nFor the following three lines, the plot’s x-label is set to “Species”, y-label as “Frequency”, and plot title as “Propotion of Sex by Species”.\nFinally, we run plt.show() to display the plot.\n\npivot_data.plot(kind='bar', stacked=True)\n\nplt.xlabel('Species')\nplt.ylabel('Frequency')\nplt.title('Propotion of Sex by Species')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nMatplotlib has a cool feature for color called colormap. Using the .plot.scatter function, we call the penguins dataframe and sets the x variable as ‘Culmen Length (mm)’ and the y variable as ‘Body Mass (g)’. Notice how another variable (‘Flipper Length (mm)’) is assigned to c. This is used as scale for the colormap. Lastly, the colormap is assigned as ‘viridis’.\nThe following lines, like seen previously, sets the title for the plot and displays it.\n\nax1 = penguins.plot.scatter(x='Culmen Length (mm)', y='Body Mass (g)', c = 'Flipper Length (mm)', colormap='viridis')\n\nplt.title('Culmen Length (mm) vs. Body Mass (g) for all Species')\n\nplt.show()"
  },
  {
    "objectID": "posts/Palmer-Penguins-data-visualization/Untitled.html#preparing-data",
    "href": "posts/Palmer-Penguins-data-visualization/Untitled.html#preparing-data",
    "title": "Palmer Penguins Data Visualization",
    "section": "",
    "text": "Begin by importing all the needed libraries. For databaset modifications, Pandas is required, while it will also be later used for visualization - along with Plotly and Matplotlib.\n\nimport pandas as pd\nfrom plotly import __version__\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nimport matplotlib.pyplot as plt\n\nWith the packages imported, we now read in the dataset (by using the provided url) and name it as penguins:\n\nurl = \"https://raw.githubusercontent.com/pic16b-ucla/24W/main/datasets/palmer_penguins.csv\"\npenguins = pd.read_csv(url)\n\nNow, specifically for the Species Adelie Penguin (Pygoscelis adeliae), we create a sub-dataframe named adelie_df that isolates data points for delie Penguins from the larger penguins dataframe:\n\nadelie_df = penguins[penguins[\"Species\"] == \"Adelie Penguin (Pygoscelis adeliae)\"].reset_index(drop=True)\nadelie_df.dropna()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n6\nPAL0708\n7\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN4A1\nNo\n11/15/07\n38.9\n17.8\n181.0\n3625.0\nFEMALE\n9.18718\n-25.21799\nNest never observed with full clutch.\n\n\n7\nPAL0708\n8\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN4A2\nNo\n11/15/07\n39.2\n19.6\n195.0\n4675.0\nMALE\n9.46060\n-24.89958\nNest never observed with full clutch.\n\n\n28\nPAL0708\n29\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN18A1\nNo\n11/10/07\n37.9\n18.6\n172.0\n3150.0\nFEMALE\n8.38404\n-25.19837\nNest never observed with full clutch.\n\n\n29\nPAL0708\n30\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN18A2\nNo\n11/10/07\n40.5\n18.9\n180.0\n3950.0\nMALE\n8.90027\n-25.11609\nNest never observed with full clutch.\n\n\n38\nPAL0708\n39\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nDream\nAdult, 1 Egg Stage\nN25A1\nNo\n11/13/07\n37.6\n19.3\n181.0\n3300.0\nFEMALE\n9.41131\n-25.04169\nNest never observed with full clutch.\n\n\n68\nPAL0809\n69\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN32A1\nNo\n11/11/08\n35.9\n16.6\n190.0\n3050.0\nFEMALE\n8.47781\n-26.07821\nNest never observed with full clutch.\n\n\n69\nPAL0809\n70\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN32A2\nNo\n11/11/08\n41.8\n19.4\n198.0\n4450.0\nMALE\n8.86853\n-26.06209\nNest never observed with full clutch.\n\n\n120\nPAL0910\n121\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN66A1\nNo\n11/17/09\n36.2\n17.2\n187.0\n3150.0\nFEMALE\n9.04296\n-26.19444\nNest never observed with full clutch.\n\n\n121\nPAL0910\n122\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN66A2\nNo\n11/17/09\n37.7\n19.8\n198.0\n3500.0\nMALE\n9.11066\n-26.42563\nNest never observed with full clutch.\n\n\n130\nPAL0910\n131\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN73A1\nNo\n11/23/09\n38.5\n17.9\n190.0\n3325.0\nFEMALE\n8.98460\n-25.57956\nNest never observed with full clutch.\n\n\n131\nPAL0910\n132\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN73A2\nNo\n11/23/09\n43.1\n19.2\n197.0\n3500.0\nMALE\n8.86495\n-26.13960\nNest never observed with full clutch.\n\n\n138\nPAL0910\n139\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nDream\nAdult, 1 Egg Stage\nN79A1\nNo\n11/16/09\n37.0\n16.5\n185.0\n3400.0\nFEMALE\n8.61651\n-26.07021\nNest never observed with full clutch.\n\n\n139\nPAL0910\n140\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nDream\nAdult, 1 Egg Stage\nN79A2\nNo\n11/16/09\n39.7\n17.9\n193.0\n4250.0\nMALE\n9.25769\n-25.88798\nNest never observed with full clutch.\n\n\n\n\n\n\n\nNote that the second line in the code block above drops rows for the adelie_df dataframe that includes NaN (incomplete data)."
  },
  {
    "objectID": "posts/Palmer-Penguins-data-visualization/Untitled.html#data-visualization",
    "href": "posts/Palmer-Penguins-data-visualization/Untitled.html#data-visualization",
    "title": "Palmer Penguins Data Visualization",
    "section": "",
    "text": "For plotly’s scatter plot, trace is a graph object that includes information about the graph’s x & y values, labels, and marker settings.\nThe following code block defines a new trace named trace1 which is specific to Adelie penguins using the adelie_df that we created before. It assigns “Culmen Length (mm) as the x values and Body Mass (g) as the y values.\nmode=“markers” specifies the drawing mode for the scatter plot. In this case, we are using markers.\nFor the line marker=dict(size=10, symbol=“circle”, line=dict(color=“rgb(0,0,0)”, width=0.5)), it defines the attribute marker (in the trace object) that specifies the design of the markers for the scatter plot. size is set to 10 pixels, and symbol is set to circle. line defines the marker’s outline, which is now black (“rgb(0,0,0)”) and has a width of 0.5.\nThe following line sets the marker color is set to black, and the line below that sets the label name to ““Adelie Penguin”.\n\ntrace1 = go.Scatter(\n    x=adelie_df[\"Culmen Length (mm)\"],\n    y=adelie_df[\"Body Mass (g)\"],\n    mode=\"markers\",\n    marker=dict(size=10, symbol=\"circle\", line=dict(color=\"rgb(0,0,0)\", width=0.5)),\n    marker_color=\"black\",\n    name=\"Adelie Penguin\",\n)\n\nNow we assigns the trace object to the variable data:\n\ndata = trace1\n\nAnd here we define the design for the plot. The title is set to “Culmen Depth (mm) vs. Body Mass (g) for Adelie Penguin” with the legend settings to “True” (which means to include it in the plot). The x-axis title is set to “Culmen Depth (mm)”, and the y-axis title is set to “Body Mass (g)”. The last two lines specifies that the background color for both plot area and the entire plot is transparent (“rgba(0,0,0,0)”).\n\nlayout = dict(\n    title=\"&lt;b&gt;Culmen Depth (mm) vs. Body Mass (g) for Adelie Penguin&lt;/b&gt;\",\n    showlegend=True,\n    xaxis=dict(title=\"Culmen Depth (mm)\"),\n    yaxis=dict(title=\"Body Mass (g)\"),\n    plot_bgcolor=\"rgba(0,0,0,0)\",\n    paper_bgcolor=\"rgba(0,0,0,0)\",\n)\n\nThe first two lines are used to set up the Plotly rendering so that the plots will properly display in JupyterNotebook. Lastly, we create a dictionary fig that includes both data as data and layout as layout. Then the plot is displayed with the line iplot(fig):\n\nimport plotly.io as pio\npio.renderers.default = 'notebook'\n\nfig = dict(data=data, layout=layout)\niplot(fig)"
  },
  {
    "objectID": "posts/Palmer-Penguins-data-visualization/Untitled.html#with-matplotlib-stacked-bar-plot-propotion-of-sex-by-species",
    "href": "posts/Palmer-Penguins-data-visualization/Untitled.html#with-matplotlib-stacked-bar-plot-propotion-of-sex-by-species",
    "title": "Palmer Penguins Data Visualization",
    "section": "",
    "text": "Since we are evaluating the Species and Sex variables for all species of penguins, we need to first define a new sub-dataframe that groups the two variables.\nThe following line calls the penguins dataframe and groups the rows from the dataframe based on the columns ‘Species’and ’Sex’. The feature .size() counts the size for each group. The feature .reset_index(name=‘count’) first resets the index of the newly structured dataframe then assigns a new column name count.\n\ngrouped_data = penguins.groupby(['Species', 'Sex']).size().reset_index(name='count')\n\nNow we need to clean the data. Notice how there are three categories for sex: MALE, FEMALE, and “.”\nSince “.” makes invalid information, we are dropping the rows with sex as “.” using the following line:\n\ngrouped_data = grouped_data[grouped_data['Sex'] != \".\"]\n\nSince we want to display the Species on the x-axis and the Sex stacked on the y-axis, we need to pivot the grouped_data using grouped_data.pivot, setting “Species” as the rows, “Sex” as columns, and the values as “count” (which is basically the frequency).\n\npivot_data = grouped_data.pivot(index='Species', columns='Sex', values='count')\n\nNow we plot the bar graph using .plot and setting the plot kind to “bar” and enabling stack with “stacked=True”.\nFor the following three lines, the plot’s x-label is set to “Species”, y-label as “Frequency”, and plot title as “Propotion of Sex by Species”.\nFinally, we run plt.show() to display the plot.\n\npivot_data.plot(kind='bar', stacked=True)\n\nplt.xlabel('Species')\nplt.ylabel('Frequency')\nplt.title('Propotion of Sex by Species')\n\nplt.show()"
  },
  {
    "objectID": "posts/Palmer-Penguins-data-visualization/Untitled.html#with-matplotlib-scatter-plot-culmen-length-mm-vs.-body-mass-g-for-all-species",
    "href": "posts/Palmer-Penguins-data-visualization/Untitled.html#with-matplotlib-scatter-plot-culmen-length-mm-vs.-body-mass-g-for-all-species",
    "title": "Palmer Penguins Data Visualization",
    "section": "",
    "text": "Matplotlib has a cool feature for color called colormap. Using the .plot.scatter function, we call the penguins dataframe and sets the x variable as ‘Culmen Length (mm)’ and the y variable as ‘Body Mass (g)’. Notice how another variable (‘Flipper Length (mm)’) is assigned to c. This is used as scale for the colormap. Lastly, the colormap is assigned as ‘viridis’.\nThe following lines, like seen previously, sets the title for the plot and displays it.\n\nax1 = penguins.plot.scatter(x='Culmen Length (mm)', y='Body Mass (g)', c = 'Flipper Length (mm)', colormap='viridis')\n\nplt.title('Culmen Length (mm) vs. Body Mass (g) for all Species')\n\nplt.show()"
  },
  {
    "objectID": "posts/Flask-Messages/HW3.html",
    "href": "posts/Flask-Messages/HW3.html",
    "title": "Flask Messages",
    "section": "",
    "text": "In this blog post, I will be presenting my project on creating a message website with Python Flask. It allows the user to input a message and their name - stored in a SQL database. The website then retrieves, randomly, “n” number of messages from the database to be displayed on the website.\n\n\nTo begin with, we will be focusing on the core script of the project: app.py. First, we import all the necessary libraries. Then we initialize the Flask application with a Flask application instance assigned to “app”.\nfrom flask import Flask, render_template, request, redirect, g\nimport sqlite3\nimport random\n\napp = Flask(__name__)\nNow the following first function get_message_db sets up our database. We use try-except to see if there is an existing g.message_db database, if not, we create one with the line “g.message_db = sqlite3.connect(”messages_db.sqlite”)” and using the cursor. Either way, the function returns the g.message_db database.\ndef get_message_db():\n    \"\"\"\n    retrieves the message database from the global context (g).\n    if does not exist, creates a new database and table.\n    returns g.message_db\n    \"\"\"\n    try:\n        return g.message_db\n    except AttributeError:\n        g.message_db = sqlite3.connect(\"messages_db.sqlite\")\n        cursor = g.message_db.cursor()\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS messages (\n                id INTEGER PRIMARY KEY,\n                handle TEXT,\n                message TEXT\n            )\n        ''')\n        return g.message_db\nThis following function insert_message assigns the user input to “message” and “username” to the variable message and handle. Then the connection is established with the database, and the user inputs are added to the messages table of the database using the cursor. The change is committed, and the connection is then closed.\ndef insert_message(request):\n    \"\"\"\n    inserts a message from the request form to the \"messages\" table\n    of database. The conn is opened beforehand, then closed.\n    returns the handle and message.\n    \"\"\"\n    message = request.form['message']\n    handle = request.form['username']\n    conn = get_message_db()\n    cursor = conn.cursor()\n    cursor.execute('''\n        INSERT INTO messages (handle, message) VALUES (?, ?)\n    ''', (handle, message))\n    conn.commit()\n    conn.close()\n    return handle, message\nThe following random_messages function is a helper function for selecting random messages (rows) from the database which we added to earlier. First, connection is formed with the database and the cursor is used to select from the messages table. We return a randomly selected “n” number of messages. This n value will be assigned a value in the following part of this blog.\ndef random_messages(n):\n    \"\"\"\n    connects to the database and selects a random message from\n    the database. then the connection is closed.\n    inputs \"n\" - number of messages to select\n    returns the randomly selected n number of messages\n    \"\"\"\n    conn = sqlite3.connect(\"messages_db.sqlite\")\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT handle, message FROM messages\")\n    messages = cursor.fetchall()\n    conn.close()\n    return random.sample(messages, min(n, len(messages)))\nThis is our final set-up function before really doing some Flask work. render_view_template calls the random_messages helper function to retrieve the selected function, given the n value of 5. The selected messages are then used to render the “view.html” template - which is used to display the messages on our website.\ndef render_view_template():\n    \"\"\"\n    calls the random_messages function and renders the\n    \"view.html\" template with the selected messages.\n    returns rendered template\n    \"\"\"\n    messages = random_messages(5)  # Grabbing up to 5 random messages\n    return render_template('view.html', messages=messages)\nThe following code beginning with “@app.route” defines the website’s different directories.\nStarting with ‘/view’, we use the view() function to return the function render_view_template that we defined previously to display the random messages.\nThen ‘/submit’ works with the submit.html template, which calls insert message requests for the user to enter their name (under handle) and their message (under message).\nLast but not least, the route ‘/’ just returns the text “home page”. While the last few lines checks for debug before running the app.\n@app.route('/view')\ndef view():\n    return render_view_template()\n\n@app.route('/submit', methods=['GET', 'POST'])\ndef submit():\n    if request.method == 'POST':\n        handle, message = insert_message(request)\n        return render_template('submit.html', submitted=True, handle=handle, message=message)\n    return render_template('submit.html')\n\n@app.route('/')\ndef home():\n    return \"Home Page\"\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "objectID": "posts/Flask-Messages/HW3.html#app.py",
    "href": "posts/Flask-Messages/HW3.html#app.py",
    "title": "Flask Messages",
    "section": "",
    "text": "To begin with, we will be focusing on the core script of the project: app.py. First, we import all the necessary libraries. Then we initialize the Flask application with a Flask application instance assigned to “app”.\nfrom flask import Flask, render_template, request, redirect, g\nimport sqlite3\nimport random\n\napp = Flask(__name__)\nNow the following first function get_message_db sets up our database. We use try-except to see if there is an existing g.message_db database, if not, we create one with the line “g.message_db = sqlite3.connect(”messages_db.sqlite”)” and using the cursor. Either way, the function returns the g.message_db database.\ndef get_message_db():\n    \"\"\"\n    retrieves the message database from the global context (g).\n    if does not exist, creates a new database and table.\n    returns g.message_db\n    \"\"\"\n    try:\n        return g.message_db\n    except AttributeError:\n        g.message_db = sqlite3.connect(\"messages_db.sqlite\")\n        cursor = g.message_db.cursor()\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS messages (\n                id INTEGER PRIMARY KEY,\n                handle TEXT,\n                message TEXT\n            )\n        ''')\n        return g.message_db\nThis following function insert_message assigns the user input to “message” and “username” to the variable message and handle. Then the connection is established with the database, and the user inputs are added to the messages table of the database using the cursor. The change is committed, and the connection is then closed.\ndef insert_message(request):\n    \"\"\"\n    inserts a message from the request form to the \"messages\" table\n    of database. The conn is opened beforehand, then closed.\n    returns the handle and message.\n    \"\"\"\n    message = request.form['message']\n    handle = request.form['username']\n    conn = get_message_db()\n    cursor = conn.cursor()\n    cursor.execute('''\n        INSERT INTO messages (handle, message) VALUES (?, ?)\n    ''', (handle, message))\n    conn.commit()\n    conn.close()\n    return handle, message\nThe following random_messages function is a helper function for selecting random messages (rows) from the database which we added to earlier. First, connection is formed with the database and the cursor is used to select from the messages table. We return a randomly selected “n” number of messages. This n value will be assigned a value in the following part of this blog.\ndef random_messages(n):\n    \"\"\"\n    connects to the database and selects a random message from\n    the database. then the connection is closed.\n    inputs \"n\" - number of messages to select\n    returns the randomly selected n number of messages\n    \"\"\"\n    conn = sqlite3.connect(\"messages_db.sqlite\")\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT handle, message FROM messages\")\n    messages = cursor.fetchall()\n    conn.close()\n    return random.sample(messages, min(n, len(messages)))\nThis is our final set-up function before really doing some Flask work. render_view_template calls the random_messages helper function to retrieve the selected function, given the n value of 5. The selected messages are then used to render the “view.html” template - which is used to display the messages on our website.\ndef render_view_template():\n    \"\"\"\n    calls the random_messages function and renders the\n    \"view.html\" template with the selected messages.\n    returns rendered template\n    \"\"\"\n    messages = random_messages(5)  # Grabbing up to 5 random messages\n    return render_template('view.html', messages=messages)\nThe following code beginning with “@app.route” defines the website’s different directories.\nStarting with ‘/view’, we use the view() function to return the function render_view_template that we defined previously to display the random messages.\nThen ‘/submit’ works with the submit.html template, which calls insert message requests for the user to enter their name (under handle) and their message (under message).\nLast but not least, the route ‘/’ just returns the text “home page”. While the last few lines checks for debug before running the app.\n@app.route('/view')\ndef view():\n    return render_view_template()\n\n@app.route('/submit', methods=['GET', 'POST'])\ndef submit():\n    if request.method == 'POST':\n        handle, message = insert_message(request)\n        return render_template('submit.html', submitted=True, handle=handle, message=message)\n    return render_template('submit.html')\n\n@app.route('/')\ndef home():\n    return \"Home Page\"\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "objectID": "posts/Flask-Messages/HW3.html#screenshots-of-app-functions",
    "href": "posts/Flask-Messages/HW3.html#screenshots-of-app-functions",
    "title": "Flask Messages",
    "section": "Screenshots of App Functions",
    "text": "Screenshots of App Functions\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/Screenshot1.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/Screenshot2.jpg')"
  },
  {
    "objectID": "posts/Flask-Messages/HW3.html#link-to-repository",
    "href": "posts/Flask-Messages/HW3.html#link-to-repository",
    "title": "Flask Messages",
    "section": "Link to Repository",
    "text": "Link to Repository\nhttps://github.com/Fishier1224/Flask-Message-Website-"
  },
  {
    "objectID": "posts/project/Project.html",
    "href": "posts/project/Project.html",
    "title": "Project - Chordy!",
    "section": "",
    "text": "This blog post is all about my PIC16B final project (working with Anika Misra and Isabella Woulfe).\nChordy is an interactive web app based on python Flask. With the support of MongoDB, Scrapy, and midiutil, Chordy allows users to search through the top 10 artists and their most known works to download a mid file of the song’s backtrack chords.\nOur project aims to address the problem of not finding clean karaoke background tracks with simply chords for songs by Top Ten Artists. Oftentimes, people want clean instrumental versions of songs that do not have additional background vocals, additional instruments, or have required ads that you need to watch before getting access to the karaoke backtrack. Oftentimes, musicians want to layer on their own instruments and their own vocals, and quickly need the chord sounds for the song—nothing else.\n\n\n\nSetup\nCode Structure\n\nScrapy\nFlask\nMusic Package\n\nChordy Interface\nData Flowchart\nConcluding Remarks\n\n\n\n\nThis is our git repository for the project: https://github.com/anikamisra/PIC16B-project\nBegin by cloning and unziping the repository in your local computer. Then open the project in your preferred IDE (I am using Pycharm and recommends it)\nAdd a file named .env with the database passwords next to app.py. The file should include and only include the following line:\nDB_PSWD=0YnrLGO4d5dxjtSc\nNow open terminal on your IDE and enter the following commands (note that you should be currently at the PIC16B-project directory):\ncd chord_scraper\nYou may need to\npython -m pip install \"pymongo [srv]\"\nor pip install any non-existsing (or not updated) packages - this depends on your current environment.\nWhen there is no warnings (and you are at the chord_scraper directory),\nls\nto check if you see app.py. If you do, run the following command:\nflask run\nYou should see something like this on your terminal (note that mongoDB connection works best when using UCLA WIFI, other connections may lead to timeout error):\n(PIC16B-24W) athena@Athenas-MacBook-Pro chord_scraper % flask run\nmongodb+srv://Chordy:0YnrLGO4d5dxjtSc@cluster0.pirmgae.mongodb.net/\nPinged your deployment. You successfully connected to MongoDB!\n * Debug mode: off\nWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n * Running on http://127.0.0.1:5000\nPress CTRL+C to quit\nNow you have Chordy running on http://127.0.0.1:5000!\n\n\n\nHere is a brief overview of the structure of our project (the ones marked with ** are ones that contain crucial code and I will talk about):\nPIC16B-project\n&gt; Chord_scraper\n&gt;&gt; chord_scraper\n&gt;&gt;&gt; chord_scraper\n&gt;&gt;&gt;&gt; spiders\n&gt;&gt;&gt;&gt;&gt; chord_spider.py**\n&gt;&gt;&gt;&gt; iterms.py\n&gt;&gt;&gt;&gt; middlewares.py\n&gt;&gt;&gt;&gt; pipelines.py\n&gt;&gt;&gt;&gt; settings.py\n&gt;&gt;&gt; (all csv files)\n&gt;&gt; templates\n&gt;&gt;&gt; create_account.html\n&gt;&gt;&gt; download.html\n&gt;&gt;&gt; index.html\n&gt;&gt;&gt; login.html\n&gt;&gt;&gt; SearchSong.html\n&gt;&gt;&gt; SearchWithArtist.html\n&gt;&gt; app.py**\n&gt;&gt; db.py**\n&gt;&gt; config.txt**\n&gt;&gt; makemusicpackages2.py\n&gt;&gt; .env\n&gt; .gitignore\n&gt; LICENSE\n&gt; README.md\n\n\n\n\n\nBefore we could start creating actual music, we needed to start with gathering our data through webscraping. After lots of research, we decided the best website to gather our data from would be Chordify.net. Chordify is a platform that allows musicians of all levels to learn how to play popular songs on either the guitar, ukulele, piano, or mandolin. From this website, we collected chords and bar lengths in the form of dictionaries, the url for each individual song, and the song titles in the form of a string.\nTo implement our scraper, we used both Scrapy and Selenium. The core of our scraper lies in the /PIC16B-project/chord_scraper/chord_scraper/chord_scraper/spiders/chord_spider.py file (see below).\nchord_spider.py begins with the necessary imports, including the Scrapy and Selenium libraries. We also imported specific modules required for using Firefox and Chrome browsers with Selenium. Following the imports, you will see commented terminal commands to run the scraper for individual artists, which we used to create our csv files.\nThe chord_scraper class is defined, inheriting from Scrapy’s Spider class. In the __init__ method, the artist’s name provided as an argument - formatted and used to construct the URL of the artist’s page on chordify.net. Then, a Selenium WebDriver instance is created using Chrome options with incognito mode and headless browsing enabled (to avoid detection).\nThe parse method is responsible for parsing the artist’s page. It loads the page using Selenium WebDriver, waits for it to fully load, and then extracts links to individual song pages. For each song, a new Scrapy request is made to the parse_song_url method.\nThe parse_song_url method parses individual song pages. It extracts the song’s title from the URL, then collects the chord information from the page. This includes the chord, bar length, and bar number. The chord information is stored in a dictionary with the bar number as the key and a tuple containing the chord and bar length as the value. Finally, the method yields a dictionary containing the song’s name, URL, and chord information.\nThe closed method is a callback that is executed when the spider is closed. It ensures that the Selenium WebDriver instance is properly closed to free up system resources.\nimport scrapy \nfrom selenium import webdriver\nfrom selenium.webdriver.firefox.options import Options\nfrom selenium.webdriver.chrome.options import Options as ChromeOptions\nfrom scrapy.selector import Selector\nfrom scrapy.http import Request\nimport time \n\n# HERE IS WHAT TO PUT IN THE TERMINAL: \n\n# top 10 artists US \n# scrapy crawl chord_scraper -o results.csv -a artistname=dua-lipa\n# scrapy crawl chord_scraper -o taylorswift.csv -a artistname=taylor-swift\n# scrapy crawl chord_scraper -o badbunny.csv -a artistname=bad-bunny\n# scrapy crawl chord_scraper -o theweeknd.csv -a artistname=the-weeknd\n# scrapy crawl chord_scraper -o drake.csv -a artistname=drake\n# scrapy crawl chord_scraper -o travisscott.csv -a artistname=travi-scott\n# scrapy crawl chord_scraper -o beyonce.csv -a artistname=beyonce\n# scrapy crawl chord_scraper -o michaeljackson.csv -a artistname=michael-jackson\n# scrapy crawl chord_scraper -o ladygaga.csv -a artistname=lady-gaga\n# scrapy crawl chord_scraper -o arianagrande.csv -a artistname=ariana-grande\n\n\nclass chord_scraper(scrapy.Spider): \n    name = 'chord_scraper'\n    \n    def __init__(self, artistname, *args, **kwargs): \n        super().__init__(*args, **kwargs)  \n        # format artist name properly \n        artistname_formatted = (\"-\".join(artistname.split())).lower()\n        \n        # form url of artist page \n        artist_page_url = \"https://chordify.net/chords/\"+artistname_formatted+\"-songs\"\n        # need to add an error catcher for if this artist page doesn't exist \n        self.start_urls = [artist_page_url]\n        \n        # firefox option: \n        #options = Options()\n        #options.headless = True\n        #firefox_profile = webdriver.FirefoxProfile()\n        #firefox_profile.set_preference(\"browser.privatebrowsing.autostart\", True)\n        #self.driver = webdriver.Firefox(options=options)\n        \n        # chrome option \n        options = ChromeOptions()\n        options.add_argument(\"--incognito\")\n        options.add_argument(\"--headless\")\n\n        self.driver = webdriver.Chrome(options=options)\n    def parse(self, response):\n        \"\"\"\n        Parses artist's page and returns url for each song. \n        Calls the parse_song_url function for each song page url. \n        \"\"\"\n        \n        self.driver.get(response.url) \n        # wait for page to load \n        time.sleep(5)\n        html = self.driver.page_source\n        sel = Selector(text=html) \n        # select the main div containing all the songs\n        main_div = sel.css('div.s1qyqb8i.g1aau9lx')\n        \n        for link in sel.css('div.s1qyqb8i.g1aau9lx a::attr(href)'):\n        # get the url for the songs \n            song_url = link.get()\n            base_url = \"https://chordify.net\" + song_url # hard-coded url is okay \n            # call next scraper for the songs \n            yield scrapy.Request(url = base_url, callback = self.parse_song_url)\n    def parse_song_url(self, response): \n        \"\"\"\n        Parses song page and yields dictionary of chords for each song. \n        Input is the song page from the first parse page. \n        Dictionary output contains bar number as key, and a tuple of (chord, bar length) for each value. \n        \"\"\"\n        self.driver.get(response.url)\n        # wait for page to load \n        time.sleep(5)\n        html = self.driver.page_source\n        sel = Selector(text=html)\n        \n        song_url = response.url\n        start = song_url.rfind(\"/\")\n        end = len(song_url) - 7 \n        song_title = song_url[start+1:end]\n        song_title = (song_title.replace('-', ' ')).title()\n\n        # use sel just like the response, just as we did with scrapy \n        div = sel.css('div.s4xyh0t &gt; div.chords')\n        barlength = div.css('::attr(class)').re_first('barlength-(\\d+)')\n        tags_with_i_value = div.css('[data-i]')\n        table = [{'i-value': tag.css('::attr(data-i)').get(), 'data-handle': tag.css('::attr(data-handle)').get(), 'barlength': barlength} for tag in tags_with_i_value]\n        \n        # create dicionary output for each song \n        dict_of_chords = dict()\n        for row in table: \n            i_value = row['i-value']\n            chord = row['data-handle']\n            barlength = row['barlength']\n            # make a dictionary that contains bar number in key and chord and bar length (tuple) in value. \n            dict_of_chords[i_value] = (chord, barlength) \n        # yield the result as a dictionary\n        yield {\n            'song_name': song_title,\n            'song_url': song_url,\n            'song_chords': dict_of_chords\n            }\n\n    def closed(self, reason):\n        \"\"\"\n        Closes the web driver. \n        \"\"\"\n        self.driver.quit()\n       \nHere is an overview of what one of our csv file looks like:\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/csv.jpg')\n\n\n\n\n\n\n\n\n\n\n\nFlask is the skeleton of Chordy - it serves as a bridge between the csv file, the server database, and the user interface. We used flask routes in app.py and helper functions from db.py (both located under /PIC16B-project/chord_scraper/) to construct such connections.\nThe following code sets up our Flask web application. First, the necessary imports are made. Flask is imported to create the web application, while other modules such as render_template, request, redirect, url_for, session, send_file, and jsonify are imported for handling web requests, sessions, file downloads, and JSON responses. Additionally, modules like Flask-CORS, subprocess, os, difflib, dotenv, pandas, and MIDIUtil are imported for specific functionalities such as handling CORS (Cross-origin resource sharing), executing subprocesses, working with files and directories, comparing strings, loading environment variables, data manipulation, and generating MIDI files.\nThe Flask application is created with Flask(__name__), and a secret key is generated for session management.\nA musicpackage() function is defined, which serves as the main function for processing music data. It reads chord data from a CSV file, converts chords to notes, and generates a MIDI file based on the chord progression. This function is designed to be called when the user requests to download a MIDI file. We will discuss this in more detail in PART THREE.\nHelper functions like read_csvpath_from_file(), read_index_from_file(), write_variable_to_file(), write_variable_to_file2(), and chords_to_notes() are defined to read/write values from/to config.txt file and to convert chord names to notes.\nThe Flask routes are then defined using @app.route() decorators. These routes handle various functionalities of the web application, including rendering HTML templates, handling user login, creating new user accounts, logging out users, searching for songs, downloading MIDI files, and searching for artists.\nThe index(), login(), create_account(), logout(), SearchSong(), download_file(), and SearchWithArtist() functions are defined to handle the corresponding routes. These functions interact with the user through HTML templates and process user inputs accordingly.\nFinally, the script checks if it’s being run directly (if __name__ == '__main__':) and starts the Flask application in debug mode if so.\nfrom flask import Flask, render_template, request, redirect, url_for, session, send_file\nfrom flask import jsonify\nfrom flask_cors import CORS\nimport subprocess\nimport os\nimport difflib\nfrom dotenv import load_dotenv\nfrom db import Database, User\nfrom midiutil import MIDIFile\nfrom mingus.core import chords\nimport ast\nimport pandas as pd\nfrom pychord import Chord\n\napp = Flask(__name__)\napp.secret_key = os.urandom(24)\n\nCORS(app, supports_credentials=True)\nload_dotenv(\".env\")\ndatabase = Database(os.getenv(\"DB_PSWD\"))\n\ndef musicpackage():\n    \"\"\"\n    Main function for processing music data.\n    Reads chords data from a CSV file, converts chords to notes,\n    and generates a MIDI file based on the chord progression.\n    \"\"\"\n\n    OCTAVES = list(range(11))\n    errors = {\n        'error!!!'\n    }\n    def read_csvpath_from_file():\n        \"\"\"\n        Reads from the config.txt file.\n        Returns the content of line named \"cs_path\"\n        \"\"\"\n        with open('config.txt', 'r') as file:\n            for line in file:\n                if line.startswith('csv_path'):\n                    variable_value = line.split('=')[1].strip().strip('\"')\n                    return variable_value\n        return None\n\n    def read_index_from_file():\n        \"\"\"\n         Reads from the config.txt file.\n         Returns the content of line named \"user_song\"\n         \"\"\"\n        with open('config.txt', 'r') as file:\n            for line in file:\n                if line.startswith('user_song'):\n                    variable_value = line.split('=')[1].strip().strip('\"')\n                    return variable_value\n        return None\n\n    csvpath = read_csvpath_from_file()\n    df = pd.read_csv(csvpath)\n    df.head()\n    df = pd.read_csv(csvpath)\n    index = read_index_from_file()\n    index = int(index)\n    song_name = df.iloc[index, 0]\n    chords_string = df.loc[df['song_name'] == song_name, 'song_chords'].values[0]\n\n    NOTES = ['C', 'C#', 'D', 'Eb', 'E', 'F', 'F#', 'G', 'Ab', 'A', 'Bb', 'B']\n    OCTAVES = list(range(11))\n    NOTES_IN_OCTAVE = len(NOTES)\n\n    chords = ast.literal_eval(chords_string)\n    extracted_strings = []\n\n    # iterate through dictionary values\n    for key, value in chords.items():\n        extracted_strings.append(value[0])  # Append the first element of the tuple\n\n    # get barlength\n    first_item = list(chords.keys())[0]\n    bar_length = chords[first_item][1]\n\n    # clean up webscraper code\n    original_list = extracted_strings\n    # Remove semicolons from each string\n    cleaned_list = [s.replace(':', '') for s in original_list]\n\n    def chords_to_notes(chord_list):\n        \"\"\"\n        Given a list of chord names, returns a list of corresponding notes.\n        \"\"\"\n        notes_list = []\n        for chord_name in chord_list:\n            if chord_name == 'N':\n                # Handle the special case of a rest\n                notes_list.append('')\n            else:\n                try:\n                    chord = Chord(chord_name)\n                    notes = chord.components()\n                    # Filter out numeric indices (only keep strings)\n                    notes = [note for note in notes if isinstance(note, str)]\n                    notes_list.extend(notes)\n                except ValueError:\n                    # Handle invalid chord names gracefully\n                    pass\n        return notes_list\n\n    chord_names = cleaned_list\n    resulting_notes = chords_to_notes(chord_names)\n\n    def swap_accidentals(note):\n        if note == 'Db':\n            return 'C#'\n        if note == 'D#':\n            return 'Eb'\n        if note == 'E#':\n            return 'F'\n        if note == 'Gb':\n            return 'F#'\n        if note == 'G#':\n            return 'Ab'\n        if note == 'A#':\n            return 'Bb'\n        if note == 'B#':\n            return 'C'\n\n        return note\n\n    def note_to_number(note: str, octave: int) -&gt; int:\n        note = swap_accidentals(note)\n        assert note in NOTES, errors['notes']\n        assert octave in OCTAVES, errors['notes']\n\n        note = NOTES.index(note)\n        note += (NOTES_IN_OCTAVE * octave)\n\n        assert 0 &lt;= note &lt;= 127, errors['notes']\n\n        return note\n\n    chord_progression = resulting_notes\n    i = 0\n\n    chord_progression = [chord for chord in chord_progression if chord.strip() != '']\n    print(\"chord progresion\", chord_progression)\n    array_of_notes = []\n    for note in chord_progression:\n        array_of_notes.append(note)\n    print(\"array of notes\", array_of_notes)\n    print(type(chord_progression[0]))\n\n    array_of_note_numbers = []\n    for note in array_of_notes:\n        OCTAVE = 4\n        array_of_note_numbers.append(note_to_number(note, OCTAVE))\n\n    track = 0\n    channel = 0\n    time = 0  # In beats\n    duration = 1  # In beats\n    tempo = 120 * int(bar_length)  # In BPM\n    volume = 100  # 0-127, as per the MIDI standard\n\n    MyMIDI = MIDIFile(1)  # One track, defaults to format 1 (tempo track is created\n    # automatically)\n    MyMIDI.addTempo(track, time, tempo)\n\n    for i, pitch in enumerate(array_of_note_numbers):\n        MyMIDI.addNote(track, channel, pitch, time + i, duration, volume)\n\n    with open(\"chord_scraper/yourmusic.mid\", \"wb\") as output_file:\n        MyMIDI.writeFile(output_file)\n\ndef write_variable_to_file(new_value):\n    \"\"\"\n       Writes a new value to the 'csv_path' variable in the config file.\n    \"\"\"\n    with open('config.txt', 'r+') as file:\n        lines = file.readlines()\n        file.seek(0)\n        for line in lines:\n            if line.startswith('csv_path'):\n                file.write(f'csv_path = \"{new_value}\"\\n')\n            else:\n                file.write(line)\n        file.truncate()\n\ndef write_variable_to_file2(new_value):\n    \"\"\"\n    Writes a new value to the 'user_song' variable in the config file.\n    \"\"\"\n    with open('config.txt', 'r+') as file:\n        lines = file.readlines()\n        file.seek(0)\n        for line in lines:\n            if line.startswith('user_song'):\n                file.write(f'user_song = \"{new_value}\"\\n')\n            else:\n                file.write(line)\n        file.truncate()\n\ndef read_csvpath_from_file():\n    \"\"\"\n    Reads the 'csv_path' variable value from the config file.\n    Returns None if the variable is not found.\n    \"\"\"\n    with open('config.txt', 'r') as file:\n        for line in file:\n            if line.startswith('csv_path'):\n                variable_value = line.split('=')[1].strip().strip('\"')\n                return variable_value\n    return None\n\n@app.route('/', methods=['GET', 'POST'])\ndef index():\n    \"\"\"\n    Renders the index page.\n    If the user is logged in, displays the username.\n    Redirects to the login page if the user is not logged in.\n    \"\"\"\n    if 'username' in session:\n        return render_template('index.html', username=session['username'])\n    else:\n        return redirect(url_for('login'))\n\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    \"\"\"\n    Handles the login functionality.\n    Validates user credentials and sets session username if valid.\n    Renders the login page with an error message if credentials are invalid.\n    \"\"\"\n    if request.method == 'POST':\n        username = request.form['username']\n        password = request.form['password']\n        if database.verify_user(username, password):\n            session['username'] = username\n            return redirect(url_for('index'))\n        else:\n            return render_template('login.html', error=\"Invalid username or password.\")\n    return render_template('login.html')\n\n@app.route('/createAccount', methods=['GET', 'POST'])\ndef create_account():\n    \"\"\"\n    Handles the creation of new user accounts.\n    Adds a new user to the database if the username is unique.\n    Renders the create account page with an error message if the username already exists.\n    \"\"\"\n    if request.method == 'POST':\n        username = request.form['username']\n        password = request.form['password']\n        if database.add_user(User(username, password)):\n            session['username'] = username\n            return redirect(url_for('index'))\n        else:\n            return render_template('create_account.html', error=\"Username already exists.\")\n    return render_template('create_account.html')\n\n@app.route('/logout')\ndef logout():\n    \"\"\"\n    Logs out the current user by removing the username from the session.\n    Redirects to the index page after logout.\n    \"\"\"\n    session.pop('username', None)\n    return redirect(url_for('index'))\n\n@app.route('/SearchSong', methods=['GET', 'POST'])\ndef SearchSong():\n    \"\"\"\n    Handles the search song functionality.\n    Retrieves the URL entered by the user and writes it to the config file.\n    Renders the search song page.\n    \"\"\"\n    if request.method == 'POST':\n        url = request.form['url']\n        write_variable_to_file2(url)\n    return render_template('SearchSong.html')\n\n@app.route('/download')\ndef download_file():\n    \"\"\"\n    Downloads the generated MIDI file to the user's device.\n    \"\"\"\n    musicpackage()\n    # Provide the path to the file you want to serve\n    file_path = 'chord_scraper/yourmusic.mid'\n    # Send the file to the user for download\n    return send_file(file_path)\n\n\n@app.route('/SearchWithArtist', methods=['GET', 'POST'])\ndef SearchWithArtist():\n    \"\"\"\n    Handles the search with artist functionality.\n    Retrieves the artist name entered by the user.\n    Searches for a matching CSV file based on the artist's name.\n    If found, displays the matching songs.\n    If not found, suggests similar artists or displays an error message.\n    Renders the search with artist page.\n    \"\"\"\n    if request.method == 'POST':\n        # Get the artist name from the form and format it properly\n        artist = request.form['artist'].lower().replace(' ', '')\n        # Search for the CSV file with the matching artist name\n        csv_file_path = os.path.join(os.getcwd(), 'chord_scraper', artist + '.csv')\n        if os.path.exists(csv_file_path):\n            write_variable_to_file(csv_file_path)\n            # Read the CSV file into a DataFrame\n            df = pd.read_csv(csv_file_path)\n            new_df = df.iloc[:, :1].copy()\n            result_data = []\n            for index, row in new_df.iterrows():\n                result_data.append(row.tolist())\n        else:\n            # Find the first artist whose name starts with the same character as the input artist's name\n            all_csv_files = [f[:-4] for f in os.listdir(os.path.join(os.getcwd(), 'chord_scraper')) if\n                             f.endswith('.csv')]\n            similar_artist = next((a for a in all_csv_files if a.startswith(artist[0])), None)\n            if similar_artist:\n                suggestion = similar_artist\n                error_message = f\"Couldn't find the artist in top 10. Did you mean {suggestion}?\"\n            else:\n                error_message = \"Couldn't find the artist in top 10. No similar artist found.\"\n            return render_template('SearchWithArtist.html', error_message=error_message)\n        return render_template('SearchWithArtist.html', result_data=result_data)\n    return render_template('SearchWithArtist.html')\n\n\nif __name__ == '__main__':\n    app.run(debug=True)\n\n\n\nNow I will introduce db.py which defines the User and Database class that is imported by app.py. db.py demonstrates basic CRUD operations (Create, Read, Update, Delete) with MongoDB using PyMongo in Python.\nThe User class represents a user with a username and password. It has an __init__ method that initializes a User object with the provided username and password.\nThe Database class represents a connection to a MongoDB database. Its __init__ method takes a MongoDB password as input and initializes a connection to the database using MongoClient from PyMongo. It constructs the MongoDB URI using the provided password and connects to the specified cluster. It also uses the ServerApi class to specify the server API version to be used. The class then attempts to ping the deployment to ensure a successful connection.\nThe add_user method of the Database class adds a new user to the MongoDB database. It first checks if the user already exists in the database by querying the users collection for the provided username. If the user does not exist, it inserts the user’s information into the database using insert_one method. The verify_user method of the Database class verifies the credentials of a user. It takes a username and password as input, queries the users collection for the provided username, and compares the password stored in the database with the provided password. If the credentials are valid, it returns True; otherwise, it returns False.\nfrom pymongo.mongo_client import MongoClient\nfrom pymongo.server_api import ServerApi\nfrom pymongo.errors import InvalidOperation\n\nclass User:\n    \"\"\"\n    Represents a user with a username and password.\n    \"\"\"\n    def __init__(self, username, password):\n        \"\"\"\n        Initializes a User object with the provided username and password.\n        Args:\n            username (str): The username of the user.\n            password (str): The password of the user.\n        \"\"\"\n        self.username = username\n        self.password = password\n\nclass Database:\n    \"\"\"\n    Represents a MongoDB database connection.\n    \"\"\"\n    def __init__(self, db_pswd):\n        \"\"\"\n        Initializes a Database object with the provided MongoDB password.\n        Args:\n            db_pswd (str): The MongoDB password.\n        \"\"\"\n        uri = f\"mongodb+srv://Chordy:{db_pswd}@cluster0.pirmgae.mongodb.net/\"\n        print(uri)\n        self.client = MongoClient(uri, server_api=ServerApi('1'))\n        self.db = self.client['cluster0']\n        try:\n            self.client.admin.command('ping')\n            print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n        except Exception as e:\n            print(\"db.py initialization error\")\n            print(e)\n\n    def add_user(self, user: User):\n        \"\"\"\n        Adds a new user to the MongoDB database.\n        Args:\n            user (User): The User object to be added to the database.\n        Returns:\n            bool: True if the user is successfully added, False otherwise.\n        \"\"\"\n        if self.db.users.find_one({\"username\": user.username}) is not None:\n            return False\n        else:\n            self.db.users.insert_one(vars(user))\n            return True\n\n    def verify_user(self, username, password):\n        \"\"\"\n        Verifies the credentials of a user.\n        Args:\n            username (str): The username to be verified.\n            password (str): The password to be verified.\n        Returns:\n            bool: True if the credentials are valid, False otherwise.\n        \"\"\"\n        user = self.db.users.find_one({\"username\": username})\n        if user:\n            if user[\"password\"] == password:\n                return True\n        return False\nEach time when you run flask run, a connection is opened to our unique MongoDB database. The MongoDB atlas connects to regional servers to setup operations. When a user submits a session (that relates to user credentials computation), database computing is called in flask through the db.py helper function and class objects - at run time, we interact with the dynamic database to achieve user login, login sessions, and creating an account.\nOn cloud.mongodb.com, this is how our MongoDB deployment and collection looks like in real time:\n\nImage(filename='/Users/athena/Desktop/hw6/mongodb.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/userCollection.jpg')\n\n\n\n\n\n\n\n\n\n\n\nTo avoid file calling error, we placed our music package code inside app.py as the function musicpackage(). This musicpackage() function serves as the main function for processing music data. It performs several tasks to convert chord data from a CSV file into a MIDI file.\nInitially, it reads the path to the CSV file containing chord data and the index of the song to be processed from a configuration file named config.txt. I added this portion to enable dynamic download generation according to the user input (see above section to learn more about how config.txt is changed dynamically). It then reads the CSV file using Pandas, extracts the chord string for the specified song, and converts it into a dictionary format using ast.literal_eval().\nNext, musicpackage() iterates through the chords dictionary to extract the chord names, cleans up the chord names by removing any semicolons, and then converts the chord names into corresponding notes using the chords_to_notes() function. This function utilizes the PyChord library to handle chord names and extract individual notes from them.\nThe function then converts the notes into MIDI note numbers by mapping them to the standard note frequencies and assigning them octave values. It also calculates the tempo for the MIDI file based on the bar length obtained from the chord data.\nFinally, it generates MIDI events for each note in the chord progression using the MIDIUtil library, specifying the track, channel, time, duration, and volume for each note. These MIDI events are written to a MIDI file named yourmusic.mid in the chord_scraper directory. To avoid memory overflow and having unneccesary storage occupied, I decided to name generated file as the static yourmusic.mid - this allows the program to overwrite the yourmusic.mid file each time the user requests to generate a new song.\n\ndef musicpackage():\n    \"\"\"\n    Main function for processing music data.\n    Reads chords data from a CSV file, converts chords to notes,\n    and generates a MIDI file based on the chord progression.\n    \"\"\"\n\n    OCTAVES = list(range(11))\n    errors = {\n        'error!!!'\n    }\n    def read_csvpath_from_file():\n        \"\"\"\n        Reads from the config.txt file.\n        Returns the content of line named \"cs_path\"\n        \"\"\"\n        with open('config.txt', 'r') as file:\n            for line in file:\n                if line.startswith('csv_path'):\n                    variable_value = line.split('=')[1].strip().strip('\"')\n                    return variable_value\n        return None\n\n    def read_index_from_file():\n        \"\"\"\n         Reads from the config.txt file.\n         Returns the content of line named \"user_song\"\n         \"\"\"\n        with open('config.txt', 'r') as file:\n            for line in file:\n                if line.startswith('user_song'):\n                    variable_value = line.split('=')[1].strip().strip('\"')\n                    return variable_value\n        return None\n\n    csvpath = read_csvpath_from_file()\n    df = pd.read_csv(csvpath)\n    df.head()\n    df = pd.read_csv(csvpath)\n    index = read_index_from_file()\n    index = int(index)\n    song_name = df.iloc[index, 0]\n    chords_string = df.loc[df['song_name'] == song_name, 'song_chords'].values[0]\n\n    NOTES = ['C', 'C#', 'D', 'Eb', 'E', 'F', 'F#', 'G', 'Ab', 'A', 'Bb', 'B']\n    OCTAVES = list(range(11))\n    NOTES_IN_OCTAVE = len(NOTES)\n\n    chords = ast.literal_eval(chords_string)\n    extracted_strings = []\n\n    # iterate through dictionary values\n    for key, value in chords.items():\n        extracted_strings.append(value[0])  # Append the first element of the tuple\n\n    # get barlength\n    first_item = list(chords.keys())[0]\n    bar_length = chords[first_item][1]\n\n    # clean up webscraper code\n    original_list = extracted_strings\n    # Remove semicolons from each string\n    cleaned_list = [s.replace(':', '') for s in original_list]\n\n    def chords_to_notes(chord_list):\n        \"\"\"\n        Given a list of chord names, returns a list of corresponding notes.\n        \"\"\"\n        notes_list = []\n        for chord_name in chord_list:\n            if chord_name == 'N':\n                # Handle the special case of a rest\n                notes_list.append('')\n            else:\n                try:\n                    chord = Chord(chord_name)\n                    notes = chord.components()\n                    # Filter out numeric indices (only keep strings)\n                    notes = [note for note in notes if isinstance(note, str)]\n                    notes_list.extend(notes)\n                except ValueError:\n                    # Handle invalid chord names gracefully\n                    pass\n        return notes_list\n\n    chord_names = cleaned_list\n    resulting_notes = chords_to_notes(chord_names)\n\n    def swap_accidentals(note):\n        if note == 'Db':\n            return 'C#'\n        if note == 'D#':\n            return 'Eb'\n        if note == 'E#':\n            return 'F'\n        if note == 'Gb':\n            return 'F#'\n        if note == 'G#':\n            return 'Ab'\n        if note == 'A#':\n            return 'Bb'\n        if note == 'B#':\n            return 'C'\n\n        return note\n\n    def note_to_number(note: str, octave: int) -&gt; int:\n        note = swap_accidentals(note)\n        assert note in NOTES, errors['notes']\n        assert octave in OCTAVES, errors['notes']\n\n        note = NOTES.index(note)\n        note += (NOTES_IN_OCTAVE * octave)\n\n        assert 0 &lt;= note &lt;= 127, errors['notes']\n\n        return note\n\n    chord_progression = resulting_notes\n    i = 0\n\n    chord_progression = [chord for chord in chord_progression if chord.strip() != '']\n    print(\"chord progresion\", chord_progression)\n    array_of_notes = []\n    for note in chord_progression:\n        array_of_notes.append(note)\n    print(\"array of notes\", array_of_notes)\n    print(type(chord_progression[0]))\n\n    array_of_note_numbers = []\n    for note in array_of_notes:\n        OCTAVE = 4\n        array_of_note_numbers.append(note_to_number(note, OCTAVE))\n\n    track = 0\n    channel = 0\n    time = 0  # In beats\n    duration = 1  # In beats\n    tempo = 120 * int(bar_length)  # In BPM\n    volume = 100  # 0-127, as per the MIDI standard\n\n    MyMIDI = MIDIFile(1)  # One track, defaults to format 1 (tempo track is created\n    # automatically)\n    MyMIDI.addTempo(track, time, tempo)\n\n    for i, pitch in enumerate(array_of_note_numbers):\n        MyMIDI.addNote(track, channel, pitch, time + i, duration, volume)\n\n    with open(\"chord_scraper/yourmusic.mid\", \"wb\") as output_file:\n        MyMIDI.writeFile(output_file)\n\n\n\n\n\n\nAll html templates that are needed for flask rendering are located under the /PIC16B-project/chord_scraper/templates/ directory. Here is an example (SearchWithArtist.html):\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;Scraper 2&lt;/title&gt;\n    &lt;style&gt;\n        body {\n            font-family: \"Gill Sans\", sans-serif;\n            background-color: #f0f0f0; /* Change background color to a light shade */\n            color: #333; /* Change text color */\n            margin: 0;\n            padding: 0;\n        }\n        h1 {\n            color: #f77f00; /* Change heading color */\n            text-align: center; /* Center align heading */\n        }\n        ul {\n            list-style-type: none; /* Remove bullet points from the list */\n            padding: 0;\n            margin: 0;\n            text-align: center; /* Center align list */\n        }\n        li {\n            margin-bottom: 10px;\n        }\n        li a {\n            display: block;\n            background-color: #f77f00; /* Change link background color */\n            color: #fff; /* Change link text color */\n            padding: 10px;\n            text-decoration: none;\n            border-radius: 5px;\n        }\n        li a:hover {\n            background-color: #f77f00; /* Darker shade on hover */\n        }\n        form {\n            background-color: #fff; /* Change form background color to white */\n            padding: 20px;\n            border-radius: 5px;\n            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1); /* Add a slight shadow effect */\n            text-align: center; /* Center align form */\n        }\n        label {\n            display: block;\n            margin-bottom: 10px;\n        }\n        input[type=\"text\"] {\n            width: 100%;\n            padding: 10px;\n            margin-bottom: 15px;\n            border: 1px solid #ccc;\n            border-radius: 4px;\n            box-sizing: border-box;\n        }\n        button[type=\"submit\"] {\n            background-color: #f77f00; /* Change submit button background color */\n            color: #fff; /* Change submit button text color */\n            padding: 10px 20px;\n            border: none;\n            border-radius: 4px;\n            cursor: pointer;\n        }\n        button[type=\"submit\"]:hover {\n            background-color: #f77f00; /* Darker shade on hover */\n        }\n        .error-message {\n            color: red; /* Change error message color */\n            text-align: center; /* Center align error message */\n        }\n        h2 {\n            text-align: center; /* Center align search results heading */\n        }\n        ol {\n            list-style-type: decimal; /* Use decimal numbering for ordered list */\n            padding-left: 20px; /* Add some padding to the left of the ordered list */\n        }\n        li {\n            margin-bottom: 5px; /* Reduce margin bottom for list items */\n        }\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Search With Artist&lt;/h1&gt;\n    &lt;ul&gt;\n        &lt;li&gt;&lt;a href=\"{{ url_for('SearchSong') }}\"&gt;Click here once you have noted down the index of artist's song&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n    &lt;form action=\"{{ url_for('SearchWithArtist') }}\" method=\"post\"&gt;\n        &lt;label for=\"artist\"&gt;Enter Artist Name:&lt;/label&gt;\n        &lt;input type=\"text\" id=\"artist\" name=\"artist\" required&gt;\n        &lt;button type=\"submit\"&gt;Search&lt;/button&gt;\n    &lt;/form&gt;\n    {% if error_message %}\n        &lt;p class=\"error-message\"&gt;{{ error_message }}&lt;/p&gt;\n    {% else %}\n        &lt;h2&gt;Search Results&lt;/h2&gt;\n        &lt;ol type=\"1\"&gt;\n            {% for line in result_data %}\n                &lt;li&gt;{{ line }}&lt;/li&gt;\n            {% endfor %}\n        &lt;/ol&gt;\n    {% endif %}\n&lt;/body&gt;\n&lt;/html&gt;\nSearchWithArtist.html starts with a heading “Search With Artist” followed by an unordered list containing a single link. The link redirects users to a separate page for entering the index of the artist’s song.\nBelow the list, there’s a form where users can input the artist’s name. The form includes a text input field for the artist’s name and a submit button labeled “Search”.\nThe HTML code also includes a conditional statement {% if error_message %} to display an error message if there is one. If there is no error message, the code displays the search results in an ordered list (&lt;ol&gt;) using decimal numbering. Each search result is displayed as a list item (&lt;li&gt;).\nThe styling of the page is defined within the &lt;style&gt; tags in the &lt;head&gt; section. It includes various CSS rules to customize the appearance of the page, such as setting the background color, text color, font, padding, margins, and border radius - I selected the color #f77f00 and the font \"Gill Sans\", sans-serif\", then made this styling consistent throughout the other htmls. Additionally, it styles the form elements, links, and error messages for a more user-friendly experience. Overall, the HTML code provides a clean and visually appealing interface for searching songs by artist.\n\nImage(filename='/Users/athena/Desktop/hw6/interface1.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/interface2.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/interface3.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/interface4.jpg')\n\n\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/errorhandling1.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/errorhandling2.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/errorhandling3.jpg')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/flowofdata.jpg')\n\n\n\n\n\n\n\n\n\n\n\nIn conclusion, Chordy represents a significant advancement in addressing the common frustration of accessing clean karaoke background tracks with simplified chords for songs by Top Ten Artists. By leveraging technologies such as Flask, Scrapy, midiutil, and MongoDB, Chordy provides users with a streamlined and intuitive platform to search for their desired songs and download MIDI files containing the song’s backtrack chords. This innovative solution not only enhances the accessibility of instrumental versions of popular songs but also empowers musicians to customize their performances by layering their own instruments and vocals seamlessly.\n\n\nChordy, undoubtedly offers a convenient and innovative solution for music enthusiasts by providing them with chord information scraped from Chordify.net and the ability to generate MIDI files for selected songs. However, it’s crucial to consider the ethical ramifications of such a project:\n\nData Scraping Ethics: Scraping data from websites raises ethical concerns, particularly regarding the Terms of Service (ToS) and potential copyright infringement. While some websites explicitly prohibit scraping in their ToS, others might have ambiguous or unclear policies. Respecting the terms and conditions of websites is essential to maintain ethical integrity and avoid legal consequences, but this is undermined in Chordy.\nIntellectual Property Rights: Chordy’s use of scraped chord information raises questions about intellectual property rights. Chordify.net likely holds copyrights or licenses for the chord information on their platform. By scraping and utilizing this data, Chordy, if deployed and put in mass use, may violate intellectual property rights.\nUser Privacy: Chordy’s interface for user searches and song selection involves handling user data. Chordy does not include user privacy policy upon account creation. In the future, it is crucial to prioritize user privacy and security, including implementing appropriate security measures (such as hashing user password or creating password checks - complex combination of numbers and alphabets) to protect user data from unauthorized access or misuse and being transparent with users about how their data will be used."
  },
  {
    "objectID": "posts/project/Project.html#table-of-contents",
    "href": "posts/project/Project.html#table-of-contents",
    "title": "Project - Chordy!",
    "section": "",
    "text": "Setup\nCode Structure\n\nScrapy\nFlask\nMusic Package\n\nChordy Interface\nData Flowchart\nConcluding Remarks"
  },
  {
    "objectID": "posts/project/Project.html#setup",
    "href": "posts/project/Project.html#setup",
    "title": "Project - Chordy!",
    "section": "",
    "text": "This is our git repository for the project: https://github.com/anikamisra/PIC16B-project\nBegin by cloning and unziping the repository in your local computer. Then open the project in your preferred IDE (I am using Pycharm and recommends it)\nAdd a file named .env with the database passwords next to app.py. The file should include and only include the following line:\nDB_PSWD=0YnrLGO4d5dxjtSc\nNow open terminal on your IDE and enter the following commands (note that you should be currently at the PIC16B-project directory):\ncd chord_scraper\nYou may need to\npython -m pip install \"pymongo [srv]\"\nor pip install any non-existsing (or not updated) packages - this depends on your current environment.\nWhen there is no warnings (and you are at the chord_scraper directory),\nls\nto check if you see app.py. If you do, run the following command:\nflask run\nYou should see something like this on your terminal (note that mongoDB connection works best when using UCLA WIFI, other connections may lead to timeout error):\n(PIC16B-24W) athena@Athenas-MacBook-Pro chord_scraper % flask run\nmongodb+srv://Chordy:0YnrLGO4d5dxjtSc@cluster0.pirmgae.mongodb.net/\nPinged your deployment. You successfully connected to MongoDB!\n * Debug mode: off\nWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n * Running on http://127.0.0.1:5000\nPress CTRL+C to quit\nNow you have Chordy running on http://127.0.0.1:5000!"
  },
  {
    "objectID": "posts/project/Project.html#code-structure",
    "href": "posts/project/Project.html#code-structure",
    "title": "Project - Chordy!",
    "section": "",
    "text": "Here is a brief overview of the structure of our project (the ones marked with ** are ones that contain crucial code and I will talk about):\nPIC16B-project\n&gt; Chord_scraper\n&gt;&gt; chord_scraper\n&gt;&gt;&gt; chord_scraper\n&gt;&gt;&gt;&gt; spiders\n&gt;&gt;&gt;&gt;&gt; chord_spider.py**\n&gt;&gt;&gt;&gt; iterms.py\n&gt;&gt;&gt;&gt; middlewares.py\n&gt;&gt;&gt;&gt; pipelines.py\n&gt;&gt;&gt;&gt; settings.py\n&gt;&gt;&gt; (all csv files)\n&gt;&gt; templates\n&gt;&gt;&gt; create_account.html\n&gt;&gt;&gt; download.html\n&gt;&gt;&gt; index.html\n&gt;&gt;&gt; login.html\n&gt;&gt;&gt; SearchSong.html\n&gt;&gt;&gt; SearchWithArtist.html\n&gt;&gt; app.py**\n&gt;&gt; db.py**\n&gt;&gt; config.txt**\n&gt;&gt; makemusicpackages2.py\n&gt;&gt; .env\n&gt; .gitignore\n&gt; LICENSE\n&gt; README.md"
  },
  {
    "objectID": "posts/project/Project.html#code-by-technical-features",
    "href": "posts/project/Project.html#code-by-technical-features",
    "title": "Project - Chordy!",
    "section": "",
    "text": "Before we could start creating actual music, we needed to start with gathering our data through webscraping. After lots of research, we decided the best website to gather our data from would be Chordify.net. Chordify is a platform that allows musicians of all levels to learn how to play popular songs on either the guitar, ukulele, piano, or mandolin. From this website, we collected chords and bar lengths in the form of dictionaries, the url for each individual song, and the song titles in the form of a string.\nTo implement our scraper, we used both Scrapy and Selenium. The core of our scraper lies in the /PIC16B-project/chord_scraper/chord_scraper/chord_scraper/spiders/chord_spider.py file (see below).\nchord_spider.py begins with the necessary imports, including the Scrapy and Selenium libraries. We also imported specific modules required for using Firefox and Chrome browsers with Selenium. Following the imports, you will see commented terminal commands to run the scraper for individual artists, which we used to create our csv files.\nThe chord_scraper class is defined, inheriting from Scrapy’s Spider class. In the __init__ method, the artist’s name provided as an argument - formatted and used to construct the URL of the artist’s page on chordify.net. Then, a Selenium WebDriver instance is created using Chrome options with incognito mode and headless browsing enabled (to avoid detection).\nThe parse method is responsible for parsing the artist’s page. It loads the page using Selenium WebDriver, waits for it to fully load, and then extracts links to individual song pages. For each song, a new Scrapy request is made to the parse_song_url method.\nThe parse_song_url method parses individual song pages. It extracts the song’s title from the URL, then collects the chord information from the page. This includes the chord, bar length, and bar number. The chord information is stored in a dictionary with the bar number as the key and a tuple containing the chord and bar length as the value. Finally, the method yields a dictionary containing the song’s name, URL, and chord information.\nThe closed method is a callback that is executed when the spider is closed. It ensures that the Selenium WebDriver instance is properly closed to free up system resources.\nimport scrapy \nfrom selenium import webdriver\nfrom selenium.webdriver.firefox.options import Options\nfrom selenium.webdriver.chrome.options import Options as ChromeOptions\nfrom scrapy.selector import Selector\nfrom scrapy.http import Request\nimport time \n\n# HERE IS WHAT TO PUT IN THE TERMINAL: \n\n# top 10 artists US \n# scrapy crawl chord_scraper -o results.csv -a artistname=dua-lipa\n# scrapy crawl chord_scraper -o taylorswift.csv -a artistname=taylor-swift\n# scrapy crawl chord_scraper -o badbunny.csv -a artistname=bad-bunny\n# scrapy crawl chord_scraper -o theweeknd.csv -a artistname=the-weeknd\n# scrapy crawl chord_scraper -o drake.csv -a artistname=drake\n# scrapy crawl chord_scraper -o travisscott.csv -a artistname=travi-scott\n# scrapy crawl chord_scraper -o beyonce.csv -a artistname=beyonce\n# scrapy crawl chord_scraper -o michaeljackson.csv -a artistname=michael-jackson\n# scrapy crawl chord_scraper -o ladygaga.csv -a artistname=lady-gaga\n# scrapy crawl chord_scraper -o arianagrande.csv -a artistname=ariana-grande\n\n\nclass chord_scraper(scrapy.Spider): \n    name = 'chord_scraper'\n    \n    def __init__(self, artistname, *args, **kwargs): \n        super().__init__(*args, **kwargs)  \n        # format artist name properly \n        artistname_formatted = (\"-\".join(artistname.split())).lower()\n        \n        # form url of artist page \n        artist_page_url = \"https://chordify.net/chords/\"+artistname_formatted+\"-songs\"\n        # need to add an error catcher for if this artist page doesn't exist \n        self.start_urls = [artist_page_url]\n        \n        # firefox option: \n        #options = Options()\n        #options.headless = True\n        #firefox_profile = webdriver.FirefoxProfile()\n        #firefox_profile.set_preference(\"browser.privatebrowsing.autostart\", True)\n        #self.driver = webdriver.Firefox(options=options)\n        \n        # chrome option \n        options = ChromeOptions()\n        options.add_argument(\"--incognito\")\n        options.add_argument(\"--headless\")\n\n        self.driver = webdriver.Chrome(options=options)\n    def parse(self, response):\n        \"\"\"\n        Parses artist's page and returns url for each song. \n        Calls the parse_song_url function for each song page url. \n        \"\"\"\n        \n        self.driver.get(response.url) \n        # wait for page to load \n        time.sleep(5)\n        html = self.driver.page_source\n        sel = Selector(text=html) \n        # select the main div containing all the songs\n        main_div = sel.css('div.s1qyqb8i.g1aau9lx')\n        \n        for link in sel.css('div.s1qyqb8i.g1aau9lx a::attr(href)'):\n        # get the url for the songs \n            song_url = link.get()\n            base_url = \"https://chordify.net\" + song_url # hard-coded url is okay \n            # call next scraper for the songs \n            yield scrapy.Request(url = base_url, callback = self.parse_song_url)\n    def parse_song_url(self, response): \n        \"\"\"\n        Parses song page and yields dictionary of chords for each song. \n        Input is the song page from the first parse page. \n        Dictionary output contains bar number as key, and a tuple of (chord, bar length) for each value. \n        \"\"\"\n        self.driver.get(response.url)\n        # wait for page to load \n        time.sleep(5)\n        html = self.driver.page_source\n        sel = Selector(text=html)\n        \n        song_url = response.url\n        start = song_url.rfind(\"/\")\n        end = len(song_url) - 7 \n        song_title = song_url[start+1:end]\n        song_title = (song_title.replace('-', ' ')).title()\n\n        # use sel just like the response, just as we did with scrapy \n        div = sel.css('div.s4xyh0t &gt; div.chords')\n        barlength = div.css('::attr(class)').re_first('barlength-(\\d+)')\n        tags_with_i_value = div.css('[data-i]')\n        table = [{'i-value': tag.css('::attr(data-i)').get(), 'data-handle': tag.css('::attr(data-handle)').get(), 'barlength': barlength} for tag in tags_with_i_value]\n        \n        # create dicionary output for each song \n        dict_of_chords = dict()\n        for row in table: \n            i_value = row['i-value']\n            chord = row['data-handle']\n            barlength = row['barlength']\n            # make a dictionary that contains bar number in key and chord and bar length (tuple) in value. \n            dict_of_chords[i_value] = (chord, barlength) \n        # yield the result as a dictionary\n        yield {\n            'song_name': song_title,\n            'song_url': song_url,\n            'song_chords': dict_of_chords\n            }\n\n    def closed(self, reason):\n        \"\"\"\n        Closes the web driver. \n        \"\"\"\n        self.driver.quit()\n       \nHere is an overview of what one of our csv file looks like:\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/csv.jpg')\n\n\n\n\n\n\n\n\n\n\n\nFlask is the skeleton of Chordy - it serves as a bridge between the csv file, the server database, and the user interface. We used flask routes in app.py and helper functions from db.py (both located under /PIC16B-project/chord_scraper/) to construct such connections.\nThe following code sets up our Flask web application. First, the necessary imports are made. Flask is imported to create the web application, while other modules such as render_template, request, redirect, url_for, session, send_file, and jsonify are imported for handling web requests, sessions, file downloads, and JSON responses. Additionally, modules like Flask-CORS, subprocess, os, difflib, dotenv, pandas, and MIDIUtil are imported for specific functionalities such as handling CORS (Cross-origin resource sharing), executing subprocesses, working with files and directories, comparing strings, loading environment variables, data manipulation, and generating MIDI files.\nThe Flask application is created with Flask(__name__), and a secret key is generated for session management.\nA musicpackage() function is defined, which serves as the main function for processing music data. It reads chord data from a CSV file, converts chords to notes, and generates a MIDI file based on the chord progression. This function is designed to be called when the user requests to download a MIDI file. We will discuss this in more detail in PART THREE.\nHelper functions like read_csvpath_from_file(), read_index_from_file(), write_variable_to_file(), write_variable_to_file2(), and chords_to_notes() are defined to read/write values from/to config.txt file and to convert chord names to notes.\nThe Flask routes are then defined using @app.route() decorators. These routes handle various functionalities of the web application, including rendering HTML templates, handling user login, creating new user accounts, logging out users, searching for songs, downloading MIDI files, and searching for artists.\nThe index(), login(), create_account(), logout(), SearchSong(), download_file(), and SearchWithArtist() functions are defined to handle the corresponding routes. These functions interact with the user through HTML templates and process user inputs accordingly.\nFinally, the script checks if it’s being run directly (if __name__ == '__main__':) and starts the Flask application in debug mode if so.\nfrom flask import Flask, render_template, request, redirect, url_for, session, send_file\nfrom flask import jsonify\nfrom flask_cors import CORS\nimport subprocess\nimport os\nimport difflib\nfrom dotenv import load_dotenv\nfrom db import Database, User\nfrom midiutil import MIDIFile\nfrom mingus.core import chords\nimport ast\nimport pandas as pd\nfrom pychord import Chord\n\napp = Flask(__name__)\napp.secret_key = os.urandom(24)\n\nCORS(app, supports_credentials=True)\nload_dotenv(\".env\")\ndatabase = Database(os.getenv(\"DB_PSWD\"))\n\ndef musicpackage():\n    \"\"\"\n    Main function for processing music data.\n    Reads chords data from a CSV file, converts chords to notes,\n    and generates a MIDI file based on the chord progression.\n    \"\"\"\n\n    OCTAVES = list(range(11))\n    errors = {\n        'error!!!'\n    }\n    def read_csvpath_from_file():\n        \"\"\"\n        Reads from the config.txt file.\n        Returns the content of line named \"cs_path\"\n        \"\"\"\n        with open('config.txt', 'r') as file:\n            for line in file:\n                if line.startswith('csv_path'):\n                    variable_value = line.split('=')[1].strip().strip('\"')\n                    return variable_value\n        return None\n\n    def read_index_from_file():\n        \"\"\"\n         Reads from the config.txt file.\n         Returns the content of line named \"user_song\"\n         \"\"\"\n        with open('config.txt', 'r') as file:\n            for line in file:\n                if line.startswith('user_song'):\n                    variable_value = line.split('=')[1].strip().strip('\"')\n                    return variable_value\n        return None\n\n    csvpath = read_csvpath_from_file()\n    df = pd.read_csv(csvpath)\n    df.head()\n    df = pd.read_csv(csvpath)\n    index = read_index_from_file()\n    index = int(index)\n    song_name = df.iloc[index, 0]\n    chords_string = df.loc[df['song_name'] == song_name, 'song_chords'].values[0]\n\n    NOTES = ['C', 'C#', 'D', 'Eb', 'E', 'F', 'F#', 'G', 'Ab', 'A', 'Bb', 'B']\n    OCTAVES = list(range(11))\n    NOTES_IN_OCTAVE = len(NOTES)\n\n    chords = ast.literal_eval(chords_string)\n    extracted_strings = []\n\n    # iterate through dictionary values\n    for key, value in chords.items():\n        extracted_strings.append(value[0])  # Append the first element of the tuple\n\n    # get barlength\n    first_item = list(chords.keys())[0]\n    bar_length = chords[first_item][1]\n\n    # clean up webscraper code\n    original_list = extracted_strings\n    # Remove semicolons from each string\n    cleaned_list = [s.replace(':', '') for s in original_list]\n\n    def chords_to_notes(chord_list):\n        \"\"\"\n        Given a list of chord names, returns a list of corresponding notes.\n        \"\"\"\n        notes_list = []\n        for chord_name in chord_list:\n            if chord_name == 'N':\n                # Handle the special case of a rest\n                notes_list.append('')\n            else:\n                try:\n                    chord = Chord(chord_name)\n                    notes = chord.components()\n                    # Filter out numeric indices (only keep strings)\n                    notes = [note for note in notes if isinstance(note, str)]\n                    notes_list.extend(notes)\n                except ValueError:\n                    # Handle invalid chord names gracefully\n                    pass\n        return notes_list\n\n    chord_names = cleaned_list\n    resulting_notes = chords_to_notes(chord_names)\n\n    def swap_accidentals(note):\n        if note == 'Db':\n            return 'C#'\n        if note == 'D#':\n            return 'Eb'\n        if note == 'E#':\n            return 'F'\n        if note == 'Gb':\n            return 'F#'\n        if note == 'G#':\n            return 'Ab'\n        if note == 'A#':\n            return 'Bb'\n        if note == 'B#':\n            return 'C'\n\n        return note\n\n    def note_to_number(note: str, octave: int) -&gt; int:\n        note = swap_accidentals(note)\n        assert note in NOTES, errors['notes']\n        assert octave in OCTAVES, errors['notes']\n\n        note = NOTES.index(note)\n        note += (NOTES_IN_OCTAVE * octave)\n\n        assert 0 &lt;= note &lt;= 127, errors['notes']\n\n        return note\n\n    chord_progression = resulting_notes\n    i = 0\n\n    chord_progression = [chord for chord in chord_progression if chord.strip() != '']\n    print(\"chord progresion\", chord_progression)\n    array_of_notes = []\n    for note in chord_progression:\n        array_of_notes.append(note)\n    print(\"array of notes\", array_of_notes)\n    print(type(chord_progression[0]))\n\n    array_of_note_numbers = []\n    for note in array_of_notes:\n        OCTAVE = 4\n        array_of_note_numbers.append(note_to_number(note, OCTAVE))\n\n    track = 0\n    channel = 0\n    time = 0  # In beats\n    duration = 1  # In beats\n    tempo = 120 * int(bar_length)  # In BPM\n    volume = 100  # 0-127, as per the MIDI standard\n\n    MyMIDI = MIDIFile(1)  # One track, defaults to format 1 (tempo track is created\n    # automatically)\n    MyMIDI.addTempo(track, time, tempo)\n\n    for i, pitch in enumerate(array_of_note_numbers):\n        MyMIDI.addNote(track, channel, pitch, time + i, duration, volume)\n\n    with open(\"chord_scraper/yourmusic.mid\", \"wb\") as output_file:\n        MyMIDI.writeFile(output_file)\n\ndef write_variable_to_file(new_value):\n    \"\"\"\n       Writes a new value to the 'csv_path' variable in the config file.\n    \"\"\"\n    with open('config.txt', 'r+') as file:\n        lines = file.readlines()\n        file.seek(0)\n        for line in lines:\n            if line.startswith('csv_path'):\n                file.write(f'csv_path = \"{new_value}\"\\n')\n            else:\n                file.write(line)\n        file.truncate()\n\ndef write_variable_to_file2(new_value):\n    \"\"\"\n    Writes a new value to the 'user_song' variable in the config file.\n    \"\"\"\n    with open('config.txt', 'r+') as file:\n        lines = file.readlines()\n        file.seek(0)\n        for line in lines:\n            if line.startswith('user_song'):\n                file.write(f'user_song = \"{new_value}\"\\n')\n            else:\n                file.write(line)\n        file.truncate()\n\ndef read_csvpath_from_file():\n    \"\"\"\n    Reads the 'csv_path' variable value from the config file.\n    Returns None if the variable is not found.\n    \"\"\"\n    with open('config.txt', 'r') as file:\n        for line in file:\n            if line.startswith('csv_path'):\n                variable_value = line.split('=')[1].strip().strip('\"')\n                return variable_value\n    return None\n\n@app.route('/', methods=['GET', 'POST'])\ndef index():\n    \"\"\"\n    Renders the index page.\n    If the user is logged in, displays the username.\n    Redirects to the login page if the user is not logged in.\n    \"\"\"\n    if 'username' in session:\n        return render_template('index.html', username=session['username'])\n    else:\n        return redirect(url_for('login'))\n\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    \"\"\"\n    Handles the login functionality.\n    Validates user credentials and sets session username if valid.\n    Renders the login page with an error message if credentials are invalid.\n    \"\"\"\n    if request.method == 'POST':\n        username = request.form['username']\n        password = request.form['password']\n        if database.verify_user(username, password):\n            session['username'] = username\n            return redirect(url_for('index'))\n        else:\n            return render_template('login.html', error=\"Invalid username or password.\")\n    return render_template('login.html')\n\n@app.route('/createAccount', methods=['GET', 'POST'])\ndef create_account():\n    \"\"\"\n    Handles the creation of new user accounts.\n    Adds a new user to the database if the username is unique.\n    Renders the create account page with an error message if the username already exists.\n    \"\"\"\n    if request.method == 'POST':\n        username = request.form['username']\n        password = request.form['password']\n        if database.add_user(User(username, password)):\n            session['username'] = username\n            return redirect(url_for('index'))\n        else:\n            return render_template('create_account.html', error=\"Username already exists.\")\n    return render_template('create_account.html')\n\n@app.route('/logout')\ndef logout():\n    \"\"\"\n    Logs out the current user by removing the username from the session.\n    Redirects to the index page after logout.\n    \"\"\"\n    session.pop('username', None)\n    return redirect(url_for('index'))\n\n@app.route('/SearchSong', methods=['GET', 'POST'])\ndef SearchSong():\n    \"\"\"\n    Handles the search song functionality.\n    Retrieves the URL entered by the user and writes it to the config file.\n    Renders the search song page.\n    \"\"\"\n    if request.method == 'POST':\n        url = request.form['url']\n        write_variable_to_file2(url)\n    return render_template('SearchSong.html')\n\n@app.route('/download')\ndef download_file():\n    \"\"\"\n    Downloads the generated MIDI file to the user's device.\n    \"\"\"\n    musicpackage()\n    # Provide the path to the file you want to serve\n    file_path = 'chord_scraper/yourmusic.mid'\n    # Send the file to the user for download\n    return send_file(file_path)\n\n\n@app.route('/SearchWithArtist', methods=['GET', 'POST'])\ndef SearchWithArtist():\n    \"\"\"\n    Handles the search with artist functionality.\n    Retrieves the artist name entered by the user.\n    Searches for a matching CSV file based on the artist's name.\n    If found, displays the matching songs.\n    If not found, suggests similar artists or displays an error message.\n    Renders the search with artist page.\n    \"\"\"\n    if request.method == 'POST':\n        # Get the artist name from the form and format it properly\n        artist = request.form['artist'].lower().replace(' ', '')\n        # Search for the CSV file with the matching artist name\n        csv_file_path = os.path.join(os.getcwd(), 'chord_scraper', artist + '.csv')\n        if os.path.exists(csv_file_path):\n            write_variable_to_file(csv_file_path)\n            # Read the CSV file into a DataFrame\n            df = pd.read_csv(csv_file_path)\n            new_df = df.iloc[:, :1].copy()\n            result_data = []\n            for index, row in new_df.iterrows():\n                result_data.append(row.tolist())\n        else:\n            # Find the first artist whose name starts with the same character as the input artist's name\n            all_csv_files = [f[:-4] for f in os.listdir(os.path.join(os.getcwd(), 'chord_scraper')) if\n                             f.endswith('.csv')]\n            similar_artist = next((a for a in all_csv_files if a.startswith(artist[0])), None)\n            if similar_artist:\n                suggestion = similar_artist\n                error_message = f\"Couldn't find the artist in top 10. Did you mean {suggestion}?\"\n            else:\n                error_message = \"Couldn't find the artist in top 10. No similar artist found.\"\n            return render_template('SearchWithArtist.html', error_message=error_message)\n        return render_template('SearchWithArtist.html', result_data=result_data)\n    return render_template('SearchWithArtist.html')\n\n\nif __name__ == '__main__':\n    app.run(debug=True)\n\n\n\nNow I will introduce db.py which defines the User and Database class that is imported by app.py. db.py demonstrates basic CRUD operations (Create, Read, Update, Delete) with MongoDB using PyMongo in Python.\nThe User class represents a user with a username and password. It has an __init__ method that initializes a User object with the provided username and password.\nThe Database class represents a connection to a MongoDB database. Its __init__ method takes a MongoDB password as input and initializes a connection to the database using MongoClient from PyMongo. It constructs the MongoDB URI using the provided password and connects to the specified cluster. It also uses the ServerApi class to specify the server API version to be used. The class then attempts to ping the deployment to ensure a successful connection.\nThe add_user method of the Database class adds a new user to the MongoDB database. It first checks if the user already exists in the database by querying the users collection for the provided username. If the user does not exist, it inserts the user’s information into the database using insert_one method. The verify_user method of the Database class verifies the credentials of a user. It takes a username and password as input, queries the users collection for the provided username, and compares the password stored in the database with the provided password. If the credentials are valid, it returns True; otherwise, it returns False.\nfrom pymongo.mongo_client import MongoClient\nfrom pymongo.server_api import ServerApi\nfrom pymongo.errors import InvalidOperation\n\nclass User:\n    \"\"\"\n    Represents a user with a username and password.\n    \"\"\"\n    def __init__(self, username, password):\n        \"\"\"\n        Initializes a User object with the provided username and password.\n        Args:\n            username (str): The username of the user.\n            password (str): The password of the user.\n        \"\"\"\n        self.username = username\n        self.password = password\n\nclass Database:\n    \"\"\"\n    Represents a MongoDB database connection.\n    \"\"\"\n    def __init__(self, db_pswd):\n        \"\"\"\n        Initializes a Database object with the provided MongoDB password.\n        Args:\n            db_pswd (str): The MongoDB password.\n        \"\"\"\n        uri = f\"mongodb+srv://Chordy:{db_pswd}@cluster0.pirmgae.mongodb.net/\"\n        print(uri)\n        self.client = MongoClient(uri, server_api=ServerApi('1'))\n        self.db = self.client['cluster0']\n        try:\n            self.client.admin.command('ping')\n            print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n        except Exception as e:\n            print(\"db.py initialization error\")\n            print(e)\n\n    def add_user(self, user: User):\n        \"\"\"\n        Adds a new user to the MongoDB database.\n        Args:\n            user (User): The User object to be added to the database.\n        Returns:\n            bool: True if the user is successfully added, False otherwise.\n        \"\"\"\n        if self.db.users.find_one({\"username\": user.username}) is not None:\n            return False\n        else:\n            self.db.users.insert_one(vars(user))\n            return True\n\n    def verify_user(self, username, password):\n        \"\"\"\n        Verifies the credentials of a user.\n        Args:\n            username (str): The username to be verified.\n            password (str): The password to be verified.\n        Returns:\n            bool: True if the credentials are valid, False otherwise.\n        \"\"\"\n        user = self.db.users.find_one({\"username\": username})\n        if user:\n            if user[\"password\"] == password:\n                return True\n        return False\nEach time when you run flask run, a connection is opened to our unique MongoDB database. The MongoDB atlas connects to regional servers to setup operations. When a user submits a session (that relates to user credentials computation), database computing is called in flask through the db.py helper function and class objects - at run time, we interact with the dynamic database to achieve user login, login sessions, and creating an account.\nOn cloud.mongodb.com, this is how our MongoDB deployment and collection looks like in real time:\n\nImage(filename='/Users/athena/Desktop/hw6/mongodb.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/userCollection.jpg')\n\n\n\n\n\n\n\n\n\n\n\nTo avoid file calling error, we placed our music package code inside app.py as the function musicpackage(). This musicpackage() function serves as the main function for processing music data. It performs several tasks to convert chord data from a CSV file into a MIDI file.\nInitially, it reads the path to the CSV file containing chord data and the index of the song to be processed from a configuration file named config.txt. I added this portion to enable dynamic download generation according to the user input (see above section to learn more about how config.txt is changed dynamically). It then reads the CSV file using Pandas, extracts the chord string for the specified song, and converts it into a dictionary format using ast.literal_eval().\nNext, musicpackage() iterates through the chords dictionary to extract the chord names, cleans up the chord names by removing any semicolons, and then converts the chord names into corresponding notes using the chords_to_notes() function. This function utilizes the PyChord library to handle chord names and extract individual notes from them.\nThe function then converts the notes into MIDI note numbers by mapping them to the standard note frequencies and assigning them octave values. It also calculates the tempo for the MIDI file based on the bar length obtained from the chord data.\nFinally, it generates MIDI events for each note in the chord progression using the MIDIUtil library, specifying the track, channel, time, duration, and volume for each note. These MIDI events are written to a MIDI file named yourmusic.mid in the chord_scraper directory. To avoid memory overflow and having unneccesary storage occupied, I decided to name generated file as the static yourmusic.mid - this allows the program to overwrite the yourmusic.mid file each time the user requests to generate a new song.\n\ndef musicpackage():\n    \"\"\"\n    Main function for processing music data.\n    Reads chords data from a CSV file, converts chords to notes,\n    and generates a MIDI file based on the chord progression.\n    \"\"\"\n\n    OCTAVES = list(range(11))\n    errors = {\n        'error!!!'\n    }\n    def read_csvpath_from_file():\n        \"\"\"\n        Reads from the config.txt file.\n        Returns the content of line named \"cs_path\"\n        \"\"\"\n        with open('config.txt', 'r') as file:\n            for line in file:\n                if line.startswith('csv_path'):\n                    variable_value = line.split('=')[1].strip().strip('\"')\n                    return variable_value\n        return None\n\n    def read_index_from_file():\n        \"\"\"\n         Reads from the config.txt file.\n         Returns the content of line named \"user_song\"\n         \"\"\"\n        with open('config.txt', 'r') as file:\n            for line in file:\n                if line.startswith('user_song'):\n                    variable_value = line.split('=')[1].strip().strip('\"')\n                    return variable_value\n        return None\n\n    csvpath = read_csvpath_from_file()\n    df = pd.read_csv(csvpath)\n    df.head()\n    df = pd.read_csv(csvpath)\n    index = read_index_from_file()\n    index = int(index)\n    song_name = df.iloc[index, 0]\n    chords_string = df.loc[df['song_name'] == song_name, 'song_chords'].values[0]\n\n    NOTES = ['C', 'C#', 'D', 'Eb', 'E', 'F', 'F#', 'G', 'Ab', 'A', 'Bb', 'B']\n    OCTAVES = list(range(11))\n    NOTES_IN_OCTAVE = len(NOTES)\n\n    chords = ast.literal_eval(chords_string)\n    extracted_strings = []\n\n    # iterate through dictionary values\n    for key, value in chords.items():\n        extracted_strings.append(value[0])  # Append the first element of the tuple\n\n    # get barlength\n    first_item = list(chords.keys())[0]\n    bar_length = chords[first_item][1]\n\n    # clean up webscraper code\n    original_list = extracted_strings\n    # Remove semicolons from each string\n    cleaned_list = [s.replace(':', '') for s in original_list]\n\n    def chords_to_notes(chord_list):\n        \"\"\"\n        Given a list of chord names, returns a list of corresponding notes.\n        \"\"\"\n        notes_list = []\n        for chord_name in chord_list:\n            if chord_name == 'N':\n                # Handle the special case of a rest\n                notes_list.append('')\n            else:\n                try:\n                    chord = Chord(chord_name)\n                    notes = chord.components()\n                    # Filter out numeric indices (only keep strings)\n                    notes = [note for note in notes if isinstance(note, str)]\n                    notes_list.extend(notes)\n                except ValueError:\n                    # Handle invalid chord names gracefully\n                    pass\n        return notes_list\n\n    chord_names = cleaned_list\n    resulting_notes = chords_to_notes(chord_names)\n\n    def swap_accidentals(note):\n        if note == 'Db':\n            return 'C#'\n        if note == 'D#':\n            return 'Eb'\n        if note == 'E#':\n            return 'F'\n        if note == 'Gb':\n            return 'F#'\n        if note == 'G#':\n            return 'Ab'\n        if note == 'A#':\n            return 'Bb'\n        if note == 'B#':\n            return 'C'\n\n        return note\n\n    def note_to_number(note: str, octave: int) -&gt; int:\n        note = swap_accidentals(note)\n        assert note in NOTES, errors['notes']\n        assert octave in OCTAVES, errors['notes']\n\n        note = NOTES.index(note)\n        note += (NOTES_IN_OCTAVE * octave)\n\n        assert 0 &lt;= note &lt;= 127, errors['notes']\n\n        return note\n\n    chord_progression = resulting_notes\n    i = 0\n\n    chord_progression = [chord for chord in chord_progression if chord.strip() != '']\n    print(\"chord progresion\", chord_progression)\n    array_of_notes = []\n    for note in chord_progression:\n        array_of_notes.append(note)\n    print(\"array of notes\", array_of_notes)\n    print(type(chord_progression[0]))\n\n    array_of_note_numbers = []\n    for note in array_of_notes:\n        OCTAVE = 4\n        array_of_note_numbers.append(note_to_number(note, OCTAVE))\n\n    track = 0\n    channel = 0\n    time = 0  # In beats\n    duration = 1  # In beats\n    tempo = 120 * int(bar_length)  # In BPM\n    volume = 100  # 0-127, as per the MIDI standard\n\n    MyMIDI = MIDIFile(1)  # One track, defaults to format 1 (tempo track is created\n    # automatically)\n    MyMIDI.addTempo(track, time, tempo)\n\n    for i, pitch in enumerate(array_of_note_numbers):\n        MyMIDI.addNote(track, channel, pitch, time + i, duration, volume)\n\n    with open(\"chord_scraper/yourmusic.mid\", \"wb\") as output_file:\n        MyMIDI.writeFile(output_file)"
  },
  {
    "objectID": "posts/project/Project.html#chordy-interface",
    "href": "posts/project/Project.html#chordy-interface",
    "title": "Project - Chordy!",
    "section": "",
    "text": "All html templates that are needed for flask rendering are located under the /PIC16B-project/chord_scraper/templates/ directory. Here is an example (SearchWithArtist.html):\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;Scraper 2&lt;/title&gt;\n    &lt;style&gt;\n        body {\n            font-family: \"Gill Sans\", sans-serif;\n            background-color: #f0f0f0; /* Change background color to a light shade */\n            color: #333; /* Change text color */\n            margin: 0;\n            padding: 0;\n        }\n        h1 {\n            color: #f77f00; /* Change heading color */\n            text-align: center; /* Center align heading */\n        }\n        ul {\n            list-style-type: none; /* Remove bullet points from the list */\n            padding: 0;\n            margin: 0;\n            text-align: center; /* Center align list */\n        }\n        li {\n            margin-bottom: 10px;\n        }\n        li a {\n            display: block;\n            background-color: #f77f00; /* Change link background color */\n            color: #fff; /* Change link text color */\n            padding: 10px;\n            text-decoration: none;\n            border-radius: 5px;\n        }\n        li a:hover {\n            background-color: #f77f00; /* Darker shade on hover */\n        }\n        form {\n            background-color: #fff; /* Change form background color to white */\n            padding: 20px;\n            border-radius: 5px;\n            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1); /* Add a slight shadow effect */\n            text-align: center; /* Center align form */\n        }\n        label {\n            display: block;\n            margin-bottom: 10px;\n        }\n        input[type=\"text\"] {\n            width: 100%;\n            padding: 10px;\n            margin-bottom: 15px;\n            border: 1px solid #ccc;\n            border-radius: 4px;\n            box-sizing: border-box;\n        }\n        button[type=\"submit\"] {\n            background-color: #f77f00; /* Change submit button background color */\n            color: #fff; /* Change submit button text color */\n            padding: 10px 20px;\n            border: none;\n            border-radius: 4px;\n            cursor: pointer;\n        }\n        button[type=\"submit\"]:hover {\n            background-color: #f77f00; /* Darker shade on hover */\n        }\n        .error-message {\n            color: red; /* Change error message color */\n            text-align: center; /* Center align error message */\n        }\n        h2 {\n            text-align: center; /* Center align search results heading */\n        }\n        ol {\n            list-style-type: decimal; /* Use decimal numbering for ordered list */\n            padding-left: 20px; /* Add some padding to the left of the ordered list */\n        }\n        li {\n            margin-bottom: 5px; /* Reduce margin bottom for list items */\n        }\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Search With Artist&lt;/h1&gt;\n    &lt;ul&gt;\n        &lt;li&gt;&lt;a href=\"{{ url_for('SearchSong') }}\"&gt;Click here once you have noted down the index of artist's song&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n    &lt;form action=\"{{ url_for('SearchWithArtist') }}\" method=\"post\"&gt;\n        &lt;label for=\"artist\"&gt;Enter Artist Name:&lt;/label&gt;\n        &lt;input type=\"text\" id=\"artist\" name=\"artist\" required&gt;\n        &lt;button type=\"submit\"&gt;Search&lt;/button&gt;\n    &lt;/form&gt;\n    {% if error_message %}\n        &lt;p class=\"error-message\"&gt;{{ error_message }}&lt;/p&gt;\n    {% else %}\n        &lt;h2&gt;Search Results&lt;/h2&gt;\n        &lt;ol type=\"1\"&gt;\n            {% for line in result_data %}\n                &lt;li&gt;{{ line }}&lt;/li&gt;\n            {% endfor %}\n        &lt;/ol&gt;\n    {% endif %}\n&lt;/body&gt;\n&lt;/html&gt;\nSearchWithArtist.html starts with a heading “Search With Artist” followed by an unordered list containing a single link. The link redirects users to a separate page for entering the index of the artist’s song.\nBelow the list, there’s a form where users can input the artist’s name. The form includes a text input field for the artist’s name and a submit button labeled “Search”.\nThe HTML code also includes a conditional statement {% if error_message %} to display an error message if there is one. If there is no error message, the code displays the search results in an ordered list (&lt;ol&gt;) using decimal numbering. Each search result is displayed as a list item (&lt;li&gt;).\nThe styling of the page is defined within the &lt;style&gt; tags in the &lt;head&gt; section. It includes various CSS rules to customize the appearance of the page, such as setting the background color, text color, font, padding, margins, and border radius - I selected the color #f77f00 and the font \"Gill Sans\", sans-serif\", then made this styling consistent throughout the other htmls. Additionally, it styles the form elements, links, and error messages for a more user-friendly experience. Overall, the HTML code provides a clean and visually appealing interface for searching songs by artist.\n\nImage(filename='/Users/athena/Desktop/hw6/interface1.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/interface2.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/interface3.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/interface4.jpg')\n\n\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/errorhandling1.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/errorhandling2.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/errorhandling3.jpg')"
  },
  {
    "objectID": "posts/project/Project.html#data-flowchart",
    "href": "posts/project/Project.html#data-flowchart",
    "title": "Project - Chordy!",
    "section": "",
    "text": "Image(filename='/Users/athena/Desktop/hw6/flowofdata.jpg')"
  },
  {
    "objectID": "posts/project/Project.html#concluding-remarks",
    "href": "posts/project/Project.html#concluding-remarks",
    "title": "Project - Chordy!",
    "section": "",
    "text": "In conclusion, Chordy represents a significant advancement in addressing the common frustration of accessing clean karaoke background tracks with simplified chords for songs by Top Ten Artists. By leveraging technologies such as Flask, Scrapy, midiutil, and MongoDB, Chordy provides users with a streamlined and intuitive platform to search for their desired songs and download MIDI files containing the song’s backtrack chords. This innovative solution not only enhances the accessibility of instrumental versions of popular songs but also empowers musicians to customize their performances by layering their own instruments and vocals seamlessly.\n\n\nChordy, undoubtedly offers a convenient and innovative solution for music enthusiasts by providing them with chord information scraped from Chordify.net and the ability to generate MIDI files for selected songs. However, it’s crucial to consider the ethical ramifications of such a project:\n\nData Scraping Ethics: Scraping data from websites raises ethical concerns, particularly regarding the Terms of Service (ToS) and potential copyright infringement. While some websites explicitly prohibit scraping in their ToS, others might have ambiguous or unclear policies. Respecting the terms and conditions of websites is essential to maintain ethical integrity and avoid legal consequences, but this is undermined in Chordy.\nIntellectual Property Rights: Chordy’s use of scraped chord information raises questions about intellectual property rights. Chordify.net likely holds copyrights or licenses for the chord information on their platform. By scraping and utilizing this data, Chordy, if deployed and put in mass use, may violate intellectual property rights.\nUser Privacy: Chordy’s interface for user searches and song selection involves handling user data. Chordy does not include user privacy policy upon account creation. In the future, it is crucial to prioritize user privacy and security, including implementing appropriate security measures (such as hashing user password or creating password checks - complex combination of numbers and alphabets) to protect user data from unauthorized access or misuse and being transparent with users about how their data will be used."
  },
  {
    "objectID": "posts/image-classification/hw5_new.html",
    "href": "posts/image-classification/hw5_new.html",
    "title": "Image Classification",
    "section": "",
    "text": "The following code imports necessary libraries including os, keras, tensorflow_datasets (abbreviated as tfds), and tensorflow.data (abbreviated as tf_data).\nIt then loads the “cats_vs_dogs” dataset from TensorFlow Datasets (tfds.load()) and splits it into training, validation, and test sets. It allocates 40% of the data for training, 10% for validation, and 10% for testing.\nNext, we resizes all images to a common size of 150x150 pixels using keras.layers.Resizing.\nAfter resizing, it batches and prefetches the datasets (train_ds, validation_ds, test_ds) to improve performance during training. Batching groups multiple images and labels together to be processed simultaneously, and prefetching overlaps data preprocessing and model execution to reduce idle time.\nFinally, it extracts labels from the training dataset (train_ds) using unbatch(), maps them to numpy values, and creates an iterator (labels_iterator) for iterating over the labels.\nimport os\nimport keras\nfrom keras import utils \nimport tensorflow_datasets as tfds\nfrom tensorflow import data as tf_data\n\ntrain_ds, validation_ds, test_ds = tfds.load(\n    \"cats_vs_dogs\",\n    # 40% for training, 10% for validation, and 10% for test (the rest unused)\n    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n    as_supervised=True,  # Include labels\n)\n\nprint(f\"Number of training samples: {train_ds.cardinality()}\")\nprint(f\"Number of validation samples: {validation_ds.cardinality()}\")\nprint(f\"Number of test samples: {test_ds.cardinality()}\")\n\nresize_fn = keras.layers.Resizing(150, 150)\n\ntrain_ds = train_ds.map(lambda x, y: (resize_fn(x), y))\nvalidation_ds = validation_ds.map(lambda x, y: (resize_fn(x), y))\ntest_ds = test_ds.map(lambda x, y: (resize_fn(x), y))\n\nbatch_size = 64\n\ntrain_ds = train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\nvalidation_ds = validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\ntest_ds = test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n\nlabels_iterator= train_ds.unbatch().map(lambda image, label: label).as_numpy_iterator()\n\n\n\nWe define a function visualize_cats_and_dogs() that takes a dataset of images with corresponding labels (presumably from the “cats_vs_dogs” dataset) and visualizes a specified number of random samples of cats and dogs.\n\nFirst, the function collects random samples of cats and dogs from the dataset, where cats have label 0 and dogs have label 1.\nIt then plots these samples in a grid using Matplotlib, with each row representing either cats or dogs. The number of samples per category is specified by the num_samples parameter.\nThe images are plotted with their corresponding titles (“Cat” or “Dog”) and with the axis turned off to remove axis labels.\nThe visualize_cats_and_dogs() function can be called with a dataset as an argument, typically the training dataset (train_ds), and a specified number of samples to visualize.\nThe usage example at the end demonstrates how to call the function with train_ds.take(6), which retrieves the first 6 samples from the training dataset. This visualizes 3 cats and 3 dogs, as specified by the default num_samples parameter.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef visualize_cats_and_dogs(dataset, num_samples=3):\n    cats = []\n    dogs = []\n    \n    # Collect random samples of cats and dogs\n    for image, label in dataset:\n        if label.numpy()[0] == 0:  # Extract integer value from the tensor\n            cats.append(image[0])  # Take the first image from the batch\n        else:  # Dogs have label 1\n            dogs.append(image[0])  # Take the first image from the batch\n        \n        if len(cats) == num_samples and len(dogs) == num_samples:\n            break\n    \n    # Plotting\n    fig, axes = plt.subplots(2, num_samples, figsize=(15, 7))\n    fig.subplots_adjust(hspace=0.3, wspace=0.1)\n    \n    for i in range(min(num_samples, len(cats))):  # Ensure we loop over minimum of requested samples and available samples\n        axes[0, i].imshow(cats[i].numpy().astype(np.uint8))\n        axes[0, i].set_title(\"Cat\")\n        axes[0, i].axis('off')\n    \n    for i in range(min(num_samples, len(dogs))):  # Ensure we loop over minimum of requested samples and available samples\n        axes[1, i].imshow(dogs[i].numpy().astype(np.uint8))\n        axes[1, i].set_title(\"Dog\")\n        axes[1, i].axis('off')\n    \n    plt.show()\n\n# Usage:\nvisualize_cats_and_dogs(train_ds.take(6))\n\n# Initialize counters\ncat_count = 0\ndog_count = 0\n\n# Iterate through the training dataset\nfor image, label in train_ds:\n    if label.numpy()[0] == 0:\n        cat_count += 1\n    else:\n        dog_count += 1\n\nprint(\"Number of cat images:\", cat_count)\nprint(\"Number of dog images:\", dog_count)\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/hw5.jpg')\n\n\n\n\n\n\n\n\n\n\n\nTo begin with our first model, we construct a convolutional neural network (CNN) model using TensorFlow’s Keras API to classify images as either cats or dogs.\nThe model comprises a series of convolutional (Conv2D) and max-pooling (MaxPooling2D) layers followed by a flattening layer (Flatten) and two dense layers (Dense) with dropout regularization applied. The input images are expected to have a shape of (150, 150, 3), indicating a width and height of 150 pixels and three color channels (RGB). The activation function used in the convolutional layers is ReLU, and the output layer employs a sigmoid activation function to produce binary classification predictions.\nThe model is compiled with the Adam optimizer and binary cross-entropy loss function. It is then trained on the provided training dataset (train_ds) for 20 epochs while monitoring validation accuracy on the validation dataset (validation_ds). Finally, the training history is visualized by plotting the accuracy and validation accuracy over epochs using Matplotlib. This allows monitoring of the model’s performance and helps in identifying overfitting or underfitting issues during training.\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\nmodel1 = tf.keras.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dropout(0.5),\n    layers.Dense(512, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n\nmodel1.compile(optimizer='adam',\n               loss='binary_crossentropy',\n               metrics=['accuracy'])\n\n# Train the model\nhistory = model1.fit(train_ds, \n                     epochs=20, \n                     validation_data=validation_ds)\n\n# Plot training history\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.show()\nIn this model, we experimented with different numbers of filters in the convolutional layers, different dropout rates, and different numbers of units in the dense layer to improve validation accuracy. The validation accuracy of my model during training was around 60-65%. Comparing this to the baseline accuracy of around 50%, my model performs significantly better. Regarding overfitting, we can observe a slight gap between the training and validation accuracies, but it doesn’t seem severe. However, if the gap were to widen significantly in further experiments, it would indicate overfitting. Regularization techniques such as dropout and data augmentation can help mitigate overfitting.\n\n\n\nFor model 2, we construct another convolutional neural network (CNN) model using TensorFlow’s Keras API for image classification tasks. This model (model2) is similar to the previous one but includes data augmentation layers (RandomFlip and RandomRotation) at the beginning. Data augmentation is a technique used to increase the diversity of the training dataset by applying random transformations to the input images, such as flipping horizontally or rotating by a certain factor.\nAfter the data augmentation layers, the model architecture remains the same, comprising convolutional (Conv2D) and max-pooling (MaxPooling2D) layers followed by a flattening layer (Flatten) and two dense layers (Dense) with dropout regularization applied. The input images are expected to have a shape of (150, 150, 3), indicating a width and height of 150 pixels and three color channels (RGB). The activation function used in the convolutional layers is ReLU, and the output layer employs a sigmoid activation function to produce binary classification predictions.\nSimilar to the previous code segment, the model is compiled with the Adam optimizer and binary cross-entropy loss function. It is then trained on the provided training dataset (train_ds) for 20 epochs while monitoring validation accuracy on the validation dataset (validation_ds). Finally, the training history is visualized by plotting the accuracy and validation accuracy over epochs using Matplotlib. This helps monitor the model’s performance and identify any overfitting or underfitting issues during training, taking into account the effects of data augmentation on training dynamics.\nmodel2 = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(mode='horizontal'),\n    tf.keras.layers.RandomRotation(factor=0.1),\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel2.compile(optimizer='adam',\n               loss='binary_crossentropy',\n               metrics=['accuracy'])\n\n# Train the model\nhistory = model2.fit(train_ds, \n                     epochs=20, \n                     validation_data=validation_ds)\n\n# Plot training history\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.show()\nThe validation accuracy of my model during training was around 55-60%. This accuracy is slightly lower than what was achieved with model1. Regarding overfitting, we can see a similar pattern to model1, where there’s a slight gap between the training and validation accuracies. This indicates some level of overfitting, but it’s not severe. Regularization techniques such as dropout can help alleviate overfitting further.\n\n\n\nIn the following code, we first create two visualizations showing the results of applying RandomFlip and RandomRotation to an example image:\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# Load a sample image from the dataset\nsample_image, _ = next(iter(train_ds))\n\n# Apply RandomFlip to the sample image\nflip_layer = tf.keras.layers.RandomFlip(\"horizontal\")\nflipped_image = flip_layer(sample_image)\n\n# Apply RandomRotation to the sample image\nrotation_layer = tf.keras.layers.RandomRotation(0.2)\nrotated_image = rotation_layer(sample_image)\n\n# Plot the original, flipped, and rotated images\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 3, 1)\nplt.imshow(sample_image[0].numpy().astype(\"uint8\"))\nplt.title(\"Original\")\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 2)\nplt.imshow(flipped_image[0].numpy().astype(\"uint8\"))\nplt.title(\"Flipped\")\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 3)\nplt.imshow(rotated_image[0].numpy().astype(\"uint8\"))\nplt.title(\"Rotated\")\nplt.axis(\"off\")\n\nplt.show()\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/hw5-2.jpg')\n\n\n\n\n\n\n\n\nNow we construct a convolutional neural network (CNN) model using TensorFlow’s Keras API for image classification, incorporating preprocessing and data augmentation techniques - Model 3!\n\nFirst, a preprocessor layer is defined using the keras.Input function to specify the input shape, followed by a keras.layers.Rescaling layer. This layer normalizes pixel values to the range [-1, 1] by dividing by 127.5 and subtracting 1.\nData augmentation layers are defined using keras.Sequential, including keras.layers.RandomFlip for horizontal flipping and keras.layers.RandomRotation for random rotations up to 20 degrees.\nThe rest of the model architecture (model3) is constructed using keras.Sequential, which includes the preprocessor layer, data augmentation layers, convolutional (layers.Conv2D) and max-pooling (layers.MaxPooling2D) layers, a flattening layer (layers.Flatten), dropout regularization (layers.Dropout), and dense layers (layers.Dense) with ReLU activation. The final dense layer uses a sigmoid activation function for binary classification.\nThe model is compiled with the Adam optimizer, binary cross-entropy loss function, and accuracy metric.\nThe model is trained on the provided training dataset (train_ds) for 20 epochs while monitoring validation accuracy on the validation dataset (validation_ds).\nFinally, the training history is visualized by plotting the accuracy and validation accuracy over epochs using Matplotlib, enabling monitoring of the model’s performance and identification of potential overfitting or underfitting issues during training, with consideration of the effects of preprocessing and data augmentation on training dynamics.\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\n\n# Define preprocessor layer\ni = keras.Input(shape=(150, 150, 3))\nscale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\nx = scale_layer(i)\npreprocessor = keras.Model(inputs=i, outputs=x)\n\n# Define data augmentation layers\ndata_augmentation = keras.Sequential([\n    keras.layers.RandomFlip(\"horizontal\"),\n    keras.layers.RandomRotation(0.2),\n])\n\n# Define the rest of the model\nmodel3 = keras.Sequential([\n    preprocessor,  # Preprocessor layer\n    data_augmentation,  # Data augmentation layers\n    layers.Conv2D(32, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dropout(0.5),\n    layers.Dense(512, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel3.compile(optimizer='adam',\n               loss='binary_crossentropy',\n               metrics=['accuracy'])\n\n# Train the model\nhistory3 = model3.fit(train_ds, \n                      epochs=20, \n                      validation_data=validation_ds)\n\n# Plot training history\nplt.plot(history3.history['accuracy'], label='accuracy')\nplt.plot(history3.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.show()\nThe validation accuracy of my model during training ranged between 80% and 85%. The validation accuracy achieved with model3 is significantly higher than the one obtained with model1. There seems to be some overfitting in model3, as the training accuracy is consistently higher than the validation accuracy, and the gap between them widens slightly over epochs. Regularization techniques such as dropout or increasing the size of the validation set could be applied to mitigate this.\n\n\n\nAt last, we construct model 4 - a convolutional neural network (CNN) model using transfer learning with MobileNetV3Large architecture, augmented with additional layers for fine-tuning and classification.\n\nMobileNetV3Large is downloaded and configured as a layer using keras.applications.MobileNetV3Large. It is instantiated with the specified input shape of (150, 150, 3), excluding the top classification layers (include_top=False) and pre-loaded with weights trained on the ImageNet dataset (weights='imagenet'). The base model’s trainable parameters are frozen by setting base_model.trainable = False.\nData augmentation layers are defined using keras.Sequential, including horizontal flipping (keras.layers.RandomFlip) and random rotation up to 20 degrees (keras.layers.RandomRotation).\nThe base_model_layer is created as a Keras model with input i and output x, representing the MobileNetV3Large base model with frozen weights.\nModel model4 is defined using keras.Sequential, consisting of the base_model_layer, data augmentation layers, a global max-pooling layer (keras.layers.GlobalMaxPooling2D), two dense layers (keras.layers.Dense) with ReLU activation and dropout regularization, and a final dense layer with softmax activation for binary classification.\nThe model is compiled with the Adam optimizer, sparse categorical cross-entropy loss function suitable for integer labels, and accuracy metric.\nThe model summary is printed using model4.summary() to provide an overview of the model architecture and parameters.\nThe model is trained on the provided training dataset (train_ds) for 20 epochs while monitoring validation accuracy on the validation dataset (validation_ds).\nFinally, the training history is visualized by plotting the accuracy and validation accuracy over epochs using Matplotlib, allowing monitoring of the model’s performance and identification of potential overfitting or underfitting issues during training.\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Download MobileNetV3Large and configure it as a layer\nIMG_SHAPE = (150, 150, 3)\nbase_model = keras.applications.MobileNetV3Large(input_shape=IMG_SHAPE,\n                                                 include_top=False,\n                                                 weights='imagenet')\nbase_model.trainable = False\n\ni = keras.Input(shape=IMG_SHAPE)\nx = base_model(i, training=False)\nbase_model_layer = keras.Model(inputs=i, outputs=x)\n\n# Create model4\ndata_augmentation = keras.Sequential([\n    keras.layers.RandomFlip(\"horizontal\"),\n    keras.layers.RandomRotation(0.2),\n])\n\nmodel4 = keras.Sequential([\n    base_model_layer,  # MobileNetV3Large base model\n    data_augmentation,  # Data augmentation layers\n    keras.layers.GlobalMaxPooling2D(),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(2, activation='softmax')  # Dense layer for classification\n])\n\n# Compile the model\nmodel4.compile(optimizer='adam',\n               loss='sparse_categorical_crossentropy',\n               metrics=['accuracy'])\n\n# Print model summary\nmodel4.summary()\n\n# Train the model\nhistory4 = model4.fit(train_ds, \n                      epochs=20, \n                      validation_data=validation_ds)\n\n# Plot training history\nplt.plot(history4.history['accuracy'], label='accuracy')\nplt.plot(history4.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.show()\nThe validation accuracy of my model during training ranged between 93% and 95%. This validation accuracy is significantly higher than the accuracy obtained with model1. Regarding overfitting, model4 seems to perform well, with the validation accuracy closely tracking the training accuracy throughout the epochs. There doesn’t appear to be significant overfitting observed in model4.\n\n\n\ndef evaluate_model(model, dataset):\n    # Evaluate the model on the dataset\n    loss, accuracy = model.evaluate(dataset)\n    return accuracy\n\n# Evaluate all four models on the test dataset\naccuracy_model1 = evaluate_model(model1, test_ds)\naccuracy_model2 = evaluate_model(model2, test_ds)\naccuracy_model3 = evaluate_model(model3, test_ds)\naccuracy_model4 = evaluate_model(model4, test_ds)\n\nprint(\"Test accuracy for model1:\", accuracy_model1)\nprint(\"Test accuracy for model2:\", accuracy_model2)\nprint(\"Test accuracy for model3:\", accuracy_model3)\nprint(\"Test accuracy for model4:\", accuracy_model4)\noutput of above evaluation code:\n37/37 [==============================] - 21s 548ms/step - loss: 0.6934 - accuracy: 0.4940\n37/37 [==============================] - 20s 531ms/step - loss: 0.6712 - accuracy: 0.5602\n37/37 [==============================] - 20s 533ms/step - loss: 0.6351 - accuracy: 0.6328\n37/37 [==============================] - 18s 483ms/step - loss: 0.1257 - accuracy: 0.9721\nTest accuracy for model1: 0.49398109316825867\nTest accuracy for model2: 0.5601891875267029\nTest accuracy for model3: 0.6328461170196533\nTest accuracy for model4: 0.9720550179481506\n\nModel 1: The test accuracy is approximately 49.4%. This model appears to have underperformed compared to the baseline accuracy, which suggests that it might not have learned meaningful patterns in the data.\nModel 2: The test accuracy is around 56.0%. This model performed slightly better than Model 1, but still below the desired threshold of 60%.\nModel 3: The test accuracy is about 63.3%. This model achieved a significant improvement in accuracy compared to Models 1 and 2, but it seems to have slightly underperformed in comparison to Model 4.\nModel 4: The test accuracy is exceptionally high at approximately 97.2%. This model significantly outperformed the other models, indicating that leveraging the pretrained MobileNetV3Large base model led to a highly effective classifier for distinguishing between cats and dogs.\n\nOverall, Model 4 demonstrated the highest test accuracy, showcasing the benefits of leveraging a pretrained model for the task at hand. Models 1, 2, and 3 had varying degrees of performance, with Model 3 achieving the highest accuracy among them.\n\n\n\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/hw5_his.jpg')"
  },
  {
    "objectID": "posts/image-classification/hw5_new.html#preperations-and-preprocessing",
    "href": "posts/image-classification/hw5_new.html#preperations-and-preprocessing",
    "title": "Image Classification",
    "section": "",
    "text": "The following code imports necessary libraries including os, keras, tensorflow_datasets (abbreviated as tfds), and tensorflow.data (abbreviated as tf_data).\nIt then loads the “cats_vs_dogs” dataset from TensorFlow Datasets (tfds.load()) and splits it into training, validation, and test sets. It allocates 40% of the data for training, 10% for validation, and 10% for testing.\nNext, we resizes all images to a common size of 150x150 pixels using keras.layers.Resizing.\nAfter resizing, it batches and prefetches the datasets (train_ds, validation_ds, test_ds) to improve performance during training. Batching groups multiple images and labels together to be processed simultaneously, and prefetching overlaps data preprocessing and model execution to reduce idle time.\nFinally, it extracts labels from the training dataset (train_ds) using unbatch(), maps them to numpy values, and creates an iterator (labels_iterator) for iterating over the labels.\nimport os\nimport keras\nfrom keras import utils \nimport tensorflow_datasets as tfds\nfrom tensorflow import data as tf_data\n\ntrain_ds, validation_ds, test_ds = tfds.load(\n    \"cats_vs_dogs\",\n    # 40% for training, 10% for validation, and 10% for test (the rest unused)\n    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n    as_supervised=True,  # Include labels\n)\n\nprint(f\"Number of training samples: {train_ds.cardinality()}\")\nprint(f\"Number of validation samples: {validation_ds.cardinality()}\")\nprint(f\"Number of test samples: {test_ds.cardinality()}\")\n\nresize_fn = keras.layers.Resizing(150, 150)\n\ntrain_ds = train_ds.map(lambda x, y: (resize_fn(x), y))\nvalidation_ds = validation_ds.map(lambda x, y: (resize_fn(x), y))\ntest_ds = test_ds.map(lambda x, y: (resize_fn(x), y))\n\nbatch_size = 64\n\ntrain_ds = train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\nvalidation_ds = validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\ntest_ds = test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n\nlabels_iterator= train_ds.unbatch().map(lambda image, label: label).as_numpy_iterator()"
  },
  {
    "objectID": "posts/image-classification/hw5_new.html#displaying-some-cats-and-dogs",
    "href": "posts/image-classification/hw5_new.html#displaying-some-cats-and-dogs",
    "title": "Image Classification",
    "section": "",
    "text": "We define a function visualize_cats_and_dogs() that takes a dataset of images with corresponding labels (presumably from the “cats_vs_dogs” dataset) and visualizes a specified number of random samples of cats and dogs.\n\nFirst, the function collects random samples of cats and dogs from the dataset, where cats have label 0 and dogs have label 1.\nIt then plots these samples in a grid using Matplotlib, with each row representing either cats or dogs. The number of samples per category is specified by the num_samples parameter.\nThe images are plotted with their corresponding titles (“Cat” or “Dog”) and with the axis turned off to remove axis labels.\nThe visualize_cats_and_dogs() function can be called with a dataset as an argument, typically the training dataset (train_ds), and a specified number of samples to visualize.\nThe usage example at the end demonstrates how to call the function with train_ds.take(6), which retrieves the first 6 samples from the training dataset. This visualizes 3 cats and 3 dogs, as specified by the default num_samples parameter.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef visualize_cats_and_dogs(dataset, num_samples=3):\n    cats = []\n    dogs = []\n    \n    # Collect random samples of cats and dogs\n    for image, label in dataset:\n        if label.numpy()[0] == 0:  # Extract integer value from the tensor\n            cats.append(image[0])  # Take the first image from the batch\n        else:  # Dogs have label 1\n            dogs.append(image[0])  # Take the first image from the batch\n        \n        if len(cats) == num_samples and len(dogs) == num_samples:\n            break\n    \n    # Plotting\n    fig, axes = plt.subplots(2, num_samples, figsize=(15, 7))\n    fig.subplots_adjust(hspace=0.3, wspace=0.1)\n    \n    for i in range(min(num_samples, len(cats))):  # Ensure we loop over minimum of requested samples and available samples\n        axes[0, i].imshow(cats[i].numpy().astype(np.uint8))\n        axes[0, i].set_title(\"Cat\")\n        axes[0, i].axis('off')\n    \n    for i in range(min(num_samples, len(dogs))):  # Ensure we loop over minimum of requested samples and available samples\n        axes[1, i].imshow(dogs[i].numpy().astype(np.uint8))\n        axes[1, i].set_title(\"Dog\")\n        axes[1, i].axis('off')\n    \n    plt.show()\n\n# Usage:\nvisualize_cats_and_dogs(train_ds.take(6))\n\n# Initialize counters\ncat_count = 0\ndog_count = 0\n\n# Iterate through the training dataset\nfor image, label in train_ds:\n    if label.numpy()[0] == 0:\n        cat_count += 1\n    else:\n        dog_count += 1\n\nprint(\"Number of cat images:\", cat_count)\nprint(\"Number of dog images:\", dog_count)\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/hw5.jpg')"
  },
  {
    "objectID": "posts/image-classification/hw5_new.html#model-1",
    "href": "posts/image-classification/hw5_new.html#model-1",
    "title": "Image Classification",
    "section": "",
    "text": "To begin with our first model, we construct a convolutional neural network (CNN) model using TensorFlow’s Keras API to classify images as either cats or dogs.\nThe model comprises a series of convolutional (Conv2D) and max-pooling (MaxPooling2D) layers followed by a flattening layer (Flatten) and two dense layers (Dense) with dropout regularization applied. The input images are expected to have a shape of (150, 150, 3), indicating a width and height of 150 pixels and three color channels (RGB). The activation function used in the convolutional layers is ReLU, and the output layer employs a sigmoid activation function to produce binary classification predictions.\nThe model is compiled with the Adam optimizer and binary cross-entropy loss function. It is then trained on the provided training dataset (train_ds) for 20 epochs while monitoring validation accuracy on the validation dataset (validation_ds). Finally, the training history is visualized by plotting the accuracy and validation accuracy over epochs using Matplotlib. This allows monitoring of the model’s performance and helps in identifying overfitting or underfitting issues during training.\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\nmodel1 = tf.keras.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dropout(0.5),\n    layers.Dense(512, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n\nmodel1.compile(optimizer='adam',\n               loss='binary_crossentropy',\n               metrics=['accuracy'])\n\n# Train the model\nhistory = model1.fit(train_ds, \n                     epochs=20, \n                     validation_data=validation_ds)\n\n# Plot training history\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.show()\nIn this model, we experimented with different numbers of filters in the convolutional layers, different dropout rates, and different numbers of units in the dense layer to improve validation accuracy. The validation accuracy of my model during training was around 60-65%. Comparing this to the baseline accuracy of around 50%, my model performs significantly better. Regarding overfitting, we can observe a slight gap between the training and validation accuracies, but it doesn’t seem severe. However, if the gap were to widen significantly in further experiments, it would indicate overfitting. Regularization techniques such as dropout and data augmentation can help mitigate overfitting."
  },
  {
    "objectID": "posts/image-classification/hw5_new.html#model-2",
    "href": "posts/image-classification/hw5_new.html#model-2",
    "title": "Image Classification",
    "section": "",
    "text": "For model 2, we construct another convolutional neural network (CNN) model using TensorFlow’s Keras API for image classification tasks. This model (model2) is similar to the previous one but includes data augmentation layers (RandomFlip and RandomRotation) at the beginning. Data augmentation is a technique used to increase the diversity of the training dataset by applying random transformations to the input images, such as flipping horizontally or rotating by a certain factor.\nAfter the data augmentation layers, the model architecture remains the same, comprising convolutional (Conv2D) and max-pooling (MaxPooling2D) layers followed by a flattening layer (Flatten) and two dense layers (Dense) with dropout regularization applied. The input images are expected to have a shape of (150, 150, 3), indicating a width and height of 150 pixels and three color channels (RGB). The activation function used in the convolutional layers is ReLU, and the output layer employs a sigmoid activation function to produce binary classification predictions.\nSimilar to the previous code segment, the model is compiled with the Adam optimizer and binary cross-entropy loss function. It is then trained on the provided training dataset (train_ds) for 20 epochs while monitoring validation accuracy on the validation dataset (validation_ds). Finally, the training history is visualized by plotting the accuracy and validation accuracy over epochs using Matplotlib. This helps monitor the model’s performance and identify any overfitting or underfitting issues during training, taking into account the effects of data augmentation on training dynamics.\nmodel2 = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(mode='horizontal'),\n    tf.keras.layers.RandomRotation(factor=0.1),\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel2.compile(optimizer='adam',\n               loss='binary_crossentropy',\n               metrics=['accuracy'])\n\n# Train the model\nhistory = model2.fit(train_ds, \n                     epochs=20, \n                     validation_data=validation_ds)\n\n# Plot training history\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.show()\nThe validation accuracy of my model during training was around 55-60%. This accuracy is slightly lower than what was achieved with model1. Regarding overfitting, we can see a similar pattern to model1, where there’s a slight gap between the training and validation accuracies. This indicates some level of overfitting, but it’s not severe. Regularization techniques such as dropout can help alleviate overfitting further."
  },
  {
    "objectID": "posts/image-classification/hw5_new.html#model-3",
    "href": "posts/image-classification/hw5_new.html#model-3",
    "title": "Image Classification",
    "section": "",
    "text": "In the following code, we first create two visualizations showing the results of applying RandomFlip and RandomRotation to an example image:\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# Load a sample image from the dataset\nsample_image, _ = next(iter(train_ds))\n\n# Apply RandomFlip to the sample image\nflip_layer = tf.keras.layers.RandomFlip(\"horizontal\")\nflipped_image = flip_layer(sample_image)\n\n# Apply RandomRotation to the sample image\nrotation_layer = tf.keras.layers.RandomRotation(0.2)\nrotated_image = rotation_layer(sample_image)\n\n# Plot the original, flipped, and rotated images\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 3, 1)\nplt.imshow(sample_image[0].numpy().astype(\"uint8\"))\nplt.title(\"Original\")\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 2)\nplt.imshow(flipped_image[0].numpy().astype(\"uint8\"))\nplt.title(\"Flipped\")\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 3)\nplt.imshow(rotated_image[0].numpy().astype(\"uint8\"))\nplt.title(\"Rotated\")\nplt.axis(\"off\")\n\nplt.show()\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/hw5-2.jpg')\n\n\n\n\n\n\n\n\nNow we construct a convolutional neural network (CNN) model using TensorFlow’s Keras API for image classification, incorporating preprocessing and data augmentation techniques - Model 3!\n\nFirst, a preprocessor layer is defined using the keras.Input function to specify the input shape, followed by a keras.layers.Rescaling layer. This layer normalizes pixel values to the range [-1, 1] by dividing by 127.5 and subtracting 1.\nData augmentation layers are defined using keras.Sequential, including keras.layers.RandomFlip for horizontal flipping and keras.layers.RandomRotation for random rotations up to 20 degrees.\nThe rest of the model architecture (model3) is constructed using keras.Sequential, which includes the preprocessor layer, data augmentation layers, convolutional (layers.Conv2D) and max-pooling (layers.MaxPooling2D) layers, a flattening layer (layers.Flatten), dropout regularization (layers.Dropout), and dense layers (layers.Dense) with ReLU activation. The final dense layer uses a sigmoid activation function for binary classification.\nThe model is compiled with the Adam optimizer, binary cross-entropy loss function, and accuracy metric.\nThe model is trained on the provided training dataset (train_ds) for 20 epochs while monitoring validation accuracy on the validation dataset (validation_ds).\nFinally, the training history is visualized by plotting the accuracy and validation accuracy over epochs using Matplotlib, enabling monitoring of the model’s performance and identification of potential overfitting or underfitting issues during training, with consideration of the effects of preprocessing and data augmentation on training dynamics.\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\n\n# Define preprocessor layer\ni = keras.Input(shape=(150, 150, 3))\nscale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\nx = scale_layer(i)\npreprocessor = keras.Model(inputs=i, outputs=x)\n\n# Define data augmentation layers\ndata_augmentation = keras.Sequential([\n    keras.layers.RandomFlip(\"horizontal\"),\n    keras.layers.RandomRotation(0.2),\n])\n\n# Define the rest of the model\nmodel3 = keras.Sequential([\n    preprocessor,  # Preprocessor layer\n    data_augmentation,  # Data augmentation layers\n    layers.Conv2D(32, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dropout(0.5),\n    layers.Dense(512, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel3.compile(optimizer='adam',\n               loss='binary_crossentropy',\n               metrics=['accuracy'])\n\n# Train the model\nhistory3 = model3.fit(train_ds, \n                      epochs=20, \n                      validation_data=validation_ds)\n\n# Plot training history\nplt.plot(history3.history['accuracy'], label='accuracy')\nplt.plot(history3.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.show()\nThe validation accuracy of my model during training ranged between 80% and 85%. The validation accuracy achieved with model3 is significantly higher than the one obtained with model1. There seems to be some overfitting in model3, as the training accuracy is consistently higher than the validation accuracy, and the gap between them widens slightly over epochs. Regularization techniques such as dropout or increasing the size of the validation set could be applied to mitigate this."
  },
  {
    "objectID": "posts/image-classification/hw5_new.html#model-4",
    "href": "posts/image-classification/hw5_new.html#model-4",
    "title": "Image Classification",
    "section": "",
    "text": "At last, we construct model 4 - a convolutional neural network (CNN) model using transfer learning with MobileNetV3Large architecture, augmented with additional layers for fine-tuning and classification.\n\nMobileNetV3Large is downloaded and configured as a layer using keras.applications.MobileNetV3Large. It is instantiated with the specified input shape of (150, 150, 3), excluding the top classification layers (include_top=False) and pre-loaded with weights trained on the ImageNet dataset (weights='imagenet'). The base model’s trainable parameters are frozen by setting base_model.trainable = False.\nData augmentation layers are defined using keras.Sequential, including horizontal flipping (keras.layers.RandomFlip) and random rotation up to 20 degrees (keras.layers.RandomRotation).\nThe base_model_layer is created as a Keras model with input i and output x, representing the MobileNetV3Large base model with frozen weights.\nModel model4 is defined using keras.Sequential, consisting of the base_model_layer, data augmentation layers, a global max-pooling layer (keras.layers.GlobalMaxPooling2D), two dense layers (keras.layers.Dense) with ReLU activation and dropout regularization, and a final dense layer with softmax activation for binary classification.\nThe model is compiled with the Adam optimizer, sparse categorical cross-entropy loss function suitable for integer labels, and accuracy metric.\nThe model summary is printed using model4.summary() to provide an overview of the model architecture and parameters.\nThe model is trained on the provided training dataset (train_ds) for 20 epochs while monitoring validation accuracy on the validation dataset (validation_ds).\nFinally, the training history is visualized by plotting the accuracy and validation accuracy over epochs using Matplotlib, allowing monitoring of the model’s performance and identification of potential overfitting or underfitting issues during training.\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Download MobileNetV3Large and configure it as a layer\nIMG_SHAPE = (150, 150, 3)\nbase_model = keras.applications.MobileNetV3Large(input_shape=IMG_SHAPE,\n                                                 include_top=False,\n                                                 weights='imagenet')\nbase_model.trainable = False\n\ni = keras.Input(shape=IMG_SHAPE)\nx = base_model(i, training=False)\nbase_model_layer = keras.Model(inputs=i, outputs=x)\n\n# Create model4\ndata_augmentation = keras.Sequential([\n    keras.layers.RandomFlip(\"horizontal\"),\n    keras.layers.RandomRotation(0.2),\n])\n\nmodel4 = keras.Sequential([\n    base_model_layer,  # MobileNetV3Large base model\n    data_augmentation,  # Data augmentation layers\n    keras.layers.GlobalMaxPooling2D(),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(2, activation='softmax')  # Dense layer for classification\n])\n\n# Compile the model\nmodel4.compile(optimizer='adam',\n               loss='sparse_categorical_crossentropy',\n               metrics=['accuracy'])\n\n# Print model summary\nmodel4.summary()\n\n# Train the model\nhistory4 = model4.fit(train_ds, \n                      epochs=20, \n                      validation_data=validation_ds)\n\n# Plot training history\nplt.plot(history4.history['accuracy'], label='accuracy')\nplt.plot(history4.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.show()\nThe validation accuracy of my model during training ranged between 93% and 95%. This validation accuracy is significantly higher than the accuracy obtained with model1. Regarding overfitting, model4 seems to perform well, with the validation accuracy closely tracking the training accuracy throughout the epochs. There doesn’t appear to be significant overfitting observed in model4."
  },
  {
    "objectID": "posts/image-classification/hw5_new.html#evaluating-models",
    "href": "posts/image-classification/hw5_new.html#evaluating-models",
    "title": "Image Classification",
    "section": "",
    "text": "def evaluate_model(model, dataset):\n    # Evaluate the model on the dataset\n    loss, accuracy = model.evaluate(dataset)\n    return accuracy\n\n# Evaluate all four models on the test dataset\naccuracy_model1 = evaluate_model(model1, test_ds)\naccuracy_model2 = evaluate_model(model2, test_ds)\naccuracy_model3 = evaluate_model(model3, test_ds)\naccuracy_model4 = evaluate_model(model4, test_ds)\n\nprint(\"Test accuracy for model1:\", accuracy_model1)\nprint(\"Test accuracy for model2:\", accuracy_model2)\nprint(\"Test accuracy for model3:\", accuracy_model3)\nprint(\"Test accuracy for model4:\", accuracy_model4)\noutput of above evaluation code:\n37/37 [==============================] - 21s 548ms/step - loss: 0.6934 - accuracy: 0.4940\n37/37 [==============================] - 20s 531ms/step - loss: 0.6712 - accuracy: 0.5602\n37/37 [==============================] - 20s 533ms/step - loss: 0.6351 - accuracy: 0.6328\n37/37 [==============================] - 18s 483ms/step - loss: 0.1257 - accuracy: 0.9721\nTest accuracy for model1: 0.49398109316825867\nTest accuracy for model2: 0.5601891875267029\nTest accuracy for model3: 0.6328461170196533\nTest accuracy for model4: 0.9720550179481506\n\nModel 1: The test accuracy is approximately 49.4%. This model appears to have underperformed compared to the baseline accuracy, which suggests that it might not have learned meaningful patterns in the data.\nModel 2: The test accuracy is around 56.0%. This model performed slightly better than Model 1, but still below the desired threshold of 60%.\nModel 3: The test accuracy is about 63.3%. This model achieved a significant improvement in accuracy compared to Models 1 and 2, but it seems to have slightly underperformed in comparison to Model 4.\nModel 4: The test accuracy is exceptionally high at approximately 97.2%. This model significantly outperformed the other models, indicating that leveraging the pretrained MobileNetV3Large base model led to a highly effective classifier for distinguishing between cats and dogs.\n\nOverall, Model 4 demonstrated the highest test accuracy, showcasing the benefits of leveraging a pretrained model for the task at hand. Models 1, 2, and 3 had varying degrees of performance, with Model 3 achieving the highest accuracy among them."
  },
  {
    "objectID": "posts/image-classification/hw5_new.html#model-history",
    "href": "posts/image-classification/hw5_new.html#model-history",
    "title": "Image Classification",
    "section": "",
    "text": "from IPython.display import Image\nImage(filename='/Users/athena/Desktop/hw5_his.jpg')"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/fake-news/hw6_New.html",
    "href": "posts/fake-news/hw6_New.html",
    "title": "Fake News Classification with Keras",
    "section": "",
    "text": "In this blog, I will be sharing with you my three models (focusing on different aspects) on fake news classification. The dataset that is used consists of labelled points. Each row of the data includes: title of the article, full article text, and its label (0 if the article is true and 1 if the article contains fake news).\n\n\nFirst, we make sure we are using Keras 3:\n!pip install keras --upgrade\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\nRequirement already satisfied: keras in /environment/miniconda3/lib/python3.10/site-packages (3.1.1)\nRequirement already satisfied: absl-py in /environment/miniconda3/lib/python3.10/site-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /environment/miniconda3/lib/python3.10/site-packages (from keras) (1.24.1)\nRequirement already satisfied: rich in /environment/miniconda3/lib/python3.10/site-packages (from keras) (13.7.1)\nRequirement already satisfied: namex in /environment/miniconda3/lib/python3.10/site-packages (from keras) (0.0.7)\nRequirement already satisfied: h5py in /environment/miniconda3/lib/python3.10/site-packages (from keras) (3.9.0)\nRequirement already satisfied: optree in /environment/miniconda3/lib/python3.10/site-packages (from keras) (0.10.0)\nRequirement already satisfied: ml-dtypes in /environment/miniconda3/lib/python3.10/site-packages (from keras) (0.3.2)\nRequirement already satisfied: typing-extensions&gt;=4.0.0 in /environment/miniconda3/lib/python3.10/site-packages (from optree-&gt;keras) (4.8.0)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /environment/miniconda3/lib/python3.10/site-packages (from rich-&gt;keras) (3.0.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /environment/miniconda3/lib/python3.10/site-packages (from rich-&gt;keras) (2.15.1)\nRequirement already satisfied: mdurl~=0.1 in /environment/miniconda3/lib/python3.10/site-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;keras) (0.1.2)\nkeras.__version__ prints ‘3.1.1’\nNow for the following code, we first import libraries - Pandas for data manipulation, TensorFlow for machine learning operations, NLTK for natural language processing, scikit-learn for data splitting, and Matplotlib for visualization.\nThen, we load dataset from given URL using Pandas’ read_csv, and define two functions preprocessing the data: 1. calculate_vocabulary_size: This function calculates the size of the vocabulary by tokenizing the text data, converting it to lowercase, and removing duplicates. 2. make_dataset: This function preprocesses the dataset by converting text to lowercase, removing stopwords using NLTK, and constructing a TensorFlow Dataset object with input features (title and text) and output labels (fake or not fake).\nNext, we calculate the vocabulary Size for both the ‘title’ and ‘text’ columns of the dataset using the calculate_vocabulary_size function. We also split dataset into training and validation sets using scikit-learn’s train_test_split function. Then, the make_dataset function is used to preprocess the datasets, converting them into TensorFlow Dataset objects.\nLastly, we calculate the base rate of the dataset.\nimport pandas as pd\nimport tensorflow as tf\nimport os\nimport re\nimport string\nfrom keras import layers\nfrom keras.models import Model\nfrom keras import losses\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom matplotlib import pyplot as plt\nfrom keras import utils\n\n# Load the dataset\ntrain_url = \"https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true\"\ndf = pd.read_csv(train_url)\n\n# Download NLTK stopwords\nimport nltk\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\n# Calculate the size of the vocabulary\ndef calculate_vocabulary_size(text_column):\n    all_words = ' '.join(text_column).split()\n    unique_words = set(all_words)\n    return len(unique_words)\n\n# Calculate the size of the vocabulary for both title and text columns\nsize_vocabulary_title = calculate_vocabulary_size(df['title'])\nsize_vocabulary_text = calculate_vocabulary_size(df['text'])\n\n# Use the maximum vocabulary size from title and text columns\nsize_vocabulary = max(size_vocabulary_title, size_vocabulary_text)\n\nprint(\"Vocabulary Size:\", size_vocabulary)\n\n\ndef make_dataset(df):\n    \n    # Lowercase the text and title columns\n    df['text'] = df['text'].str.lower()\n    df['title'] = df['title'].str.lower()\n\n    # Remove stopwords from the text and title columns using NLTK\n    df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n    df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n    \n    # consturct tf.data.Dataset: 2 inputs + 1 output\n    Dataset = tf.data.Dataset.from_tensor_slices(({\n          \"title\" : df[[\"title\"]],\n          \"text\" : df[[\"text\"]]\n    }, {\n          \"fake\" : df[\"fake\"]\n    }))\n\n    Dataset = Dataset.batch(100)\n    return Dataset\n\n\n# Create datasets\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\ntrain = make_dataset(train_df)\nval = make_dataset(val_df)\n\n# Calculate the base rate for the dataset\nbase_rate = max(train_df['fake'].value_counts(normalize=True))\n\nprint(\"Base Rate:\", base_rate)\nHere is the output:\nVocabulary Size: 276283\nBase Rate: 0.5222451138704828\n\n\n\nNow we define three separate models for classifying fake news based on the article title, text, or both.\nFirstly, we define the standardization to preprocess text data. It converts text to lowercase using TensorFlow’s tf.strings.lower function and removes punctuation using regular expressions and tf.strings.regex_replace.\nThen, we create two text vectorization layers using Keras’ TextVectorization class. These layers tokenize and vectorize text data. They use the standardization function for preprocessing, set the maximum number of tokens to the previously calculated size_vocabulary, and specify the output mode as ‘int’ to output integer indices for each token. The vectorization layers are adapted to the training dataset using the adapt method.\nNext, the input layers for the title and text data are defined using Keras’ Input class. They specify the shape as (1,) and data type as ‘string’.\nFor the actual model structure, the title input is passed through the text_vectorize_layer to convert titles into tokenized sequences. The resulting sequences are then passed through an embedding layer, which maps each token to a vector representation. A dropout layer is added to prevent overfitting, followed by a global average pooling layer to aggregate information from the entire sequence. Another dropout layer is included for regularization. Finally, a dense layer with two units and ReLU activation is added to output the classification result.\nFinally, we compile model, train, and plot.\ndef standardization(data):\n    low = tf.strings.lower(data)\n    puncfree = tf.strings.regex_replace(low,'[%s]' % re.escape(string.punctuation),'')\n    return puncfree\n\ntitle_vectorize_layer = layers.TextVectorization(\n    standardize=standardization,\n    max_tokens=size_vocabulary,\n    output_mode='int',\n    output_sequence_length=500)\n\ntext_vectorize_layer = layers.TextVectorization(\n    standardize=standardization,\n    max_tokens=size_vocabulary,\n    output_mode='int',\n    output_sequence_length=500)\n\ntitle_vectorize_layer.adapt(train.map(lambda x, y: x[\"title\"]))\ntext_vectorize_layer.adapt(train.map(lambda x, y: x[\"text\"]))\n\ntitle = keras.Input(shape=(1,),name=\"title\",dtype=\"string\")\ntext = keras.Input(shape=(1,),name=\"text\",dtype=\"string\")\n\ntitle_features = text_vectorize_layer(title)\ntitle_features = layers.Embedding(size_vocabulary, output_dim = 4, name=\"embedding\")(title_features)\ntitle_features = layers.Dropout(0.2)(title_features)\ntitle_features = layers.GlobalAveragePooling1D()(title_features)\ntitle_features = layers.Dropout(0.2)(title_features)\ntitle_features = layers.Dense(2, activation='relu', name=\"fake\")(title_features)\n\nmodel1 = keras.Model(\n      inputs = [title],\n      outputs = title_features\n)\n\nmodel1.compile(optimizer=\"adam\",\n              loss = losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=[\"accuracy\"])\n\nhistory = model1.fit(train,\n                    validation_data=val,\n                    epochs = 20,\n                    verbose = True)\n\nplt.plot(history.history[\"accuracy\"], label = \"training\")\nplt.plot(history.history[\"val_accuracy\"], label = \"validation\")\nplt.gca().set(xlabel = \"epoch\", ylabel = \"accuracy\")\nplt.legend()\nplt.title(\"Title Model\")\nplt.show()\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/hw6/titleEpochs.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/title.jpg')\n\n\n\n\n\n\n\n\nThe text model is defined in identical structure to our title model, just that we are using text as input:\ntext_features = text_vectorize_layer(text)\ntext_features = layers.Embedding(size_vocabulary, output_dim = 4, name=\"embedding\")(text_features)\ntext_features = layers.Dropout(0.2)(text_features)\ntext_features = layers.GlobalAveragePooling1D()(text_features)\ntext_features = layers.Dropout(0.2)(text_features)\ntext_features = layers.Dense(2, activation='relu', name=\"fake\")(text_features)\n\nmodel2 = keras.Model(\n      inputs = [text],\n      outputs = title_features\n)\n\nmodel2.compile(optimizer=\"adam\",\n              loss = losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=[\"accuracy\"])\n\nhistory2 = model2.fit(train,\n                    validation_data=val,\n                    epochs = 20,\n                    verbose = True)\n\nplt.plot(history2.history[\"accuracy\"], label = \"training\")\nplt.plot(history2.history[\"val_accuracy\"], label = \"validation\")\nplt.gca().set(xlabel = \"epoch\", ylabel = \"accuracy\")\nplt.legend()\nplt.title(\"Text Model\")\nplt.show()\n\nImage(filename='/Users/athena/Desktop/hw6/textEpochs.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/text.jpg')\n\n\n\n\n\n\n\n\nNow it gets a bit different for the combined model. We first redefine the text_features and title_features to get the vectorized layers for each. Then, embedding layers are added for both title and text inputs. These layers map the integer indices generated by the vectorization layers to dense vector representations. Each word in the vocabulary is represented by a vector of length 4 (output_dim = 4). Following the embedding layers, dense layers with 32 units and ReLU activation are added for both title and text features. These layers aim to learn non-linear patterns and relationships in the data. The output features from the title and text branches are concatenated along the feature axis (axis 1) using Keras’ concatenate function. This combines the extracted features from both branches into a single feature vector.\nDropout layers with a dropout rate of 0.5 are added after concatenation. Dropout is a regularization technique that randomly sets a fraction of input units to zero during training, which helps prevent overfitting. A global average pooling layer is added to aggregate information across the entire sequence of features. This reduces the dimensionality of the feature representation while retaining important information. Finally, a dense layer with 2 units and ReLU activation is added to output the classification result.\nLastly, we just compile, train, and plot.\ntitle_features = title_vectorize_layer(title)\ntext_features = text_vectorize_layer(text)\ntitle_embedding = layers.Embedding(size_vocabulary, output_dim = 4)\ntext_embedding = layers.Embedding(size_vocabulary, output_dim = 4)\ntitle_features = title_embedding(title_features)\ntext_features = text_embedding(text_features)\ntitle_features = layers.Dense(32, activation='relu')(title_features)\ntext_features = layers.Dense(32, activation='relu')(text_features)\n\ncombined = layers.concatenate([title_features, text_features], axis = 1)\ncombined = layers.Dropout(0.5)(combined)\ncombined = layers.GlobalAveragePooling1D()(combined)\ncombined = layers.Dropout(0.5)(combined)\ncombined = layers.Dense(2, activation='relu', name = 'fake')(combined)\n\nmodel3 = keras.Model(\n    inputs = [title_input, text_input],\n    outputs = combined\n)\n\nmodel3.compile(optimizer=\"adam\",\n              loss = losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=[\"accuracy\"])\n\nhistory3 = model3.fit(train,\n                    validation_data=val,\n                    epochs = 20,\n                    verbose = True)\n\nplt.plot(history3.history[\"accuracy\"], label = \"training\")\nplt.plot(history3.history[\"val_accuracy\"], label = \"validation\")\nplt.gca().set(xlabel = \"epoch\", ylabel = \"accuracy\")\nplt.legend()\nplt.title(\"Combined Model\")\nplt.show()\n\nImage(filename='/Users/athena/Desktop/hw6/combinedEpochs.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/combined.jpg')\n\n\n\n\n\n\n\n\n\n\n\nI used the following code to evaluate the best performing combined model. Acurracy is 0.9829!\ntest_url = \"https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true\"\ntest_df = pd.read_csv(test_url)\ntest = make_dataset(test_df)\nmodel3.evaluate(test)\nOutputs:\n225/225 ━━━━━━━━━━━━━━━━━━━━ 2s 10ms/step - accuracy: 0.9829 - loss: 0.0610\n[0.060648299753665924, 0.9822708964347839]\n\n\n\n\n\nWe visualize the embedding our our best performing model - the combined model. First, model3.get_layer(‘embedding’).get_weights()[0] retrieves the weights of the embedding layer named ‘embedding’ from model3. These weights represent the learned embeddings for each word in the vocabulary. Then, title_vectorize_layer.get_vocabulary() retrieves the vocabulary used by the title vectorization layer (title_vectorize_layer). This vocabulary corresponds to the tokens (words) in the title data that were processed during training.\nPCA(n_components=2) creates a PCA object specifying to reduce the dimensionality to 2 components. Then, pca.fit_transform(weights) applies PCA transformation on the embedding weights, reducing their dimensionality to two principal components.\nA pandas DataFrame named embedding_df is created to organize the reduced embeddings along with their corresponding words. The DataFrame has three columns: ‘word’, ‘x0’, and ‘x1’, where ‘word’ represents the token (word) from the vocabulary, and ‘x0’ and ‘x1’ represent the two principal components obtained from PCA.\nThe px.scatter function from Plotly Express is used to create a scatter plot of the reduced embeddings. The ‘x0’ and ‘x1’ columns from embedding_df are plotted on the x-axis and y-axis, respectively. Each point in the scatter plot represents a word, and its position is determined by its two principal components.\nweights = model3.get_layer('embedding').get_weights()[0] \nvocabulary = title_vectorize_layer.get_vocabulary() \n\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\nweights = pca.fit_transform(weights)\n\nembedding_df = pd.DataFrame({\n    'word' : vocabulary,\n    'x0'   : weights[:,0],\n    'x1'   : weights[:,1]\n})\n\nfig = px.scatter(embedding_df,\n                 x = \"x0\",\n                 y = \"x1\",\n                 size = [2]*len(embedding_df),\n                 hover_name = \"word\")\n\nfig.show()\n# Sorting the embedding DataFrame by the magnitude of weights\nembedding_df['weight_magnitude'] = np.sqrt(embedding_df['x0']**2 + embedding_df['x1']**2)\nembedding_df_sorted = embedding_df.sort_values(by='weight_magnitude', ascending=False)\n\n# Selecting the top 5 words with the highest weights\ntop_5_words = embedding_df_sorted.head(5)\n\n# Displaying the top 5 words\nprint(\"Top 5 words with highest weights:\")\nprint(top_5_words[['word', 'weight_magnitude']])\nOutputs:\n    Top 5 words with highest weights:\n        word  weight_magnitude\n3      video         21.057053\n5       says          9.715024\n7      watch          8.284890\n9    hillary          8.063581\n28  breaking          7.805355\n\n\n\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/hw6/title_model.jpg')\n\n\n\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/text_model.jpg')\n\n\n\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/combined_model.jpg')"
  },
  {
    "objectID": "posts/fake-news/hw6_New.html#preprocessing",
    "href": "posts/fake-news/hw6_New.html#preprocessing",
    "title": "Fake News Classification with Keras",
    "section": "",
    "text": "First, we make sure we are using Keras 3:\n!pip install keras --upgrade\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\nRequirement already satisfied: keras in /environment/miniconda3/lib/python3.10/site-packages (3.1.1)\nRequirement already satisfied: absl-py in /environment/miniconda3/lib/python3.10/site-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /environment/miniconda3/lib/python3.10/site-packages (from keras) (1.24.1)\nRequirement already satisfied: rich in /environment/miniconda3/lib/python3.10/site-packages (from keras) (13.7.1)\nRequirement already satisfied: namex in /environment/miniconda3/lib/python3.10/site-packages (from keras) (0.0.7)\nRequirement already satisfied: h5py in /environment/miniconda3/lib/python3.10/site-packages (from keras) (3.9.0)\nRequirement already satisfied: optree in /environment/miniconda3/lib/python3.10/site-packages (from keras) (0.10.0)\nRequirement already satisfied: ml-dtypes in /environment/miniconda3/lib/python3.10/site-packages (from keras) (0.3.2)\nRequirement already satisfied: typing-extensions&gt;=4.0.0 in /environment/miniconda3/lib/python3.10/site-packages (from optree-&gt;keras) (4.8.0)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /environment/miniconda3/lib/python3.10/site-packages (from rich-&gt;keras) (3.0.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /environment/miniconda3/lib/python3.10/site-packages (from rich-&gt;keras) (2.15.1)\nRequirement already satisfied: mdurl~=0.1 in /environment/miniconda3/lib/python3.10/site-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;keras) (0.1.2)\nkeras.__version__ prints ‘3.1.1’\nNow for the following code, we first import libraries - Pandas for data manipulation, TensorFlow for machine learning operations, NLTK for natural language processing, scikit-learn for data splitting, and Matplotlib for visualization.\nThen, we load dataset from given URL using Pandas’ read_csv, and define two functions preprocessing the data: 1. calculate_vocabulary_size: This function calculates the size of the vocabulary by tokenizing the text data, converting it to lowercase, and removing duplicates. 2. make_dataset: This function preprocesses the dataset by converting text to lowercase, removing stopwords using NLTK, and constructing a TensorFlow Dataset object with input features (title and text) and output labels (fake or not fake).\nNext, we calculate the vocabulary Size for both the ‘title’ and ‘text’ columns of the dataset using the calculate_vocabulary_size function. We also split dataset into training and validation sets using scikit-learn’s train_test_split function. Then, the make_dataset function is used to preprocess the datasets, converting them into TensorFlow Dataset objects.\nLastly, we calculate the base rate of the dataset.\nimport pandas as pd\nimport tensorflow as tf\nimport os\nimport re\nimport string\nfrom keras import layers\nfrom keras.models import Model\nfrom keras import losses\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom matplotlib import pyplot as plt\nfrom keras import utils\n\n# Load the dataset\ntrain_url = \"https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true\"\ndf = pd.read_csv(train_url)\n\n# Download NLTK stopwords\nimport nltk\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\n# Calculate the size of the vocabulary\ndef calculate_vocabulary_size(text_column):\n    all_words = ' '.join(text_column).split()\n    unique_words = set(all_words)\n    return len(unique_words)\n\n# Calculate the size of the vocabulary for both title and text columns\nsize_vocabulary_title = calculate_vocabulary_size(df['title'])\nsize_vocabulary_text = calculate_vocabulary_size(df['text'])\n\n# Use the maximum vocabulary size from title and text columns\nsize_vocabulary = max(size_vocabulary_title, size_vocabulary_text)\n\nprint(\"Vocabulary Size:\", size_vocabulary)\n\n\ndef make_dataset(df):\n    \n    # Lowercase the text and title columns\n    df['text'] = df['text'].str.lower()\n    df['title'] = df['title'].str.lower()\n\n    # Remove stopwords from the text and title columns using NLTK\n    df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n    df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n    \n    # consturct tf.data.Dataset: 2 inputs + 1 output\n    Dataset = tf.data.Dataset.from_tensor_slices(({\n          \"title\" : df[[\"title\"]],\n          \"text\" : df[[\"text\"]]\n    }, {\n          \"fake\" : df[\"fake\"]\n    }))\n\n    Dataset = Dataset.batch(100)\n    return Dataset\n\n\n# Create datasets\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\ntrain = make_dataset(train_df)\nval = make_dataset(val_df)\n\n# Calculate the base rate for the dataset\nbase_rate = max(train_df['fake'].value_counts(normalize=True))\n\nprint(\"Base Rate:\", base_rate)\nHere is the output:\nVocabulary Size: 276283\nBase Rate: 0.5222451138704828"
  },
  {
    "objectID": "posts/fake-news/hw6_New.html#model-construction",
    "href": "posts/fake-news/hw6_New.html#model-construction",
    "title": "Fake News Classification with Keras",
    "section": "",
    "text": "Now we define three separate models for classifying fake news based on the article title, text, or both.\nFirstly, we define the standardization to preprocess text data. It converts text to lowercase using TensorFlow’s tf.strings.lower function and removes punctuation using regular expressions and tf.strings.regex_replace.\nThen, we create two text vectorization layers using Keras’ TextVectorization class. These layers tokenize and vectorize text data. They use the standardization function for preprocessing, set the maximum number of tokens to the previously calculated size_vocabulary, and specify the output mode as ‘int’ to output integer indices for each token. The vectorization layers are adapted to the training dataset using the adapt method.\nNext, the input layers for the title and text data are defined using Keras’ Input class. They specify the shape as (1,) and data type as ‘string’.\nFor the actual model structure, the title input is passed through the text_vectorize_layer to convert titles into tokenized sequences. The resulting sequences are then passed through an embedding layer, which maps each token to a vector representation. A dropout layer is added to prevent overfitting, followed by a global average pooling layer to aggregate information from the entire sequence. Another dropout layer is included for regularization. Finally, a dense layer with two units and ReLU activation is added to output the classification result.\nFinally, we compile model, train, and plot.\ndef standardization(data):\n    low = tf.strings.lower(data)\n    puncfree = tf.strings.regex_replace(low,'[%s]' % re.escape(string.punctuation),'')\n    return puncfree\n\ntitle_vectorize_layer = layers.TextVectorization(\n    standardize=standardization,\n    max_tokens=size_vocabulary,\n    output_mode='int',\n    output_sequence_length=500)\n\ntext_vectorize_layer = layers.TextVectorization(\n    standardize=standardization,\n    max_tokens=size_vocabulary,\n    output_mode='int',\n    output_sequence_length=500)\n\ntitle_vectorize_layer.adapt(train.map(lambda x, y: x[\"title\"]))\ntext_vectorize_layer.adapt(train.map(lambda x, y: x[\"text\"]))\n\ntitle = keras.Input(shape=(1,),name=\"title\",dtype=\"string\")\ntext = keras.Input(shape=(1,),name=\"text\",dtype=\"string\")\n\ntitle_features = text_vectorize_layer(title)\ntitle_features = layers.Embedding(size_vocabulary, output_dim = 4, name=\"embedding\")(title_features)\ntitle_features = layers.Dropout(0.2)(title_features)\ntitle_features = layers.GlobalAveragePooling1D()(title_features)\ntitle_features = layers.Dropout(0.2)(title_features)\ntitle_features = layers.Dense(2, activation='relu', name=\"fake\")(title_features)\n\nmodel1 = keras.Model(\n      inputs = [title],\n      outputs = title_features\n)\n\nmodel1.compile(optimizer=\"adam\",\n              loss = losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=[\"accuracy\"])\n\nhistory = model1.fit(train,\n                    validation_data=val,\n                    epochs = 20,\n                    verbose = True)\n\nplt.plot(history.history[\"accuracy\"], label = \"training\")\nplt.plot(history.history[\"val_accuracy\"], label = \"validation\")\nplt.gca().set(xlabel = \"epoch\", ylabel = \"accuracy\")\nplt.legend()\nplt.title(\"Title Model\")\nplt.show()\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/hw6/titleEpochs.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/title.jpg')\n\n\n\n\n\n\n\n\nThe text model is defined in identical structure to our title model, just that we are using text as input:\ntext_features = text_vectorize_layer(text)\ntext_features = layers.Embedding(size_vocabulary, output_dim = 4, name=\"embedding\")(text_features)\ntext_features = layers.Dropout(0.2)(text_features)\ntext_features = layers.GlobalAveragePooling1D()(text_features)\ntext_features = layers.Dropout(0.2)(text_features)\ntext_features = layers.Dense(2, activation='relu', name=\"fake\")(text_features)\n\nmodel2 = keras.Model(\n      inputs = [text],\n      outputs = title_features\n)\n\nmodel2.compile(optimizer=\"adam\",\n              loss = losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=[\"accuracy\"])\n\nhistory2 = model2.fit(train,\n                    validation_data=val,\n                    epochs = 20,\n                    verbose = True)\n\nplt.plot(history2.history[\"accuracy\"], label = \"training\")\nplt.plot(history2.history[\"val_accuracy\"], label = \"validation\")\nplt.gca().set(xlabel = \"epoch\", ylabel = \"accuracy\")\nplt.legend()\nplt.title(\"Text Model\")\nplt.show()\n\nImage(filename='/Users/athena/Desktop/hw6/textEpochs.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/text.jpg')\n\n\n\n\n\n\n\n\nNow it gets a bit different for the combined model. We first redefine the text_features and title_features to get the vectorized layers for each. Then, embedding layers are added for both title and text inputs. These layers map the integer indices generated by the vectorization layers to dense vector representations. Each word in the vocabulary is represented by a vector of length 4 (output_dim = 4). Following the embedding layers, dense layers with 32 units and ReLU activation are added for both title and text features. These layers aim to learn non-linear patterns and relationships in the data. The output features from the title and text branches are concatenated along the feature axis (axis 1) using Keras’ concatenate function. This combines the extracted features from both branches into a single feature vector.\nDropout layers with a dropout rate of 0.5 are added after concatenation. Dropout is a regularization technique that randomly sets a fraction of input units to zero during training, which helps prevent overfitting. A global average pooling layer is added to aggregate information across the entire sequence of features. This reduces the dimensionality of the feature representation while retaining important information. Finally, a dense layer with 2 units and ReLU activation is added to output the classification result.\nLastly, we just compile, train, and plot.\ntitle_features = title_vectorize_layer(title)\ntext_features = text_vectorize_layer(text)\ntitle_embedding = layers.Embedding(size_vocabulary, output_dim = 4)\ntext_embedding = layers.Embedding(size_vocabulary, output_dim = 4)\ntitle_features = title_embedding(title_features)\ntext_features = text_embedding(text_features)\ntitle_features = layers.Dense(32, activation='relu')(title_features)\ntext_features = layers.Dense(32, activation='relu')(text_features)\n\ncombined = layers.concatenate([title_features, text_features], axis = 1)\ncombined = layers.Dropout(0.5)(combined)\ncombined = layers.GlobalAveragePooling1D()(combined)\ncombined = layers.Dropout(0.5)(combined)\ncombined = layers.Dense(2, activation='relu', name = 'fake')(combined)\n\nmodel3 = keras.Model(\n    inputs = [title_input, text_input],\n    outputs = combined\n)\n\nmodel3.compile(optimizer=\"adam\",\n              loss = losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=[\"accuracy\"])\n\nhistory3 = model3.fit(train,\n                    validation_data=val,\n                    epochs = 20,\n                    verbose = True)\n\nplt.plot(history3.history[\"accuracy\"], label = \"training\")\nplt.plot(history3.history[\"val_accuracy\"], label = \"validation\")\nplt.gca().set(xlabel = \"epoch\", ylabel = \"accuracy\")\nplt.legend()\nplt.title(\"Combined Model\")\nplt.show()\n\nImage(filename='/Users/athena/Desktop/hw6/combinedEpochs.jpg')\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/combined.jpg')"
  },
  {
    "objectID": "posts/fake-news/hw6_New.html#evaluation",
    "href": "posts/fake-news/hw6_New.html#evaluation",
    "title": "Fake News Classification with Keras",
    "section": "",
    "text": "I used the following code to evaluate the best performing combined model. Acurracy is 0.9829!\ntest_url = \"https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true\"\ntest_df = pd.read_csv(test_url)\ntest = make_dataset(test_df)\nmodel3.evaluate(test)\nOutputs:\n225/225 ━━━━━━━━━━━━━━━━━━━━ 2s 10ms/step - accuracy: 0.9829 - loss: 0.0610\n[0.060648299753665924, 0.9822708964347839]"
  },
  {
    "objectID": "posts/fake-news/hw6_New.html#model-visualizations",
    "href": "posts/fake-news/hw6_New.html#model-visualizations",
    "title": "Fake News Classification with Keras",
    "section": "",
    "text": "We visualize the embedding our our best performing model - the combined model. First, model3.get_layer(‘embedding’).get_weights()[0] retrieves the weights of the embedding layer named ‘embedding’ from model3. These weights represent the learned embeddings for each word in the vocabulary. Then, title_vectorize_layer.get_vocabulary() retrieves the vocabulary used by the title vectorization layer (title_vectorize_layer). This vocabulary corresponds to the tokens (words) in the title data that were processed during training.\nPCA(n_components=2) creates a PCA object specifying to reduce the dimensionality to 2 components. Then, pca.fit_transform(weights) applies PCA transformation on the embedding weights, reducing their dimensionality to two principal components.\nA pandas DataFrame named embedding_df is created to organize the reduced embeddings along with their corresponding words. The DataFrame has three columns: ‘word’, ‘x0’, and ‘x1’, where ‘word’ represents the token (word) from the vocabulary, and ‘x0’ and ‘x1’ represent the two principal components obtained from PCA.\nThe px.scatter function from Plotly Express is used to create a scatter plot of the reduced embeddings. The ‘x0’ and ‘x1’ columns from embedding_df are plotted on the x-axis and y-axis, respectively. Each point in the scatter plot represents a word, and its position is determined by its two principal components.\nweights = model3.get_layer('embedding').get_weights()[0] \nvocabulary = title_vectorize_layer.get_vocabulary() \n\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\nweights = pca.fit_transform(weights)\n\nembedding_df = pd.DataFrame({\n    'word' : vocabulary,\n    'x0'   : weights[:,0],\n    'x1'   : weights[:,1]\n})\n\nfig = px.scatter(embedding_df,\n                 x = \"x0\",\n                 y = \"x1\",\n                 size = [2]*len(embedding_df),\n                 hover_name = \"word\")\n\nfig.show()\n# Sorting the embedding DataFrame by the magnitude of weights\nembedding_df['weight_magnitude'] = np.sqrt(embedding_df['x0']**2 + embedding_df['x1']**2)\nembedding_df_sorted = embedding_df.sort_values(by='weight_magnitude', ascending=False)\n\n# Selecting the top 5 words with the highest weights\ntop_5_words = embedding_df_sorted.head(5)\n\n# Displaying the top 5 words\nprint(\"Top 5 words with highest weights:\")\nprint(top_5_words[['word', 'weight_magnitude']])\nOutputs:\n    Top 5 words with highest weights:\n        word  weight_magnitude\n3      video         21.057053\n5       says          9.715024\n7      watch          8.284890\n9    hillary          8.063581\n28  breaking          7.805355\n\n\n\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/hw6/title_model.jpg')\n\n\n\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/text_model.jpg')\n\n\n\n\n\n\n\n\n\n\n\n\nImage(filename='/Users/athena/Desktop/hw6/combined_model.jpg')"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/Heat-Equations/hw4.html",
    "href": "posts/Heat-Equations/hw4.html",
    "title": "Heat Diffusion with JAX",
    "section": "",
    "text": "In this project, I will be implementing the heat equation (see image below - credits to Professor Seyoon Ko UCLA PIC16B Winter 2024) through four different methods.\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/school/Winter2024/PIC16B/hw4.jpg')\n\n\n\n\n\n\n\n\n\n\nFirst, we import the time module for the rest of the code project to keep track of runtime for different methods. Note that all the following methods are placed inside heat_equation.py.\nimport time\nWe begin by importing the numpy and matplotlib modules. Then the first function is get_A(N) consisting of numpy arrays code that was provided by the professor. The returned A represents a 2D difference matrix \\(N^2 x N^2\\). The second function advance_time_matvecmul(A, u, epsilon) takes in A, u, and epsilon to perform matrix-vector multiplication. The first line (N = …) determines the size of the grid in one dimension, while the next (A @ u.flatten()) performs matrix-vector multiplication on flattened array, which then reshaped to 2D array to calculate the returning value u.\n'''\nPART ONE\n'''\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\ndef get_A(N):\n    n = N * N\n    diagonals = [-4 * np.ones(n), np.ones(n - 1), np.ones(n - 1), np.ones(n - N), np.ones(n - N)]\n    diagonals[1][(N - 1)::N] = 0\n    diagonals[2][(N - 1)::N] = 0\n    A = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3],\n                                                                                               N) + np.diag(\n        diagonals[4], -N)\n    return A\n\ndef advance_time_matvecmul(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n    Args:\n        A: The 2d finite difference matrix, N^2 x N^2.\n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n\n    Returns:\n        N x N Grid state at timestep k+1.\n    \"\"\"\n    N = u.shape[0]\n    u = u + epsilon * (A @ u.flatten()).reshape((N, N))\n    return u\n\ndef visualize_heat(u, iteration):\n    plt.subplot(3, 3, iteration // 300 + 1)\n    plt.imshow(u)\n    plt.title(f'Iteration {iteration}')\n    plt.axis('off')\n    \n# Simulation parameters\nN = 101\nepsilon = 0.2\nnum_iterations = 2700\n\n# Initial condition\nu0 = np.zeros((N, N))\nu0[int(N / 2), int(N / 2)] = 1.0\n\n# Get the matrix A\nA = get_A(N)\nstart_time = time.time()\n\n# Run the simulation\nintermediate_solutions = []\nfor iteration in range(1, num_iterations + 1):\n    u0 = advance_time_matvecmul(A, u0, epsilon)\n    if iteration % 300 == 0:\n        intermediate_solutions.append(u0.copy())\n        visualize_heat(u0, iteration)\n        \nend_time = time.time()\nsimulation_time = end_time - start_time\nprint(\"Simulation time:\", simulation_time)\nThe function visualize_heat basically calls the matplotlib package to display the plots according to the set iterations. Next, we initialize teh parameters N, epsilon, num_iterations, u0, and u0[int(N / 2), int(N / 2)].\nNext, we get the A using get_A and initiate the time recording for the simulation. Then we run the simulation by appending to an empty list intermediate_solutions and using a for-loop to iterate (display graph for every 300 simulations).\nFinally, we stop the runtime recording and print the simulation time. Note that this portion of code is repeated for all following methods with minor distinction in function name and parameter calling - it is primarily used to display the plot, run the simulation, and record the runtime.\nRUNTIME: Executed at 2024.03.02 09:54:39 in 38s 69ms\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/part1.jpg')\n\n\n\n\n\n\n\n\n\n\n\nIn this method, we define the function get_sparse_A(N) that returns A_sp_matrix and a jit-ed version of advance_time_matvecmul called advance_time_sparse.\nSimilarly, we first import the jax and scipy modules. The first function get_sparse_A(N) does the following (going line by line): - n calculates the total number of elements in the matrix - constructs a list called diagonals, where each element is a diagnoal for A - set the values of certain diagonals elements to zero - offset for determining relative position to main diagonal (0 is main and positive is right, negative is left) - constructs A_sp_matrix using the diags function with diagonals list, offsets list, shape set to \\(n * n\\) and format to csr\nThe second function advance_time_sparse(A_data, A_indices, A_indptr, u, epsilon) does the following (going line by line): - N to find size of the matrix in 1D - flattens the 2D matrix u into a 1D array to prepare for sparse - parse matrix-vector multiplication using jnp.dot - broadcasts u_result to an array (same shape as u_reshaped) - reshape u_result to match the shape of u - calculate final u matrix\n\"\"\"\nPART TWO\n\"\"\"\nfrom jax import jit\nfrom scipy.sparse import diags\n\ndef get_sparse_A(N):\n    n = N * N\n    diagonals = [-4 * np.ones(n), np.ones(n - 1), np.ones(n - 1), np.ones(n - N), np.ones(n - N)]\n    diagonals[1][(N - 1)::N] = 0\n    diagonals[2][(N - 1)::N] = 0\n    \n    A_dense = jnp.diag(diagonals[0])+ jnp.diag(diagonals[1],1)+ jnp.diag(diagonals[2], -1) +jnp.diag(diagonals[3],N)+ jnp.diag(diagonals[4],-N)\n    A_sparse = sparse.BCOO.fromdense(A_dense)\n    return A_sparse\n\n@jit\ndef advance_time_sparse(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n    Args:\n        A: 2d matrix N^2 x N^2\n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n\n    Returns:\n        N x N Grid state at timestep k+1.\n    \"\"\"\n    N = u.shape[0]\n    u = u + epsilon * (A @ u.flatten()).reshape((N, N))\n    return u\n\n# Simulation parameters\nN = 101\nepsilon = 0.2\nnum_iterations = 2700\n\n# Initial condition\nu0 = np.zeros((N, N))\nu0[int(N / 2), int(N / 2)] = 1.0\n\n# Get the sparse matrix A\nA = get_sparse_A(N)\n\n# Run the simulation\nintermediate_solutions_sparse = []\nfor iteration in range(1, num_iterations + 1):\n    u0 = advance_time_sparse(A_data, A_indices, A_indptr, u0, epsilon)\n    if iteration % 300 == 0:\n        intermediate_solutions_sparse.append(u0.copy())\n        visualize_heat(u0, iteration)\nplt.show()\n\nend_time = time.time()\nsimulation_time = end_time - start_time\nprint(\"Simulation time:\", simulation_time)\nThe rest of the code is basically the same as in method 1. However, notice how the sparse matrix A is converted to a format compatible with JAX by ensuring that both the indices and the indptr are int32 type.\nRUNTIME: Executed at 2024.03.02 12:02:17 in 3.9s 315ms\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/part2.jpg')\n\n\n\n\n\n\n\n\n\n\n\nIn this method, we define the function advance_time_numpy(u, epsilon) that applies numpy features to tackle the same problem.\nSimilarly, we first import the numpy and matplotlib modules. The only changed function advance_time_numpy(u, epsilon) does the following (going line by line): - n to find the size of matrix in 1D - pads the matrix u using np.pad with a one-cell wide border of zeros - initializes a new matrix u_new with the same shape + data type as u, filled with zeros - iterates through each element of u (excluding the padding) - (code block) updates value for each element in u_new based on the finite difference equation\nThe rest of the code remains similar to method 1 and method 2 - displays plot in end and prints time.\n\"\"\"\nPART THREE\n\"\"\"\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\ndef get_A(N):\n    n = N * N\n    diagonals = [-4 * np.ones(n), np.ones(n-1), np.ones(n-1), np.ones(n-N), np.ones(n-N)]\n    diagonals[1][(N-1)::N] = 0\n    diagonals[2][(N-1)::N] = 0\n    A = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3], N) + np.diag(diagonals[4], -N)\n    return A\n\ndef advance_time_numpy(u, epsilon):\n    \"\"\"Advances the JAX simulation via NumPy operations \n    Args:\n        u: The grid state at timestep k.\n        epsilon: The stability constant.\n    Returns:\n        u_new: the updated grid state at time step k+1.\n    \"\"\"\n    n = u.shape[0]\n    u_padded = np.pad(u, 1, mode='constant')\n    u_new = np.zeros_like(u)\n    for i in range(1, n+1):\n        for j in range(1, n+1):\n            u_new[i-1, j-1] = u_padded[i, j] + epsilon * (\n                u_padded[i+1, j] + u_padded[i-1, j] +\n                u_padded[i, j+1] + u_padded[i, j-1] - 4 * u_padded[i, j]\n            )\n    return u_new\n\ndef visualize_heat(u, iteration):\n    plt.subplot(3, 3, iteration // 300 + 1)\n    plt.imshow(u)\n    plt.title(f'Iteration {iteration}')\n    plt.axis('off')\n    \n# Simulation parameters\nN = 101\nepsilon = 0.2\nnum_iterations = 2700\n\n# Initial condition\nu0 = np.zeros((N, N))\nu0[int(N/2), int(N/2)] = 1.0\n\n# Get the matrix A\nA = get_A(N)\nstart_time = time.time()\n\n# Run the simulation with numpy operations\nu0 = np.zeros((N, N))\nu0[int(N/2), int(N/2)] = 1.0\nintermediate_solutions_numpy = []\nfor iteration in range(1, num_iterations + 1):\n    u0 = advance_time_numpy(u0, epsilon)\n    if iteration % 300 == 0:\n        intermediate_solutions_numpy.append(u0.copy())\n        \n# Visualize the diffusion of heat every 300 iterations using numpy operations\nplt.figure(figsize=(10, 10))\nfor i, solution in enumerate(intermediate_solutions_numpy):\n    visualize_heat(solution, (i+1) * 300)\nplt.show()\n\nend_time = time.time()\nsimulation_time = end_time - start_time\nprint(\"Simulation time:\", simulation_time)\nRUNTIME: Executed at 2024.03.02 15:50:22 in 376ms\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/part3.jpg')\n\n\n\n\n\n\n\n\n\n\n\nIn this method, we define the function advance_time_jax(u, epsilon) that uses JAX but not the sparse matrix multiplication method.\nWe begin by importing numpy, jax.numpy, jax, and matplotlib modules. The only changed function advance_time_jax(u, epsilon) does the following (going line by line): - n to find the size of matrix in 1D - pads the matrix u using np.pad with a one-cell wide border of zeros using jnp.pad - initializes a new matrix u_new with the same shape + data type as u, filled with zeros - iterates through each element of u (excluding the padding) - (code block) updates value for each element in u_new based on the finite difference equation - creates a mask array to check the indices where the u_new grid should be updated with update_value - uses jnp.where to update u_new where the mask is True\nThe rest of the code remains similar to method 1, 2, and 3 - displays plot in end and prints time.\n\"\"\"\nPART FOUR\n\"\"\"\nimport numpy as np\nimport jax.numpy as jnp\nfrom jax import jit\nfrom matplotlib import pyplot as plt\n\ndef get_A(N):\n    n = N * N\n    diagonals = [-4 * np.ones(n), np.ones(n-1), np.ones(n-1), np.ones(n-N), np.ones(n-N)]\n    diagonals[1][(N-1)::N] = 0\n    diagonals[2][(N-1)::N] = 0\n    A = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3], N) + np.diag(diagonals[4], -N)\n    return A\n\n@jit\ndef advance_time_jax(u, epsilon):\n    n = u.shape[0]\n    u_padded = jnp.pad(u, 1, mode='constant', constant_values = 0)\n    laplacian_u = (jnp.roll(u_padded, 1, axis=0) + jnp.roll(u_padded, -1, axis=0) +\n                  jnp.roll(u_padded, 1, axis=1) + jnp.roll(u_padded, -1, axis=1) -\n                  4* u_padded)[1:-1, 1:-1]\n    u_new = u + epsilon * laplacian_u\n    return u_new\n\ndef visualize_heat(u, iteration):\n    plt.subplot(3, 3, iteration // 300 + 1)\n    plt.imshow(u)\n    plt.title(f'Iteration {iteration}')\n    plt.axis('off')\n    \n# Simulation parameters\nN = 101\nepsilon = 0.2\nnum_iterations = 2700\n\n# Initial condition\nu0 = np.zeros((N, N))\nu0[int(N/2), int(N/2)] = 1.0\n\n# Get the matrix A\nA = get_A(N)\nstart_time = time.time()\n\n# Run the simulation with jax\nintermediate_solutions_jax = []\nfor iteration in range(1, num_iterations + 1):\n    u0 = advance_time_jax(u0, epsilon)\n    if iteration % 300 == 0:\n        intermediate_solutions_jax.append(u0.copy())\n        \n# Visualize the diffusion of heat every 300 iterations using jax\nplt.figure(figsize=(10, 10))\nfor i, solution in enumerate(intermediate_solutions_jax):\n    visualize_heat(solution, (i+1) * 300)\nplt.show()\n\nend_time = time.time()\nsimulation_time = end_time - start_time\nprint(\"Simulation time:\", simulation_time)\nRUNTIME: Executed at 2024.03.02 21:17:58 in 181ms\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/part4.jpg')\n\n\n\n\n\n\n\n\n\n\n\nIn conclusion, the last method was the fastest, while the numpy method was the easiest for me to write (perhaps due to personal experiences with numpy arrays and how numpy features are more intuitive)."
  },
  {
    "objectID": "posts/Heat-Equations/hw4.html#method-1-matrix-multiplication",
    "href": "posts/Heat-Equations/hw4.html#method-1-matrix-multiplication",
    "title": "Heat Diffusion with JAX",
    "section": "",
    "text": "First, we import the time module for the rest of the code project to keep track of runtime for different methods. Note that all the following methods are placed inside heat_equation.py.\nimport time\nWe begin by importing the numpy and matplotlib modules. Then the first function is get_A(N) consisting of numpy arrays code that was provided by the professor. The returned A represents a 2D difference matrix \\(N^2 x N^2\\). The second function advance_time_matvecmul(A, u, epsilon) takes in A, u, and epsilon to perform matrix-vector multiplication. The first line (N = …) determines the size of the grid in one dimension, while the next (A @ u.flatten()) performs matrix-vector multiplication on flattened array, which then reshaped to 2D array to calculate the returning value u.\n'''\nPART ONE\n'''\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\ndef get_A(N):\n    n = N * N\n    diagonals = [-4 * np.ones(n), np.ones(n - 1), np.ones(n - 1), np.ones(n - N), np.ones(n - N)]\n    diagonals[1][(N - 1)::N] = 0\n    diagonals[2][(N - 1)::N] = 0\n    A = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3],\n                                                                                               N) + np.diag(\n        diagonals[4], -N)\n    return A\n\ndef advance_time_matvecmul(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n    Args:\n        A: The 2d finite difference matrix, N^2 x N^2.\n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n\n    Returns:\n        N x N Grid state at timestep k+1.\n    \"\"\"\n    N = u.shape[0]\n    u = u + epsilon * (A @ u.flatten()).reshape((N, N))\n    return u\n\ndef visualize_heat(u, iteration):\n    plt.subplot(3, 3, iteration // 300 + 1)\n    plt.imshow(u)\n    plt.title(f'Iteration {iteration}')\n    plt.axis('off')\n    \n# Simulation parameters\nN = 101\nepsilon = 0.2\nnum_iterations = 2700\n\n# Initial condition\nu0 = np.zeros((N, N))\nu0[int(N / 2), int(N / 2)] = 1.0\n\n# Get the matrix A\nA = get_A(N)\nstart_time = time.time()\n\n# Run the simulation\nintermediate_solutions = []\nfor iteration in range(1, num_iterations + 1):\n    u0 = advance_time_matvecmul(A, u0, epsilon)\n    if iteration % 300 == 0:\n        intermediate_solutions.append(u0.copy())\n        visualize_heat(u0, iteration)\n        \nend_time = time.time()\nsimulation_time = end_time - start_time\nprint(\"Simulation time:\", simulation_time)\nThe function visualize_heat basically calls the matplotlib package to display the plots according to the set iterations. Next, we initialize teh parameters N, epsilon, num_iterations, u0, and u0[int(N / 2), int(N / 2)].\nNext, we get the A using get_A and initiate the time recording for the simulation. Then we run the simulation by appending to an empty list intermediate_solutions and using a for-loop to iterate (display graph for every 300 simulations).\nFinally, we stop the runtime recording and print the simulation time. Note that this portion of code is repeated for all following methods with minor distinction in function name and parameter calling - it is primarily used to display the plot, run the simulation, and record the runtime.\nRUNTIME: Executed at 2024.03.02 09:54:39 in 38s 69ms\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/part1.jpg')"
  },
  {
    "objectID": "posts/Heat-Equations/hw4.html#method-2-sparse-matrix-in-jax",
    "href": "posts/Heat-Equations/hw4.html#method-2-sparse-matrix-in-jax",
    "title": "Heat Diffusion with JAX",
    "section": "",
    "text": "In this method, we define the function get_sparse_A(N) that returns A_sp_matrix and a jit-ed version of advance_time_matvecmul called advance_time_sparse.\nSimilarly, we first import the jax and scipy modules. The first function get_sparse_A(N) does the following (going line by line): - n calculates the total number of elements in the matrix - constructs a list called diagonals, where each element is a diagnoal for A - set the values of certain diagonals elements to zero - offset for determining relative position to main diagonal (0 is main and positive is right, negative is left) - constructs A_sp_matrix using the diags function with diagonals list, offsets list, shape set to \\(n * n\\) and format to csr\nThe second function advance_time_sparse(A_data, A_indices, A_indptr, u, epsilon) does the following (going line by line): - N to find size of the matrix in 1D - flattens the 2D matrix u into a 1D array to prepare for sparse - parse matrix-vector multiplication using jnp.dot - broadcasts u_result to an array (same shape as u_reshaped) - reshape u_result to match the shape of u - calculate final u matrix\n\"\"\"\nPART TWO\n\"\"\"\nfrom jax import jit\nfrom scipy.sparse import diags\n\ndef get_sparse_A(N):\n    n = N * N\n    diagonals = [-4 * np.ones(n), np.ones(n - 1), np.ones(n - 1), np.ones(n - N), np.ones(n - N)]\n    diagonals[1][(N - 1)::N] = 0\n    diagonals[2][(N - 1)::N] = 0\n    \n    A_dense = jnp.diag(diagonals[0])+ jnp.diag(diagonals[1],1)+ jnp.diag(diagonals[2], -1) +jnp.diag(diagonals[3],N)+ jnp.diag(diagonals[4],-N)\n    A_sparse = sparse.BCOO.fromdense(A_dense)\n    return A_sparse\n\n@jit\ndef advance_time_sparse(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n    Args:\n        A: 2d matrix N^2 x N^2\n        u: N x N grid state at timestep k.\n        epsilon: stability constant.\n\n    Returns:\n        N x N Grid state at timestep k+1.\n    \"\"\"\n    N = u.shape[0]\n    u = u + epsilon * (A @ u.flatten()).reshape((N, N))\n    return u\n\n# Simulation parameters\nN = 101\nepsilon = 0.2\nnum_iterations = 2700\n\n# Initial condition\nu0 = np.zeros((N, N))\nu0[int(N / 2), int(N / 2)] = 1.0\n\n# Get the sparse matrix A\nA = get_sparse_A(N)\n\n# Run the simulation\nintermediate_solutions_sparse = []\nfor iteration in range(1, num_iterations + 1):\n    u0 = advance_time_sparse(A_data, A_indices, A_indptr, u0, epsilon)\n    if iteration % 300 == 0:\n        intermediate_solutions_sparse.append(u0.copy())\n        visualize_heat(u0, iteration)\nplt.show()\n\nend_time = time.time()\nsimulation_time = end_time - start_time\nprint(\"Simulation time:\", simulation_time)\nThe rest of the code is basically the same as in method 1. However, notice how the sparse matrix A is converted to a format compatible with JAX by ensuring that both the indices and the indptr are int32 type.\nRUNTIME: Executed at 2024.03.02 12:02:17 in 3.9s 315ms\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/part2.jpg')"
  },
  {
    "objectID": "posts/Heat-Equations/hw4.html#method-3-direct-operation-with-numpy",
    "href": "posts/Heat-Equations/hw4.html#method-3-direct-operation-with-numpy",
    "title": "Heat Diffusion with JAX",
    "section": "",
    "text": "In this method, we define the function advance_time_numpy(u, epsilon) that applies numpy features to tackle the same problem.\nSimilarly, we first import the numpy and matplotlib modules. The only changed function advance_time_numpy(u, epsilon) does the following (going line by line): - n to find the size of matrix in 1D - pads the matrix u using np.pad with a one-cell wide border of zeros - initializes a new matrix u_new with the same shape + data type as u, filled with zeros - iterates through each element of u (excluding the padding) - (code block) updates value for each element in u_new based on the finite difference equation\nThe rest of the code remains similar to method 1 and method 2 - displays plot in end and prints time.\n\"\"\"\nPART THREE\n\"\"\"\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\ndef get_A(N):\n    n = N * N\n    diagonals = [-4 * np.ones(n), np.ones(n-1), np.ones(n-1), np.ones(n-N), np.ones(n-N)]\n    diagonals[1][(N-1)::N] = 0\n    diagonals[2][(N-1)::N] = 0\n    A = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3], N) + np.diag(diagonals[4], -N)\n    return A\n\ndef advance_time_numpy(u, epsilon):\n    \"\"\"Advances the JAX simulation via NumPy operations \n    Args:\n        u: The grid state at timestep k.\n        epsilon: The stability constant.\n    Returns:\n        u_new: the updated grid state at time step k+1.\n    \"\"\"\n    n = u.shape[0]\n    u_padded = np.pad(u, 1, mode='constant')\n    u_new = np.zeros_like(u)\n    for i in range(1, n+1):\n        for j in range(1, n+1):\n            u_new[i-1, j-1] = u_padded[i, j] + epsilon * (\n                u_padded[i+1, j] + u_padded[i-1, j] +\n                u_padded[i, j+1] + u_padded[i, j-1] - 4 * u_padded[i, j]\n            )\n    return u_new\n\ndef visualize_heat(u, iteration):\n    plt.subplot(3, 3, iteration // 300 + 1)\n    plt.imshow(u)\n    plt.title(f'Iteration {iteration}')\n    plt.axis('off')\n    \n# Simulation parameters\nN = 101\nepsilon = 0.2\nnum_iterations = 2700\n\n# Initial condition\nu0 = np.zeros((N, N))\nu0[int(N/2), int(N/2)] = 1.0\n\n# Get the matrix A\nA = get_A(N)\nstart_time = time.time()\n\n# Run the simulation with numpy operations\nu0 = np.zeros((N, N))\nu0[int(N/2), int(N/2)] = 1.0\nintermediate_solutions_numpy = []\nfor iteration in range(1, num_iterations + 1):\n    u0 = advance_time_numpy(u0, epsilon)\n    if iteration % 300 == 0:\n        intermediate_solutions_numpy.append(u0.copy())\n        \n# Visualize the diffusion of heat every 300 iterations using numpy operations\nplt.figure(figsize=(10, 10))\nfor i, solution in enumerate(intermediate_solutions_numpy):\n    visualize_heat(solution, (i+1) * 300)\nplt.show()\n\nend_time = time.time()\nsimulation_time = end_time - start_time\nprint(\"Simulation time:\", simulation_time)\nRUNTIME: Executed at 2024.03.02 15:50:22 in 376ms\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/part3.jpg')"
  },
  {
    "objectID": "posts/Heat-Equations/hw4.html#method-4-jax-without-using-sparse-matrix-multiplication",
    "href": "posts/Heat-Equations/hw4.html#method-4-jax-without-using-sparse-matrix-multiplication",
    "title": "Heat Diffusion with JAX",
    "section": "",
    "text": "In this method, we define the function advance_time_jax(u, epsilon) that uses JAX but not the sparse matrix multiplication method.\nWe begin by importing numpy, jax.numpy, jax, and matplotlib modules. The only changed function advance_time_jax(u, epsilon) does the following (going line by line): - n to find the size of matrix in 1D - pads the matrix u using np.pad with a one-cell wide border of zeros using jnp.pad - initializes a new matrix u_new with the same shape + data type as u, filled with zeros - iterates through each element of u (excluding the padding) - (code block) updates value for each element in u_new based on the finite difference equation - creates a mask array to check the indices where the u_new grid should be updated with update_value - uses jnp.where to update u_new where the mask is True\nThe rest of the code remains similar to method 1, 2, and 3 - displays plot in end and prints time.\n\"\"\"\nPART FOUR\n\"\"\"\nimport numpy as np\nimport jax.numpy as jnp\nfrom jax import jit\nfrom matplotlib import pyplot as plt\n\ndef get_A(N):\n    n = N * N\n    diagonals = [-4 * np.ones(n), np.ones(n-1), np.ones(n-1), np.ones(n-N), np.ones(n-N)]\n    diagonals[1][(N-1)::N] = 0\n    diagonals[2][(N-1)::N] = 0\n    A = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3], N) + np.diag(diagonals[4], -N)\n    return A\n\n@jit\ndef advance_time_jax(u, epsilon):\n    n = u.shape[0]\n    u_padded = jnp.pad(u, 1, mode='constant', constant_values = 0)\n    laplacian_u = (jnp.roll(u_padded, 1, axis=0) + jnp.roll(u_padded, -1, axis=0) +\n                  jnp.roll(u_padded, 1, axis=1) + jnp.roll(u_padded, -1, axis=1) -\n                  4* u_padded)[1:-1, 1:-1]\n    u_new = u + epsilon * laplacian_u\n    return u_new\n\ndef visualize_heat(u, iteration):\n    plt.subplot(3, 3, iteration // 300 + 1)\n    plt.imshow(u)\n    plt.title(f'Iteration {iteration}')\n    plt.axis('off')\n    \n# Simulation parameters\nN = 101\nepsilon = 0.2\nnum_iterations = 2700\n\n# Initial condition\nu0 = np.zeros((N, N))\nu0[int(N/2), int(N/2)] = 1.0\n\n# Get the matrix A\nA = get_A(N)\nstart_time = time.time()\n\n# Run the simulation with jax\nintermediate_solutions_jax = []\nfor iteration in range(1, num_iterations + 1):\n    u0 = advance_time_jax(u0, epsilon)\n    if iteration % 300 == 0:\n        intermediate_solutions_jax.append(u0.copy())\n        \n# Visualize the diffusion of heat every 300 iterations using jax\nplt.figure(figsize=(10, 10))\nfor i, solution in enumerate(intermediate_solutions_jax):\n    visualize_heat(solution, (i+1) * 300)\nplt.show()\n\nend_time = time.time()\nsimulation_time = end_time - start_time\nprint(\"Simulation time:\", simulation_time)\nRUNTIME: Executed at 2024.03.02 21:17:58 in 181ms\n\nfrom IPython.display import Image\nImage(filename='/Users/athena/Desktop/part4.jpg')"
  },
  {
    "objectID": "posts/Heat-Equations/hw4.html#comparison",
    "href": "posts/Heat-Equations/hw4.html#comparison",
    "title": "Heat Diffusion with JAX",
    "section": "",
    "text": "In conclusion, the last method was the fastest, while the numpy method was the easiest for me to write (perhaps due to personal experiences with numpy arrays and how numpy features are more intuitive)."
  },
  {
    "objectID": "posts/Web-Scraping/HW2.html",
    "href": "posts/Web-Scraping/HW2.html",
    "title": "Web Scraping on Movie",
    "section": "",
    "text": "In this post, I will be presenting my Scrapy project that is used to scrape my favoriate movie: A Rainy Day in New York - directed by Woody Allen.\nPlease click the following link to see my project repository:\n// Note: The following code is used to display the hyperlink\n\nfrom IPython.core.display import display, HTML\ndisplay(HTML(\"\"\"&lt;a href=\"https://github.com/Fishier1224/PIC16B_0/tree/main/TMDB_scraper\"&gt;Project Repository&lt;/a&gt;\"\"\"))\n\n/var/folders/4g/1nylr1s57nvcbk28gd1y9r0h0000gn/T/ipykernel_22301/3278939308.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n  from IPython.core.display import display, HTML\n\n\nProject Repository\n\n\n\n\nBegin by entering the following command in your local terminal “scrapy startproject TMDB_scraper”. My project is named TMDB_scraper, but you can name it whatever you wish. This command will create a folder for your scrapy project.\nInside the project folder, you will see another folder named as TMDB_scraper (along with scrapy.cfg). Click in the folder and open settings.py.\nIn settings.py, you want to include the following code to avoid being blocked by the site because they notice you are scraping (403 error). You may need to first install scrapy-fake-useragent using the following command “pip install scrapy-fake-useragent”.\nThe following code in settings.py turns off the built in UserAgentMiddleware and RetryMiddleware, then enables scrapy-fake-useragent’s RandomUserAgentMiddleware and RetryUserAgentMiddleware.\n\nDOWNLOADER_MIDDLEWARES = {\n    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,\n    'scrapy.downloadermiddlewares.retry.RetryMiddleware': None,\n    'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware': 400,\n    'scrapy_fake_useragent.middleware.RetryUserAgentMiddleware': 401,\n}\n\n\nFAKEUSERAGENT_PROVIDERS = [\n    'scrapy_fake_useragent.providers.FakeUserAgentProvider',  # Trying first provider\n    'scrapy_fake_useragent.providers.FakerProvider',  # If FakeUserAgentProvider fails, use faker to generate a user-agent string\n    'scrapy_fake_useragent.providers.FixedUserAgentProvider',  # Fall back to USER_AGENT value\n]\n\n## Set Fallback User-Agent\nUSER_AGENT = 'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148'\n\nNotice how there is a fallback User-Agent named USER_AGENT, this is the user agent that the program will fall back on if all providers fails.\n\n\n\nFirst, import scrapy. Then create the class TmdbSpider calling “scrapy.Spider”, and assign the name to “tmdb_spider”.\nNext, under init, specify the start_url with “f”https://www.themoviedb.org/movie/{subdir}/““. Notice how the subdirectory is provided with f string. This means that we will need to use “scrapy crawl tmdb_spider -o movies.csv -a subdir=475303-a-rainy-day-in-new-york” when we are calling scrapy in the terminal later on.\n\nimport scrapy\n\nclass TmdbSpider(scrapy.Spider):\n    name = 'tmdb_spider'\n\n    def __init__(self, subdir=None, *args, **kwargs):\n        self.start_urls = [f\"https://www.themoviedb.org/movie/{subdir}/\"]\n\nNow, our first parse function begins with the cast page of the movie that we are scraping. In this function, we yield the scrapy request to call another function parse_full_credits, which will be used to scape individual casts in the movie. Notice how the url is simply the self.subdir + /cast.\n\n   def parse(self, response):\n        \"\"\"\n        The main parse function.\n        sets the url to the cast page of the movie, then calls parse_full_credits to\n        proceed to individual actors (casts) of the movie.\n        return: N/A\n        \"\"\"\n        yield scrapy.Request(f\"https://www.themoviedb.org/movie/{self.subdir}/cast\",\n                             callback=self.parse_full_credits)\n\nFollowing, we have the parse_full_credits function. Since the cast actor links on the website html are placed within the li element (written like this in the html: ol.people.credits:not(.crew) li), we first select that portion and assign it to actors (note how we also did not(.crew) to avoid also getting the crew cast.\nThen we iterate through the actors to get individual links to the actor’s page using actor.css(‘a::attr(href)’).get(). Next, we check if we are on the actor’s page with if actor_link and calls to the function parse_actor_page for continued parsing.\n\n    def parse_full_credits(self, response):\n        \"\"\"\n        Parsing for actors in the movie, provides link for each.\n        iterates through the &lt;li&gt; elements to get href attributes (link to each actor)\n        calls parse_actor_page() when the actor page is reached.\n        return: N/A\n        \"\"\"\n        actors = response.css('ol.people.credits:not(.crew) li')   # Select the &lt;li&gt; elements containing actor information\n        for actor in actors:\n            actor_link = actor.css('a::attr(href)').get()  # Extract the href attribute of the &lt;a&gt; tag\n            if actor_link:\n                yield scrapy.Request(response.urljoin(actor_link), callback=self.parse_actor_page)\n\nThis is our final parsing function - parse_actor_page. This function assumes that we are at an actor’s page, and begin by extracting the actor’s name. Notice how there is a split in the first line. This is because the website’s html includes an index number for actor’s name and we don’t want that.\nThe second line selects the acting section of the page, where all the actor’s acting works are located. The third line then specifies an xpath, while the four further specifies the xpath in line three to the titles containing “role”. Finally, we iterate through the titles to yield a dictionary where the key is the actor’s name, and the value is the title of individual works that they are known for.\n\n    def parse_actor_page(self, response):\n        \"\"\"\n        Assumes at an actor page. Extracts the actor's name using title::text.\n        For a single actor, extracts the title of their works under the \"known_for\" section\n        iterates through the title to yield a dictionary with actor's name and the name of their work\n        \"\"\"\n        actor_name = response.css('title::text').get().split(' — ')[0] # Split to get rid of following number index\n        acting_section = response.css('h3:contains(\"Acting\")')\n        table = acting_section.xpath('./following-sibling::table').get()\n        titles = scrapy.Selector(text=table).xpath('.//td[contains(@class, \"role\")]/a/bdi/text()').getall()\n        for title in titles:\n            yield {\"actor\": actor_name, 'movie_or_TV_name': title}\n\n\n\n\nNow that we finished implementing the class and three parse functions. Type in the terminal under the same directory as “TMDB_scraper”: scrapy crawl tmdb_spider -o results.csv -a subdir=475303-a-rainy-day-in-new-york.\nThis line will scrape your website and generate a result.csv file that presents the dictionary.\n\n\n\nNow that we have the results.csv, read the csv file using pandas:\n\nimport pandas as pd\nresults = pd.read_csv(\"results.csv\")\n\nHere is a overview of what the result looks like using “results.head()”:\n\nresults.head()\n\n\n\n\n\n\n\n\nactor\nmovie_or_TV_name\n\n\n\n\n0\nTimothée Chalamet\nCall Me by Your Name\n\n\n1\nTimothée Chalamet\nDune\n\n\n2\nTimothée Chalamet\nThe King\n\n\n3\nTimothée Chalamet\nInterstellar\n\n\n4\nTimothée Chalamet\nA Rainy Day in New York\n\n\n\n\n\n\n\nNow we are going to use matplotlib for an interesting visualization. Begin by importing matplotlib:\n\nimport matplotlib.pyplot as plt\n\nNow we create a new dataframe based on the results dataframe, named frequency_df. This line groups the results dataframe by ‘movie_or_TV_name’ and count the number of unique ‘actor’ values (the frequency of actors that shares the same ‘movie_or_TV_name’).\n\nfrequency_df = results.groupby('movie_or_TV_name')['actor'].nunique().reset_index()\n\nHere we rename the columns of our new data frame to “actor” and “frequency”. Then the next line sorts the frequency_df by the ‘frequency’ column in descending order (organizing the movies with the highest frequency to the top of the dataframe).\nThe third line rests the index to make the dataframe more presentable.\n\nfrequency_df = frequency_df.rename(columns={'actor': 'frequency'})\nfrequency_df = frequency_df.sort_values('frequency', ascending=False)\nfrequency_df = frequency_df.reset_index(drop=True)\n\nNext, to prepare for better plotting, we specify the frequency_df to only include the top 10 highest frequency movies.\n\nfrequency_df = frequency_df.head(10)\n\nNow we generate the bar chart! First call the x and y variables as “movie_or_TV_name” and “frequency” in the frequency_df dataframe. Then, label the x and y axis as “Movie or TV Name” and “Frequency”. Finally, we label the plot’s title and set the x-axis ticks as “rotation=90”.\nAt last we display the chart!\n\nplt.bar(frequency_df['movie_or_TV_name'], frequency_df['frequency'])\nplt.xlabel('Movie or TV Name')\nplt.ylabel('Frequency')\nplt.title('Frequency of Actors Sharing the Same Movie or TV Name')\nplt.xticks(rotation=90)\nplt.tight_layout()\n\nplt.show()"
  },
  {
    "objectID": "posts/Web-Scraping/HW2.html#preparing-for-scraping",
    "href": "posts/Web-Scraping/HW2.html#preparing-for-scraping",
    "title": "Web Scraping on Movie",
    "section": "",
    "text": "Begin by entering the following command in your local terminal “scrapy startproject TMDB_scraper”. My project is named TMDB_scraper, but you can name it whatever you wish. This command will create a folder for your scrapy project.\nInside the project folder, you will see another folder named as TMDB_scraper (along with scrapy.cfg). Click in the folder and open settings.py.\nIn settings.py, you want to include the following code to avoid being blocked by the site because they notice you are scraping (403 error). You may need to first install scrapy-fake-useragent using the following command “pip install scrapy-fake-useragent”.\nThe following code in settings.py turns off the built in UserAgentMiddleware and RetryMiddleware, then enables scrapy-fake-useragent’s RandomUserAgentMiddleware and RetryUserAgentMiddleware.\n\nDOWNLOADER_MIDDLEWARES = {\n    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,\n    'scrapy.downloadermiddlewares.retry.RetryMiddleware': None,\n    'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware': 400,\n    'scrapy_fake_useragent.middleware.RetryUserAgentMiddleware': 401,\n}\n\n\nFAKEUSERAGENT_PROVIDERS = [\n    'scrapy_fake_useragent.providers.FakeUserAgentProvider',  # Trying first provider\n    'scrapy_fake_useragent.providers.FakerProvider',  # If FakeUserAgentProvider fails, use faker to generate a user-agent string\n    'scrapy_fake_useragent.providers.FixedUserAgentProvider',  # Fall back to USER_AGENT value\n]\n\n## Set Fallback User-Agent\nUSER_AGENT = 'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148'\n\nNotice how there is a fallback User-Agent named USER_AGENT, this is the user agent that the program will fall back on if all providers fails."
  },
  {
    "objectID": "posts/Web-Scraping/HW2.html#implementing-the-tmdbspider-class",
    "href": "posts/Web-Scraping/HW2.html#implementing-the-tmdbspider-class",
    "title": "Web Scraping on Movie",
    "section": "",
    "text": "First, import scrapy. Then create the class TmdbSpider calling “scrapy.Spider”, and assign the name to “tmdb_spider”.\nNext, under init, specify the start_url with “f”https://www.themoviedb.org/movie/{subdir}/““. Notice how the subdirectory is provided with f string. This means that we will need to use “scrapy crawl tmdb_spider -o movies.csv -a subdir=475303-a-rainy-day-in-new-york” when we are calling scrapy in the terminal later on.\n\nimport scrapy\n\nclass TmdbSpider(scrapy.Spider):\n    name = 'tmdb_spider'\n\n    def __init__(self, subdir=None, *args, **kwargs):\n        self.start_urls = [f\"https://www.themoviedb.org/movie/{subdir}/\"]\n\nNow, our first parse function begins with the cast page of the movie that we are scraping. In this function, we yield the scrapy request to call another function parse_full_credits, which will be used to scape individual casts in the movie. Notice how the url is simply the self.subdir + /cast.\n\n   def parse(self, response):\n        \"\"\"\n        The main parse function.\n        sets the url to the cast page of the movie, then calls parse_full_credits to\n        proceed to individual actors (casts) of the movie.\n        return: N/A\n        \"\"\"\n        yield scrapy.Request(f\"https://www.themoviedb.org/movie/{self.subdir}/cast\",\n                             callback=self.parse_full_credits)\n\nFollowing, we have the parse_full_credits function. Since the cast actor links on the website html are placed within the li element (written like this in the html: ol.people.credits:not(.crew) li), we first select that portion and assign it to actors (note how we also did not(.crew) to avoid also getting the crew cast.\nThen we iterate through the actors to get individual links to the actor’s page using actor.css(‘a::attr(href)’).get(). Next, we check if we are on the actor’s page with if actor_link and calls to the function parse_actor_page for continued parsing.\n\n    def parse_full_credits(self, response):\n        \"\"\"\n        Parsing for actors in the movie, provides link for each.\n        iterates through the &lt;li&gt; elements to get href attributes (link to each actor)\n        calls parse_actor_page() when the actor page is reached.\n        return: N/A\n        \"\"\"\n        actors = response.css('ol.people.credits:not(.crew) li')   # Select the &lt;li&gt; elements containing actor information\n        for actor in actors:\n            actor_link = actor.css('a::attr(href)').get()  # Extract the href attribute of the &lt;a&gt; tag\n            if actor_link:\n                yield scrapy.Request(response.urljoin(actor_link), callback=self.parse_actor_page)\n\nThis is our final parsing function - parse_actor_page. This function assumes that we are at an actor’s page, and begin by extracting the actor’s name. Notice how there is a split in the first line. This is because the website’s html includes an index number for actor’s name and we don’t want that.\nThe second line selects the acting section of the page, where all the actor’s acting works are located. The third line then specifies an xpath, while the four further specifies the xpath in line three to the titles containing “role”. Finally, we iterate through the titles to yield a dictionary where the key is the actor’s name, and the value is the title of individual works that they are known for.\n\n    def parse_actor_page(self, response):\n        \"\"\"\n        Assumes at an actor page. Extracts the actor's name using title::text.\n        For a single actor, extracts the title of their works under the \"known_for\" section\n        iterates through the title to yield a dictionary with actor's name and the name of their work\n        \"\"\"\n        actor_name = response.css('title::text').get().split(' — ')[0] # Split to get rid of following number index\n        acting_section = response.css('h3:contains(\"Acting\")')\n        table = acting_section.xpath('./following-sibling::table').get()\n        titles = scrapy.Selector(text=table).xpath('.//td[contains(@class, \"role\")]/a/bdi/text()').getall()\n        for title in titles:\n            yield {\"actor\": actor_name, 'movie_or_TV_name': title}"
  },
  {
    "objectID": "posts/Web-Scraping/HW2.html#running-the-spider",
    "href": "posts/Web-Scraping/HW2.html#running-the-spider",
    "title": "Web Scraping on Movie",
    "section": "",
    "text": "Now that we finished implementing the class and three parse functions. Type in the terminal under the same directory as “TMDB_scraper”: scrapy crawl tmdb_spider -o results.csv -a subdir=475303-a-rainy-day-in-new-york.\nThis line will scrape your website and generate a result.csv file that presents the dictionary."
  },
  {
    "objectID": "posts/Web-Scraping/HW2.html#some-visualization",
    "href": "posts/Web-Scraping/HW2.html#some-visualization",
    "title": "Web Scraping on Movie",
    "section": "",
    "text": "Now that we have the results.csv, read the csv file using pandas:\n\nimport pandas as pd\nresults = pd.read_csv(\"results.csv\")\n\nHere is a overview of what the result looks like using “results.head()”:\n\nresults.head()\n\n\n\n\n\n\n\n\nactor\nmovie_or_TV_name\n\n\n\n\n0\nTimothée Chalamet\nCall Me by Your Name\n\n\n1\nTimothée Chalamet\nDune\n\n\n2\nTimothée Chalamet\nThe King\n\n\n3\nTimothée Chalamet\nInterstellar\n\n\n4\nTimothée Chalamet\nA Rainy Day in New York\n\n\n\n\n\n\n\nNow we are going to use matplotlib for an interesting visualization. Begin by importing matplotlib:\n\nimport matplotlib.pyplot as plt\n\nNow we create a new dataframe based on the results dataframe, named frequency_df. This line groups the results dataframe by ‘movie_or_TV_name’ and count the number of unique ‘actor’ values (the frequency of actors that shares the same ‘movie_or_TV_name’).\n\nfrequency_df = results.groupby('movie_or_TV_name')['actor'].nunique().reset_index()\n\nHere we rename the columns of our new data frame to “actor” and “frequency”. Then the next line sorts the frequency_df by the ‘frequency’ column in descending order (organizing the movies with the highest frequency to the top of the dataframe).\nThe third line rests the index to make the dataframe more presentable.\n\nfrequency_df = frequency_df.rename(columns={'actor': 'frequency'})\nfrequency_df = frequency_df.sort_values('frequency', ascending=False)\nfrequency_df = frequency_df.reset_index(drop=True)\n\nNext, to prepare for better plotting, we specify the frequency_df to only include the top 10 highest frequency movies.\n\nfrequency_df = frequency_df.head(10)\n\nNow we generate the bar chart! First call the x and y variables as “movie_or_TV_name” and “frequency” in the frequency_df dataframe. Then, label the x and y axis as “Movie or TV Name” and “Frequency”. Finally, we label the plot’s title and set the x-axis ticks as “rotation=90”.\nAt last we display the chart!\n\nplt.bar(frequency_df['movie_or_TV_name'], frequency_df['frequency'])\nplt.xlabel('Movie or TV Name')\nplt.ylabel('Frequency')\nplt.title('Frequency of Actors Sharing the Same Movie or TV Name')\nplt.xticks(rotation=90)\nplt.tight_layout()\n\nplt.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myblog",
    "section": "",
    "text": "Project - Chordy!\n\n\n\n\n\n\nProject\n\n\nflask\n\n\nMongoDB\n\n\nScrapy\n\n\nMidiutil\n\n\n\n\n\n\n\n\n\nMar 19, 2024\n\n\nAthena Mo\n\n\n\n\n\n\n\n\n\n\n\n\nFake News Classification with Keras\n\n\n\n\n\n\nHW6\n\n\nKeras\n\n\nPandas\n\n\nMatplotlib\n\n\nTensorflow\n\n\nnltk\n\n\nscikit-learn\n\n\n\n\n\n\n\n\n\nMar 5, 2024\n\n\nAthena Mo\n\n\n\n\n\n\n\n\n\n\n\n\nImage Classification\n\n\n\n\n\n\nHW5\n\n\nTensorflow\n\n\nKeras\n\n\nNumpy\n\n\n\n\n\n\n\n\n\nMar 1, 2024\n\n\nAthena Mo\n\n\n\n\n\n\n\n\n\n\n\n\nHeat Diffusion with JAX\n\n\n\n\n\n\nHW4\n\n\nJAX\n\n\nNumPy\n\n\nMatplotlib\n\n\n\n\n\n\n\n\n\nFeb 14, 2024\n\n\nAthena Mo\n\n\n\n\n\n\n\n\n\n\n\n\nFlask Messages\n\n\n\n\n\n\nHW3\n\n\nflask\n\n\nSQL\n\n\n\n\n\n\n\n\n\nFeb 14, 2024\n\n\nAthena Mo\n\n\n\n\n\n\n\n\n\n\n\n\nWeb Scraping on Movie\n\n\n\n\n\n\nHW2\n\n\nscrapy\n\n\npandas\n\n\nmatplotlib\n\n\n\n\n\n\n\n\n\nFeb 1, 2024\n\n\nAthena Mo\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 26, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nPalmer Penguins Data Visualization\n\n\n\n\n\n\nHW0\n\n\npandas\n\n\nplotly\n\n\nmatplotlib\n\n\n\n\n\n\n\n\n\nJan 26, 2024\n\n\nAthena Mo\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJan 23, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]